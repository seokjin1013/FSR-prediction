{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1_CNN_LSTM\n",
    "\n",
    "Index_X = FSR_for_force, FSR_for_coord\n",
    "\n",
    "Index_y = force, x_coord, y_coord\n",
    "\n",
    "Data = Splited by Time\n",
    "\n",
    "## Run result\n",
    "\n",
    "https://wandb.ai/seokjin/FSR-prediction/groups/FSR_Trainable_2023-08-10_16-28-50/workspace?workspace=user-seokjin\n",
    "\n",
    "## Experiment id\n",
    "\n",
    "FSR_Trainable_2023-08-10_16-28-50\n",
    "\n",
    "## Best metric (RMSE)\n",
    "\n",
    "203.214\n",
    "\n",
    "0.927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_searchspace(trial):\n",
    "    model = trial.suggest_categorical('model', ['fsr_model.CNN_LSTM'])\n",
    "    if model == 'fsr_model.LSTM':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.CNN_LSTM':\n",
    "        trial.suggest_categorical('model_args/cnn_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_categorical('model_args/lstm_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/cnn_num_layer', 1, 8)\n",
    "        trial.suggest_int('model_args/lstm_num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.ANN':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    trial.suggest_categorical('criterion', ['torch.nn.MSELoss'])\n",
    "    trial.suggest_categorical('optimizer', [\n",
    "        'torch.optim.Adam',\n",
    "        'torch.optim.NAdam',\n",
    "        'torch.optim.Adagrad',\n",
    "        'torch.optim.RAdam',\n",
    "        'torch.optim.SGD',\n",
    "    ])\n",
    "    trial.suggest_float('optimizer_args/lr', 1e-5, 1e-1, log=True)\n",
    "    imputer = trial.suggest_categorical('imputer', ['sklearn.impute.SimpleImputer'])\n",
    "    if imputer == 'sklearn.impute.SimpleImputer':\n",
    "        trial.suggest_categorical('imputer_args/strategy', [\n",
    "            'mean',\n",
    "            'median',\n",
    "        ])\n",
    "    trial.suggest_categorical('scaler', [ \n",
    "        'sklearn.preprocessing.StandardScaler',\n",
    "        'sklearn.preprocessing.MinMaxScaler',\n",
    "        'sklearn.preprocessing.RobustScaler',\n",
    "    ])\n",
    "    return {\n",
    "        'index_X': ['FSR_for_force', 'FSR_for_coord'],\n",
    "        'index_y': ['force', 'x_coord', 'y_coord'],\n",
    "        'data_loader': 'fsr_data.get_index_splited_by_time'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-10 16:28:50,387] A new study created in memory with name: optuna\n"
     ]
    }
   ],
   "source": [
    "import ray.tune\n",
    "import ray.air\n",
    "import ray.air.integrations.wandb\n",
    "import ray.tune.schedulers\n",
    "from fsr_trainable import FSR_Trainable\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "\n",
    "tuner = ray.tune.Tuner(\n",
    "    trainable=ray.tune.with_resources(\n",
    "        FSR_Trainable, {'cpu':2},\n",
    "    ),\n",
    "    tune_config=ray.tune.TuneConfig(\n",
    "        num_samples=100,\n",
    "        scheduler=ray.tune.schedulers.ASHAScheduler(\n",
    "            max_t=100,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2,\n",
    "            brackets=1,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "        search_alg=ray.tune.search.optuna.OptunaSearch(\n",
    "            space=define_searchspace,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "    ), \n",
    "    run_config=ray.air.RunConfig(\n",
    "        callbacks=[\n",
    "            ray.air.integrations.wandb.WandbLoggerCallback(project='FSR-prediction'),\n",
    "        ],\n",
    "        checkpoint_config=ray.air.CheckpointConfig(\n",
    "            num_to_keep=3,\n",
    "            checkpoint_score_attribute='metric',\n",
    "            checkpoint_score_order='min',\n",
    "            checkpoint_frequency=5,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-10 16:28:50</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.12        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.3/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th>criterion       </th><th>data_loader         </th><th>imputer             </th><th>imputer_args/strateg\n",
       "y     </th><th>index_X             </th><th>index_y             </th><th>model             </th><th style=\"text-align: right;\">    model_args/cnn_hidde\n",
       "n_size</th><th style=\"text-align: right;\">  model_args/cnn_num_l\n",
       "ayer</th><th style=\"text-align: right;\">   model_args/lstm_hidd\n",
       "en_size</th><th style=\"text-align: right;\">  model_args/lstm_num_\n",
       "layer</th><th>optimizer          </th><th style=\"text-align: right;\">  optimizer_args/lr</th><th>scaler              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_26b73957</td><td>PENDING </td><td>     </td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_d1d0</td><td>sklearn.impute._8670</td><td>mean</td><td>[&#x27;FSR_for_force_df80</td><td>[&#x27;force&#x27;, &#x27;x_co_e640</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">          0.0842028</td><td>sklearn.preproc_d110</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 16:28:50,426\tINFO wandb.py:320 -- Already logged into W&B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mae_coord</th><th style=\"text-align: right;\">  mae_force</th><th style=\"text-align: right;\">  mape_coord</th><th style=\"text-align: right;\">  mape_force</th><th style=\"text-align: right;\">   metric</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  rmse_coord</th><th style=\"text-align: right;\">  rmse_force</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  tmae_coord</th><th style=\"text-align: right;\">  tmae_force</th><th style=\"text-align: right;\">  tmape_coord</th><th style=\"text-align: right;\">  tmape_force</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  trmse_coord</th><th style=\"text-align: right;\">  trmse_force</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_072855d3</td><td>2023-08-10_17-05-07</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.76296</td><td style=\"text-align: right;\">    727.379</td><td style=\"text-align: right;\">     1.31197</td><td style=\"text-align: right;\"> 4.0234e+17 </td><td style=\"text-align: right;\"> 0.64827 </td><td>172.26.215.93</td><td style=\"text-align: right;\">85148</td><td style=\"text-align: right;\">     2.33887</td><td style=\"text-align: right;\">     593.069</td><td style=\"text-align: right;\">           311.39   </td><td style=\"text-align: right;\">          3.64825 </td><td style=\"text-align: right;\">     311.39   </td><td style=\"text-align: right;\"> 1691654707</td><td style=\"text-align: right;\">    0.948191</td><td style=\"text-align: right;\">    0.27898 </td><td style=\"text-align: right;\">  1.88291e+14</td><td style=\"text-align: right;\">  1.86594e+14</td><td style=\"text-align: right;\">                 100</td><td>072855d3  </td><td style=\"text-align: right;\">     0.434802</td><td style=\"text-align: right;\">     0.213468</td></tr>\n",
       "<tr><td>FSR_Trainable_07769fcd</td><td>2023-08-10_17-15-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.90523</td><td style=\"text-align: right;\">    768.795</td><td style=\"text-align: right;\">     1.2966 </td><td style=\"text-align: right;\"> 6.07742e+17</td><td style=\"text-align: right;\"> 0.641753</td><td>172.26.215.93</td><td style=\"text-align: right;\">89395</td><td style=\"text-align: right;\">     2.38966</td><td style=\"text-align: right;\">     572.397</td><td style=\"text-align: right;\">           100.948  </td><td style=\"text-align: right;\">          1.36824 </td><td style=\"text-align: right;\">     100.948  </td><td style=\"text-align: right;\"> 1691655353</td><td style=\"text-align: right;\">    0.979046</td><td style=\"text-align: right;\">    0.299197</td><td style=\"text-align: right;\">  1.67269e+14</td><td style=\"text-align: right;\">  3.00202e+14</td><td style=\"text-align: right;\">                  64</td><td>07769fcd  </td><td style=\"text-align: right;\">     0.440279</td><td style=\"text-align: right;\">     0.201474</td></tr>\n",
       "<tr><td>FSR_Trainable_0a4bcaa3</td><td>2023-08-10_16-45-12</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.35259</td><td style=\"text-align: right;\">   1472.15 </td><td style=\"text-align: right;\">     1.34902</td><td style=\"text-align: right;\"> 1.7415e+18 </td><td style=\"text-align: right;\"> 0.859286</td><td>172.26.215.93</td><td style=\"text-align: right;\">78107</td><td style=\"text-align: right;\">     2.63176</td><td style=\"text-align: right;\">    1133.91 </td><td style=\"text-align: right;\">            29.2114 </td><td style=\"text-align: right;\">          6.94429 </td><td style=\"text-align: right;\">      29.2114 </td><td style=\"text-align: right;\"> 1691653512</td><td style=\"text-align: right;\">    1.07617 </td><td style=\"text-align: right;\">    0.507983</td><td style=\"text-align: right;\">  2.01318e+14</td><td style=\"text-align: right;\">  5.71236e+14</td><td style=\"text-align: right;\">                   4</td><td>0a4bcaa3  </td><td style=\"text-align: right;\">     0.499358</td><td style=\"text-align: right;\">     0.359929</td></tr>\n",
       "<tr><td>FSR_Trainable_0ca736a5</td><td>2023-08-10_16-33-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.76648</td><td style=\"text-align: right;\">   1466.3  </td><td style=\"text-align: right;\">     1.44054</td><td style=\"text-align: right;\"> 1.72149e+18</td><td style=\"text-align: right;\"> 0.860441</td><td>172.26.215.93</td><td style=\"text-align: right;\">73070</td><td style=\"text-align: right;\">     2.68527</td><td style=\"text-align: right;\">    1124.72 </td><td style=\"text-align: right;\">            28.9223 </td><td style=\"text-align: right;\">          3.69158 </td><td style=\"text-align: right;\">      28.9223 </td><td style=\"text-align: right;\"> 1691652818</td><td style=\"text-align: right;\">    1.13188 </td><td style=\"text-align: right;\">    0.503006</td><td style=\"text-align: right;\">  1.86061e+14</td><td style=\"text-align: right;\">  5.24718e+14</td><td style=\"text-align: right;\">                   8</td><td>0ca736a5  </td><td style=\"text-align: right;\">     0.499558</td><td style=\"text-align: right;\">     0.360883</td></tr>\n",
       "<tr><td>FSR_Trainable_0cc277c6</td><td>2023-08-10_16-49-31</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.60991</td><td style=\"text-align: right;\">   1467.65 </td><td style=\"text-align: right;\">     1.33387</td><td style=\"text-align: right;\"> 6.97434e+16</td><td style=\"text-align: right;\">21.1816  </td><td>172.26.215.93</td><td style=\"text-align: right;\">79985</td><td style=\"text-align: right;\">     2.44394</td><td style=\"text-align: right;\">    1182.68 </td><td style=\"text-align: right;\">             3.77236</td><td style=\"text-align: right;\">          3.77236 </td><td style=\"text-align: right;\">       3.77236</td><td style=\"text-align: right;\"> 1691653771</td><td style=\"text-align: right;\">   12.6093  </td><td style=\"text-align: right;\">   11.3433  </td><td style=\"text-align: right;\">  3.93598e+15</td><td style=\"text-align: right;\">  2.48341e+15</td><td style=\"text-align: right;\">                   1</td><td>0cc277c6  </td><td style=\"text-align: right;\">     7.77869 </td><td style=\"text-align: right;\">    13.403   </td></tr>\n",
       "<tr><td>FSR_Trainable_0d2c4fda</td><td>2023-08-10_16-43-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.88406</td><td style=\"text-align: right;\">   1511.92 </td><td style=\"text-align: right;\">     1.30092</td><td style=\"text-align: right;\"> 2.12958e+18</td><td style=\"text-align: right;\"> 0.820496</td><td>172.26.215.93</td><td style=\"text-align: right;\">76867</td><td style=\"text-align: right;\">     2.48398</td><td style=\"text-align: right;\">    1112.59 </td><td style=\"text-align: right;\">            85.4892 </td><td style=\"text-align: right;\">          2.70097 </td><td style=\"text-align: right;\">      85.4892 </td><td style=\"text-align: right;\"> 1691653380</td><td style=\"text-align: right;\">    0.987978</td><td style=\"text-align: right;\">    0.525306</td><td style=\"text-align: right;\">  2.06775e+14</td><td style=\"text-align: right;\">  7.22996e+14</td><td style=\"text-align: right;\">                  32</td><td>0d2c4fda  </td><td style=\"text-align: right;\">     0.467745</td><td style=\"text-align: right;\">     0.352751</td></tr>\n",
       "<tr><td>FSR_Trainable_0f412368</td><td>2023-08-10_16-51-37</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.11881</td><td style=\"text-align: right;\">   1491.87 </td><td style=\"text-align: right;\">     1.30753</td><td style=\"text-align: right;\"> 1.94562e+18</td><td style=\"text-align: right;\"> 0.831473</td><td>172.26.215.93</td><td style=\"text-align: right;\">81104</td><td style=\"text-align: right;\">     2.53279</td><td style=\"text-align: right;\">    1120.09 </td><td style=\"text-align: right;\">            55.647  </td><td style=\"text-align: right;\">          3.33329 </td><td style=\"text-align: right;\">      55.647  </td><td style=\"text-align: right;\"> 1691653897</td><td style=\"text-align: right;\">    1.03144 </td><td style=\"text-align: right;\">    0.519786</td><td style=\"text-align: right;\">  2.05764e+14</td><td style=\"text-align: right;\">  6.70248e+14</td><td style=\"text-align: right;\">                  16</td><td>0f412368  </td><td style=\"text-align: right;\">     0.475816</td><td style=\"text-align: right;\">     0.355657</td></tr>\n",
       "<tr><td>FSR_Trainable_10524936</td><td>2023-08-10_16-43-45</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    5.13763</td><td style=\"text-align: right;\">   1341.89 </td><td style=\"text-align: right;\">     1.32825</td><td style=\"text-align: right;\"> 3.84483e+17</td><td style=\"text-align: right;\">20.9139  </td><td>172.26.215.93</td><td style=\"text-align: right;\">77623</td><td style=\"text-align: right;\">     2.5158 </td><td style=\"text-align: right;\">    1086.76 </td><td style=\"text-align: right;\">             3.24751</td><td style=\"text-align: right;\">          3.24751 </td><td style=\"text-align: right;\">       3.24751</td><td style=\"text-align: right;\"> 1691653425</td><td style=\"text-align: right;\">   15.6496  </td><td style=\"text-align: right;\">   12.8625  </td><td style=\"text-align: right;\">  1.24604e+16</td><td style=\"text-align: right;\">  1.61323e+16</td><td style=\"text-align: right;\">                   1</td><td>10524936  </td><td style=\"text-align: right;\">     8.42552 </td><td style=\"text-align: right;\">    12.4884  </td></tr>\n",
       "<tr><td>FSR_Trainable_15f12775</td><td>2023-08-10_17-15-22</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.44401</td><td style=\"text-align: right;\">   1400.2  </td><td style=\"text-align: right;\">     1.13329</td><td style=\"text-align: right;\"> 5.53242e+16</td><td style=\"text-align: right;\">24.2141  </td><td>172.26.215.93</td><td style=\"text-align: right;\">90523</td><td style=\"text-align: right;\">     2.46332</td><td style=\"text-align: right;\">    1165.69 </td><td style=\"text-align: right;\">             2.41903</td><td style=\"text-align: right;\">          2.41903 </td><td style=\"text-align: right;\">       2.41903</td><td style=\"text-align: right;\"> 1691655322</td><td style=\"text-align: right;\">   15.532   </td><td style=\"text-align: right;\">   10.4397  </td><td style=\"text-align: right;\">  5.42695e+15</td><td style=\"text-align: right;\">  2.51261e+15</td><td style=\"text-align: right;\">                   1</td><td>15f12775  </td><td style=\"text-align: right;\">    11.3314  </td><td style=\"text-align: right;\">    12.8827  </td></tr>\n",
       "<tr><td>FSR_Trainable_19390f08</td><td>2023-08-10_17-11-05</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.60737</td><td style=\"text-align: right;\">    663.756</td><td style=\"text-align: right;\">     1.17506</td><td style=\"text-align: right;\"> 5.61214e+17</td><td style=\"text-align: right;\"> 0.601072</td><td>172.26.215.93</td><td style=\"text-align: right;\">87767</td><td style=\"text-align: right;\">     2.32711</td><td style=\"text-align: right;\">     498.493</td><td style=\"text-align: right;\">           146.652  </td><td style=\"text-align: right;\">          1.58454 </td><td style=\"text-align: right;\">     146.652  </td><td style=\"text-align: right;\"> 1691655065</td><td style=\"text-align: right;\">    0.921944</td><td style=\"text-align: right;\">    0.255959</td><td style=\"text-align: right;\">  1.64635e+14</td><td style=\"text-align: right;\">  2.66787e+14</td><td style=\"text-align: right;\">                 100</td><td>19390f08  </td><td style=\"text-align: right;\">     0.429665</td><td style=\"text-align: right;\">     0.171407</td></tr>\n",
       "<tr><td>FSR_Trainable_1b9499ed</td><td>2023-08-10_16-35-11</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    6.7537 </td><td style=\"text-align: right;\">   1833.82 </td><td style=\"text-align: right;\">     1.32875</td><td style=\"text-align: right;\"> 3.34468e+18</td><td style=\"text-align: right;\"> 0.985749</td><td>172.26.215.93</td><td style=\"text-align: right;\">74490</td><td style=\"text-align: right;\">     3.07924</td><td style=\"text-align: right;\">    1142.2  </td><td style=\"text-align: right;\">             3.22222</td><td style=\"text-align: right;\">          3.22222 </td><td style=\"text-align: right;\">       3.22222</td><td style=\"text-align: right;\"> 1691652911</td><td style=\"text-align: right;\">    1.3765  </td><td style=\"text-align: right;\">    0.699846</td><td style=\"text-align: right;\">  8.94232e+13</td><td style=\"text-align: right;\">  1.3951e+15 </td><td style=\"text-align: right;\">                   1</td><td>1b9499ed  </td><td style=\"text-align: right;\">     0.596538</td><td style=\"text-align: right;\">     0.389211</td></tr>\n",
       "<tr><td>FSR_Trainable_1e628a56</td><td>2023-08-10_16-58-16</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.90702</td><td style=\"text-align: right;\">    914.653</td><td style=\"text-align: right;\">     1.2843 </td><td style=\"text-align: right;\"> 5.94162e+17</td><td style=\"text-align: right;\"> 0.699392</td><td>172.26.215.93</td><td style=\"text-align: right;\">79332</td><td style=\"text-align: right;\">     2.39259</td><td style=\"text-align: right;\">     758.379</td><td style=\"text-align: right;\">           567.935  </td><td style=\"text-align: right;\">          5.48537 </td><td style=\"text-align: right;\">     567.935  </td><td style=\"text-align: right;\"> 1691654296</td><td style=\"text-align: right;\">    0.986932</td><td style=\"text-align: right;\">    0.333277</td><td style=\"text-align: right;\">  1.93172e+14</td><td style=\"text-align: right;\">  2.49752e+14</td><td style=\"text-align: right;\">                 100</td><td>1e628a56  </td><td style=\"text-align: right;\">     0.449797</td><td style=\"text-align: right;\">     0.249595</td></tr>\n",
       "<tr><td>FSR_Trainable_1eb906b8</td><td>2023-08-10_17-16-58</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.65162</td><td style=\"text-align: right;\">    696.39 </td><td style=\"text-align: right;\">     1.22376</td><td style=\"text-align: right;\"> 5.6703e+17 </td><td style=\"text-align: right;\"> 0.622039</td><td>172.26.215.93</td><td style=\"text-align: right;\">89581</td><td style=\"text-align: right;\">     2.34571</td><td style=\"text-align: right;\">     529.354</td><td style=\"text-align: right;\">           145.702  </td><td style=\"text-align: right;\">          1.23819 </td><td style=\"text-align: right;\">     145.702  </td><td style=\"text-align: right;\"> 1691655418</td><td style=\"text-align: right;\">    0.933972</td><td style=\"text-align: right;\">    0.273783</td><td style=\"text-align: right;\">  1.62576e+14</td><td style=\"text-align: right;\">  2.75713e+14</td><td style=\"text-align: right;\">                 100</td><td>1eb906b8  </td><td style=\"text-align: right;\">     0.435253</td><td style=\"text-align: right;\">     0.186787</td></tr>\n",
       "<tr><td>FSR_Trainable_2594bb2c</td><td>2023-08-10_16-40-23</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.61093</td><td style=\"text-align: right;\">   1444.49 </td><td style=\"text-align: right;\">     1.38088</td><td style=\"text-align: right;\"> 1.47485e+18</td><td style=\"text-align: right;\"> 0.854744</td><td>172.26.215.93</td><td style=\"text-align: right;\">75446</td><td style=\"text-align: right;\">     2.62252</td><td style=\"text-align: right;\">    1139.77 </td><td style=\"text-align: right;\">           184.935  </td><td style=\"text-align: right;\">         11.4734  </td><td style=\"text-align: right;\">     184.935  </td><td style=\"text-align: right;\"> 1691653223</td><td style=\"text-align: right;\">    1.11467 </td><td style=\"text-align: right;\">    0.498645</td><td style=\"text-align: right;\">  1.75182e+14</td><td style=\"text-align: right;\">  4.70828e+14</td><td style=\"text-align: right;\">                  16</td><td>2594bb2c  </td><td style=\"text-align: right;\">     0.490325</td><td style=\"text-align: right;\">     0.364419</td></tr>\n",
       "<tr><td>FSR_Trainable_26b73957</td><td>2023-08-10_16-37-03</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.00263</td><td style=\"text-align: right;\">   1024.4  </td><td style=\"text-align: right;\">     1.31055</td><td style=\"text-align: right;\"> 8.78277e+17</td><td style=\"text-align: right;\"> 0.727801</td><td>172.26.215.93</td><td style=\"text-align: right;\">66526</td><td style=\"text-align: right;\">     2.46287</td><td style=\"text-align: right;\">     845.925</td><td style=\"text-align: right;\">           467.687  </td><td style=\"text-align: right;\">          4.69393 </td><td style=\"text-align: right;\">     467.687  </td><td style=\"text-align: right;\"> 1691653023</td><td style=\"text-align: right;\">    1.00971 </td><td style=\"text-align: right;\">    0.371543</td><td style=\"text-align: right;\">  1.99406e+14</td><td style=\"text-align: right;\">  3.63175e+14</td><td style=\"text-align: right;\">                 100</td><td>26b73957  </td><td style=\"text-align: right;\">     0.463553</td><td style=\"text-align: right;\">     0.264247</td></tr>\n",
       "<tr><td>FSR_Trainable_281c7f09</td><td>2023-08-10_16-56-22</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   10.8857 </td><td style=\"text-align: right;\">   1656.57 </td><td style=\"text-align: right;\">     1.99841</td><td style=\"text-align: right;\"> 1.85576e+18</td><td style=\"text-align: right;\"> 1.17594 </td><td>172.26.215.93</td><td style=\"text-align: right;\">82889</td><td style=\"text-align: right;\">     3.79727</td><td style=\"text-align: right;\">    1242.16 </td><td style=\"text-align: right;\">             5.94887</td><td style=\"text-align: right;\">          5.94887 </td><td style=\"text-align: right;\">       5.94887</td><td style=\"text-align: right;\"> 1691654182</td><td style=\"text-align: right;\">    2.32268 </td><td style=\"text-align: right;\">    0.643652</td><td style=\"text-align: right;\">  1.54268e+14</td><td style=\"text-align: right;\">  9.09569e+14</td><td style=\"text-align: right;\">                   1</td><td>281c7f09  </td><td style=\"text-align: right;\">     0.777676</td><td style=\"text-align: right;\">     0.398267</td></tr>\n",
       "<tr><td>FSR_Trainable_291c0121</td><td>2023-08-10_17-19-26</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.57837</td><td style=\"text-align: right;\">    694.983</td><td style=\"text-align: right;\">     1.11815</td><td style=\"text-align: right;\"> 6.18025e+17</td><td style=\"text-align: right;\"> 0.60446 </td><td>172.26.215.93</td><td style=\"text-align: right;\">91721</td><td style=\"text-align: right;\">     2.32242</td><td style=\"text-align: right;\">     525.168</td><td style=\"text-align: right;\">           107.792  </td><td style=\"text-align: right;\">          0.648162</td><td style=\"text-align: right;\">     107.792  </td><td style=\"text-align: right;\"> 1691655566</td><td style=\"text-align: right;\">    0.917771</td><td style=\"text-align: right;\">    0.264383</td><td style=\"text-align: right;\">  1.51742e+14</td><td style=\"text-align: right;\">  2.79511e+14</td><td style=\"text-align: right;\">                 100</td><td>291c0121  </td><td style=\"text-align: right;\">     0.426683</td><td style=\"text-align: right;\">     0.177777</td></tr>\n",
       "<tr><td>FSR_Trainable_2a7340c1</td><td>2023-08-10_16-45-29</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.2268 </td><td style=\"text-align: right;\">   1296.79 </td><td style=\"text-align: right;\">     1.19988</td><td style=\"text-align: right;\"> 4.7571e+09 </td><td style=\"text-align: right;\"> 5.79846 </td><td>172.26.215.93</td><td style=\"text-align: right;\">78351</td><td style=\"text-align: right;\">     2.40199</td><td style=\"text-align: right;\">    1014.49 </td><td style=\"text-align: right;\">             5.83635</td><td style=\"text-align: right;\">          5.83635 </td><td style=\"text-align: right;\">       5.83635</td><td style=\"text-align: right;\"> 1691653529</td><td style=\"text-align: right;\">    6.80791 </td><td style=\"text-align: right;\">    3.12523 </td><td style=\"text-align: right;\">  1.34617e+15</td><td style=\"text-align: right;\">  8.61141    </td><td style=\"text-align: right;\">                   1</td><td>2a7340c1  </td><td style=\"text-align: right;\">     3.49149 </td><td style=\"text-align: right;\">     2.30697 </td></tr>\n",
       "<tr><td>FSR_Trainable_2d03179b</td><td>2023-08-10_17-19-21</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.56423</td><td style=\"text-align: right;\">    641.452</td><td style=\"text-align: right;\">     1.14484</td><td style=\"text-align: right;\"> 5.66384e+17</td><td style=\"text-align: right;\"> 0.596868</td><td>172.26.215.93</td><td style=\"text-align: right;\">91524</td><td style=\"text-align: right;\">     2.3298 </td><td style=\"text-align: right;\">     487.23 </td><td style=\"text-align: right;\">           117.698  </td><td style=\"text-align: right;\">          0.795548</td><td style=\"text-align: right;\">     117.698  </td><td style=\"text-align: right;\"> 1691655561</td><td style=\"text-align: right;\">    0.911203</td><td style=\"text-align: right;\">    0.248624</td><td style=\"text-align: right;\">  1.5625e+14 </td><td style=\"text-align: right;\">  2.6091e+14 </td><td style=\"text-align: right;\">                 100</td><td>2d03179b  </td><td style=\"text-align: right;\">     0.428542</td><td style=\"text-align: right;\">     0.168326</td></tr>\n",
       "<tr><td>FSR_Trainable_32d31ca1</td><td>2023-08-10_16-40-40</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.67974</td><td style=\"text-align: right;\">   1447.31 </td><td style=\"text-align: right;\">     1.28051</td><td style=\"text-align: right;\"> 2.03379e+17</td><td style=\"text-align: right;\">21.0334  </td><td>172.26.215.93</td><td style=\"text-align: right;\">76214</td><td style=\"text-align: right;\">     2.4507 </td><td style=\"text-align: right;\">    1202.3  </td><td style=\"text-align: right;\">             4.83285</td><td style=\"text-align: right;\">          4.83285 </td><td style=\"text-align: right;\">       4.83285</td><td style=\"text-align: right;\"> 1691653240</td><td style=\"text-align: right;\">   14.0533  </td><td style=\"text-align: right;\">   12.0634  </td><td style=\"text-align: right;\">  7.70666e+15</td><td style=\"text-align: right;\">  8.94814e+15</td><td style=\"text-align: right;\">                   1</td><td>32d31ca1  </td><td style=\"text-align: right;\">     8.05382 </td><td style=\"text-align: right;\">    12.9796  </td></tr>\n",
       "<tr><td>FSR_Trainable_33be0461</td><td>2023-08-10_16-59-18</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.42584</td><td style=\"text-align: right;\">   1450.86 </td><td style=\"text-align: right;\">     1.39629</td><td style=\"text-align: right;\"> 1.4715e+18 </td><td style=\"text-align: right;\"> 0.850988</td><td>172.26.215.93</td><td style=\"text-align: right;\">84709</td><td style=\"text-align: right;\">     2.58801</td><td style=\"text-align: right;\">    1145.96 </td><td style=\"text-align: right;\">            14.2863 </td><td style=\"text-align: right;\">          3.26894 </td><td style=\"text-align: right;\">      14.2863 </td><td style=\"text-align: right;\"> 1691654358</td><td style=\"text-align: right;\">    1.08795 </td><td style=\"text-align: right;\">    0.504705</td><td style=\"text-align: right;\">  2.03495e+14</td><td style=\"text-align: right;\">  4.9781e+14 </td><td style=\"text-align: right;\">                   4</td><td>33be0461  </td><td style=\"text-align: right;\">     0.486069</td><td style=\"text-align: right;\">     0.364919</td></tr>\n",
       "<tr><td>FSR_Trainable_362152c3</td><td>2023-08-10_17-11-27</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.84352</td><td style=\"text-align: right;\">    687.128</td><td style=\"text-align: right;\">     1.22802</td><td style=\"text-align: right;\"> 5.94802e+17</td><td style=\"text-align: right;\"> 0.606584</td><td>172.26.215.93</td><td style=\"text-align: right;\">88031</td><td style=\"text-align: right;\">     2.35775</td><td style=\"text-align: right;\">     518.088</td><td style=\"text-align: right;\">           142.687  </td><td style=\"text-align: right;\">          1.41018 </td><td style=\"text-align: right;\">     142.687  </td><td style=\"text-align: right;\"> 1691655087</td><td style=\"text-align: right;\">    0.963553</td><td style=\"text-align: right;\">    0.262702</td><td style=\"text-align: right;\">  1.57708e+14</td><td style=\"text-align: right;\">  2.81466e+14</td><td style=\"text-align: right;\">                 100</td><td>362152c3  </td><td style=\"text-align: right;\">     0.43337 </td><td style=\"text-align: right;\">     0.173214</td></tr>\n",
       "<tr><td>FSR_Trainable_39c7ad9f</td><td>2023-08-10_17-18-36</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.54167</td><td style=\"text-align: right;\">    665.561</td><td style=\"text-align: right;\">     1.11697</td><td style=\"text-align: right;\"> 4.97453e+17</td><td style=\"text-align: right;\"> 0.597767</td><td>172.26.215.93</td><td style=\"text-align: right;\">90987</td><td style=\"text-align: right;\">     2.31281</td><td style=\"text-align: right;\">     519.272</td><td style=\"text-align: right;\">           141.786  </td><td style=\"text-align: right;\">          1.02218 </td><td style=\"text-align: right;\">     141.786  </td><td style=\"text-align: right;\"> 1691655516</td><td style=\"text-align: right;\">    0.911262</td><td style=\"text-align: right;\">    0.252711</td><td style=\"text-align: right;\">  1.53983e+14</td><td style=\"text-align: right;\">  2.43831e+14</td><td style=\"text-align: right;\">                 100</td><td>39c7ad9f  </td><td style=\"text-align: right;\">     0.426701</td><td style=\"text-align: right;\">     0.171067</td></tr>\n",
       "<tr><td>FSR_Trainable_3ba64bd6</td><td>2023-08-10_16-29-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.18571</td><td style=\"text-align: right;\">   1405.69 </td><td style=\"text-align: right;\">     1.21207</td><td style=\"text-align: right;\"> 6.46666e+15</td><td style=\"text-align: right;\">21.3625  </td><td>172.26.215.93</td><td style=\"text-align: right;\">66573</td><td style=\"text-align: right;\">     2.42137</td><td style=\"text-align: right;\">    1172.43 </td><td style=\"text-align: right;\">             7.32827</td><td style=\"text-align: right;\">          7.32827 </td><td style=\"text-align: right;\">       7.32827</td><td style=\"text-align: right;\"> 1691652549</td><td style=\"text-align: right;\">   12.0187  </td><td style=\"text-align: right;\">   10.8913  </td><td style=\"text-align: right;\">  1.12703e+15</td><td style=\"text-align: right;\">  2.68348e+14</td><td style=\"text-align: right;\">                   1</td><td>3ba64bd6  </td><td style=\"text-align: right;\">     7.79206 </td><td style=\"text-align: right;\">    13.5704  </td></tr>\n",
       "<tr><td>FSR_Trainable_3cac7c0f</td><td>2023-08-10_16-34-39</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.76522</td><td style=\"text-align: right;\">   1470.14 </td><td style=\"text-align: right;\">     1.42156</td><td style=\"text-align: right;\"> 1.7767e+18 </td><td style=\"text-align: right;\"> 0.857377</td><td>172.26.215.93</td><td style=\"text-align: right;\">73578</td><td style=\"text-align: right;\">     2.66796</td><td style=\"text-align: right;\">    1126.17 </td><td style=\"text-align: right;\">            45.6379 </td><td style=\"text-align: right;\">          2.60084 </td><td style=\"text-align: right;\">      45.6379 </td><td style=\"text-align: right;\"> 1691652879</td><td style=\"text-align: right;\">    1.13469 </td><td style=\"text-align: right;\">    0.503516</td><td style=\"text-align: right;\">  1.88486e+14</td><td style=\"text-align: right;\">  5.51993e+14</td><td style=\"text-align: right;\">                  16</td><td>3cac7c0f  </td><td style=\"text-align: right;\">     0.497672</td><td style=\"text-align: right;\">     0.359705</td></tr>\n",
       "<tr><td>FSR_Trainable_42211eeb</td><td>2023-08-10_17-19-58</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.63281</td><td style=\"text-align: right;\">    649.231</td><td style=\"text-align: right;\">     1.17697</td><td style=\"text-align: right;\"> 5.03518e+17</td><td style=\"text-align: right;\"> 0.601907</td><td>172.26.215.93</td><td style=\"text-align: right;\">92053</td><td style=\"text-align: right;\">     2.33824</td><td style=\"text-align: right;\">     512.542</td><td style=\"text-align: right;\">            67.7417 </td><td style=\"text-align: right;\">          0.515044</td><td style=\"text-align: right;\">      67.7417 </td><td style=\"text-align: right;\"> 1691655598</td><td style=\"text-align: right;\">    0.923174</td><td style=\"text-align: right;\">    0.250196</td><td style=\"text-align: right;\">  1.55256e+14</td><td style=\"text-align: right;\">  2.41514e+14</td><td style=\"text-align: right;\">                 100</td><td>42211eeb  </td><td style=\"text-align: right;\">     0.429163</td><td style=\"text-align: right;\">     0.172743</td></tr>\n",
       "<tr><td>FSR_Trainable_487e3dc8</td><td>2023-08-10_16-48-08</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.46755</td><td style=\"text-align: right;\">   1553.39 </td><td style=\"text-align: right;\">     1.24995</td><td style=\"text-align: right;\"> 2.39057e+18</td><td style=\"text-align: right;\"> 0.812735</td><td>172.26.215.93</td><td style=\"text-align: right;\">77850</td><td style=\"text-align: right;\">     2.44907</td><td style=\"text-align: right;\">    1107.8  </td><td style=\"text-align: right;\">           238.17   </td><td style=\"text-align: right;\">          4.82371 </td><td style=\"text-align: right;\">     238.17   </td><td style=\"text-align: right;\"> 1691653688</td><td style=\"text-align: right;\">    0.906874</td><td style=\"text-align: right;\">    0.545172</td><td style=\"text-align: right;\">  2.05563e+14</td><td style=\"text-align: right;\">  8.43434e+14</td><td style=\"text-align: right;\">                  64</td><td>487e3dc8  </td><td style=\"text-align: right;\">     0.462686</td><td style=\"text-align: right;\">     0.350049</td></tr>\n",
       "<tr><td>FSR_Trainable_4a2b16da</td><td>2023-08-10_16-34-57</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.46127</td><td style=\"text-align: right;\">   1453    </td><td style=\"text-align: right;\">     1.31771</td><td style=\"text-align: right;\"> 1.6498e+18 </td><td style=\"text-align: right;\"> 0.858181</td><td>172.26.215.93</td><td style=\"text-align: right;\">73762</td><td style=\"text-align: right;\">     2.66139</td><td style=\"text-align: right;\">    1124.86 </td><td style=\"text-align: right;\">            52.8494 </td><td style=\"text-align: right;\">          7.16638 </td><td style=\"text-align: right;\">      52.8494 </td><td style=\"text-align: right;\"> 1691652897</td><td style=\"text-align: right;\">    1.08223 </td><td style=\"text-align: right;\">    0.495058</td><td style=\"text-align: right;\">  1.77101e+14</td><td style=\"text-align: right;\">  4.76227e+14</td><td style=\"text-align: right;\">                   8</td><td>4a2b16da  </td><td style=\"text-align: right;\">     0.496018</td><td style=\"text-align: right;\">     0.362164</td></tr>\n",
       "<tr><td>FSR_Trainable_4d753b8c</td><td>2023-08-10_17-15-43</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.65392</td><td style=\"text-align: right;\">   1374.5  </td><td style=\"text-align: right;\">     1.24851</td><td style=\"text-align: right;\"> 1.90216e+17</td><td style=\"text-align: right;\">23.396   </td><td>172.26.215.93</td><td style=\"text-align: right;\">90758</td><td style=\"text-align: right;\">     2.44934</td><td style=\"text-align: right;\">    1094.46 </td><td style=\"text-align: right;\">             2.13544</td><td style=\"text-align: right;\">          2.13544 </td><td style=\"text-align: right;\">       2.13544</td><td style=\"text-align: right;\"> 1691655343</td><td style=\"text-align: right;\">   15.8325  </td><td style=\"text-align: right;\">   10.776   </td><td style=\"text-align: right;\">  6.38372e+15</td><td style=\"text-align: right;\">  8.11061e+15</td><td style=\"text-align: right;\">                   1</td><td>4d753b8c  </td><td style=\"text-align: right;\">    11.2374  </td><td style=\"text-align: right;\">    12.1586  </td></tr>\n",
       "<tr><td>FSR_Trainable_4e236230</td><td>2023-08-10_17-05-36</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.97698</td><td style=\"text-align: right;\">   1477.86 </td><td style=\"text-align: right;\">     1.3081 </td><td style=\"text-align: right;\"> 1.9821e+18 </td><td style=\"text-align: right;\"> 0.817877</td><td>172.26.215.93</td><td style=\"text-align: right;\">85979</td><td style=\"text-align: right;\">     2.48998</td><td style=\"text-align: right;\">    1098.41 </td><td style=\"text-align: right;\">           177.827  </td><td style=\"text-align: right;\">          4.69077 </td><td style=\"text-align: right;\">     177.827  </td><td style=\"text-align: right;\"> 1691654736</td><td style=\"text-align: right;\">    1.0044  </td><td style=\"text-align: right;\">    0.515591</td><td style=\"text-align: right;\">  2.06047e+14</td><td style=\"text-align: right;\">  6.84727e+14</td><td style=\"text-align: right;\">                  32</td><td>4e236230  </td><td style=\"text-align: right;\">     0.469055</td><td style=\"text-align: right;\">     0.348822</td></tr>\n",
       "<tr><td>FSR_Trainable_51c503cd</td><td>2023-08-10_17-08-07</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.74324</td><td style=\"text-align: right;\">    719.797</td><td style=\"text-align: right;\">     1.25262</td><td style=\"text-align: right;\"> 6.70267e+17</td><td style=\"text-align: right;\"> 0.616712</td><td>172.26.215.93</td><td style=\"text-align: right;\">86738</td><td style=\"text-align: right;\">     2.3567 </td><td style=\"text-align: right;\">     519.088</td><td style=\"text-align: right;\">           140.51   </td><td style=\"text-align: right;\">          1.38039 </td><td style=\"text-align: right;\">     140.51   </td><td style=\"text-align: right;\"> 1691654887</td><td style=\"text-align: right;\">    0.95234 </td><td style=\"text-align: right;\">    0.274936</td><td style=\"text-align: right;\">  1.69985e+14</td><td style=\"text-align: right;\">  2.96122e+14</td><td style=\"text-align: right;\">                 100</td><td>51c503cd  </td><td style=\"text-align: right;\">     0.436556</td><td style=\"text-align: right;\">     0.180156</td></tr>\n",
       "<tr><td>FSR_Trainable_5525c5fb</td><td>2023-08-10_16-43-27</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.95632</td><td style=\"text-align: right;\">   1356.18 </td><td style=\"text-align: right;\">     1.34222</td><td style=\"text-align: right;\"> 2.01332e+17</td><td style=\"text-align: right;\">20.739   </td><td>172.26.215.93</td><td style=\"text-align: right;\">77362</td><td style=\"text-align: right;\">     2.49746</td><td style=\"text-align: right;\">    1105.39 </td><td style=\"text-align: right;\">             3.38925</td><td style=\"text-align: right;\">          3.38925 </td><td style=\"text-align: right;\">       3.38925</td><td style=\"text-align: right;\"> 1691653407</td><td style=\"text-align: right;\">   15.2495  </td><td style=\"text-align: right;\">   11.0502  </td><td style=\"text-align: right;\">  1.0833e+16 </td><td style=\"text-align: right;\">  8.52675e+15</td><td style=\"text-align: right;\">                   1</td><td>5525c5fb  </td><td style=\"text-align: right;\">     8.45413 </td><td style=\"text-align: right;\">    12.2849  </td></tr>\n",
       "<tr><td>FSR_Trainable_555dffc9</td><td>2023-08-10_16-32-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.61839</td><td style=\"text-align: right;\">   1498.58 </td><td style=\"text-align: right;\">     1.28315</td><td style=\"text-align: right;\"> 2.04202e+18</td><td style=\"text-align: right;\"> 0.85225 </td><td>172.26.215.93</td><td style=\"text-align: right;\">71477</td><td style=\"text-align: right;\">     2.69716</td><td style=\"text-align: right;\">    1109.72 </td><td style=\"text-align: right;\">            28.2826 </td><td style=\"text-align: right;\">          3.39699 </td><td style=\"text-align: right;\">      28.2826 </td><td style=\"text-align: right;\"> 1691652720</td><td style=\"text-align: right;\">    1.12506 </td><td style=\"text-align: right;\">    0.51828 </td><td style=\"text-align: right;\">  1.71457e+14</td><td style=\"text-align: right;\">  6.79028e+14</td><td style=\"text-align: right;\">                   8</td><td>555dffc9  </td><td style=\"text-align: right;\">     0.499877</td><td style=\"text-align: right;\">     0.352373</td></tr>\n",
       "<tr><td>FSR_Trainable_597b75f1</td><td>2023-08-10_16-30-44</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.97712</td><td style=\"text-align: right;\">   1486.63 </td><td style=\"text-align: right;\">     1.28824</td><td style=\"text-align: right;\"> 7.08399e+15</td><td style=\"text-align: right;\">25.1352  </td><td>172.26.215.93</td><td style=\"text-align: right;\">70572</td><td style=\"text-align: right;\">     2.525  </td><td style=\"text-align: right;\">    1167.81 </td><td style=\"text-align: right;\">             5.93979</td><td style=\"text-align: right;\">          5.93979 </td><td style=\"text-align: right;\">       5.93979</td><td style=\"text-align: right;\"> 1691652644</td><td style=\"text-align: right;\">   16.2057  </td><td style=\"text-align: right;\">   11.0778  </td><td style=\"text-align: right;\">  6.45815e+15</td><td style=\"text-align: right;\">  5.90542e+14</td><td style=\"text-align: right;\">                   1</td><td>597b75f1  </td><td style=\"text-align: right;\">    11.5391  </td><td style=\"text-align: right;\">    13.5961  </td></tr>\n",
       "<tr><td>FSR_Trainable_5d8ca6cc</td><td>2023-08-10_16-41-01</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.7695 </td><td style=\"text-align: right;\">   1520.58 </td><td style=\"text-align: right;\">     1.28127</td><td style=\"text-align: right;\"> 2.18232e+18</td><td style=\"text-align: right;\"> 0.816479</td><td>172.26.215.93</td><td style=\"text-align: right;\">75949</td><td style=\"text-align: right;\">     2.46772</td><td style=\"text-align: right;\">    1110.62 </td><td style=\"text-align: right;\">           111.099  </td><td style=\"text-align: right;\">          4.08137 </td><td style=\"text-align: right;\">     111.099  </td><td style=\"text-align: right;\"> 1691653261</td><td style=\"text-align: right;\">    0.962839</td><td style=\"text-align: right;\">    0.529316</td><td style=\"text-align: right;\">  2.06496e+14</td><td style=\"text-align: right;\">  7.46988e+14</td><td style=\"text-align: right;\">                  32</td><td>5d8ca6cc  </td><td style=\"text-align: right;\">     0.464552</td><td style=\"text-align: right;\">     0.351927</td></tr>\n",
       "<tr><td>FSR_Trainable_618f8440</td><td>2023-08-10_16-58-37</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    7.24629</td><td style=\"text-align: right;\">   1558.75 </td><td style=\"text-align: right;\">     1.46955</td><td style=\"text-align: right;\"> 1.82343e+18</td><td style=\"text-align: right;\"> 0.931928</td><td>172.26.215.93</td><td style=\"text-align: right;\">84282</td><td style=\"text-align: right;\">     2.95136</td><td style=\"text-align: right;\">    1165.75 </td><td style=\"text-align: right;\">             6.67636</td><td style=\"text-align: right;\">          6.67636 </td><td style=\"text-align: right;\">       6.67636</td><td style=\"text-align: right;\"> 1691654317</td><td style=\"text-align: right;\">    1.47425 </td><td style=\"text-align: right;\">    0.569775</td><td style=\"text-align: right;\">  1.96072e+14</td><td style=\"text-align: right;\">  7.60619e+14</td><td style=\"text-align: right;\">                   1</td><td>618f8440  </td><td style=\"text-align: right;\">     0.561899</td><td style=\"text-align: right;\">     0.370029</td></tr>\n",
       "<tr><td>FSR_Trainable_62726c18</td><td>2023-08-10_16-30-14</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    4.31223</td><td style=\"text-align: right;\">   1105.71 </td><td style=\"text-align: right;\">     1.18048</td><td style=\"text-align: right;\"> 2.64397e+09</td><td style=\"text-align: right;\"> 5.43766 </td><td>172.26.215.93</td><td style=\"text-align: right;\">69905</td><td style=\"text-align: right;\">     2.39201</td><td style=\"text-align: right;\">     868.752</td><td style=\"text-align: right;\">             5.03376</td><td style=\"text-align: right;\">          2.19874 </td><td style=\"text-align: right;\">       5.03376</td><td style=\"text-align: right;\"> 1691652614</td><td style=\"text-align: right;\">    6.8272  </td><td style=\"text-align: right;\">    2.84674 </td><td style=\"text-align: right;\"> 26.929      </td><td style=\"text-align: right;\"> 13.3316     </td><td style=\"text-align: right;\">                   2</td><td>62726c18  </td><td style=\"text-align: right;\">     3.43344 </td><td style=\"text-align: right;\">     2.00422 </td></tr>\n",
       "<tr><td>FSR_Trainable_62905e3e</td><td>2023-08-10_16-38-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    5.63964</td><td style=\"text-align: right;\">   1449.33 </td><td style=\"text-align: right;\">     1.35404</td><td style=\"text-align: right;\"> 1.52697e+18</td><td style=\"text-align: right;\"> 0.853892</td><td>172.26.215.93</td><td style=\"text-align: right;\">74901</td><td style=\"text-align: right;\">     2.61885</td><td style=\"text-align: right;\">    1136.68 </td><td style=\"text-align: right;\">           198.329  </td><td style=\"text-align: right;\">          5.59449 </td><td style=\"text-align: right;\">     198.329  </td><td style=\"text-align: right;\"> 1691653133</td><td style=\"text-align: right;\">    1.12873 </td><td style=\"text-align: right;\">    0.500953</td><td style=\"text-align: right;\">  1.75622e+14</td><td style=\"text-align: right;\">  4.9108e+14 </td><td style=\"text-align: right;\">                  32</td><td>62905e3e  </td><td style=\"text-align: right;\">     0.490464</td><td style=\"text-align: right;\">     0.363427</td></tr>\n",
       "<tr><td>FSR_Trainable_68a03a62</td><td>2023-08-10_16-55-36</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.54054</td><td style=\"text-align: right;\">   1540.2  </td><td style=\"text-align: right;\">     1.25274</td><td style=\"text-align: right;\"> 2.30426e+18</td><td style=\"text-align: right;\"> 0.812076</td><td>172.26.215.93</td><td style=\"text-align: right;\">81426</td><td style=\"text-align: right;\">     2.44567</td><td style=\"text-align: right;\">    1109.29 </td><td style=\"text-align: right;\">           210.303  </td><td style=\"text-align: right;\">          2.8035  </td><td style=\"text-align: right;\">     210.303  </td><td style=\"text-align: right;\"> 1691654136</td><td style=\"text-align: right;\">    0.918304</td><td style=\"text-align: right;\">    0.539399</td><td style=\"text-align: right;\">  2.04651e+14</td><td style=\"text-align: right;\">  8.07412e+14</td><td style=\"text-align: right;\">                  64</td><td>68a03a62  </td><td style=\"text-align: right;\">     0.461085</td><td style=\"text-align: right;\">     0.350991</td></tr>\n",
       "<tr><td>FSR_Trainable_6ad6b355</td><td>2023-08-10_16-52-39</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.81211</td><td style=\"text-align: right;\">   1518.61 </td><td style=\"text-align: right;\">     1.28504</td><td style=\"text-align: right;\"> 2.15454e+18</td><td style=\"text-align: right;\"> 0.820432</td><td>172.26.215.93</td><td style=\"text-align: right;\">80876</td><td style=\"text-align: right;\">     2.48097</td><td style=\"text-align: right;\">    1113.75 </td><td style=\"text-align: right;\">           128.035  </td><td style=\"text-align: right;\">          4.0618  </td><td style=\"text-align: right;\">     128.035  </td><td style=\"text-align: right;\"> 1691653959</td><td style=\"text-align: right;\">    0.971761</td><td style=\"text-align: right;\">    0.529105</td><td style=\"text-align: right;\">  2.04713e+14</td><td style=\"text-align: right;\">  7.39493e+14</td><td style=\"text-align: right;\">                  32</td><td>6ad6b355  </td><td style=\"text-align: right;\">     0.467407</td><td style=\"text-align: right;\">     0.353025</td></tr>\n",
       "<tr><td>FSR_Trainable_6b89ee81</td><td>2023-08-10_17-15-03</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.44362</td><td style=\"text-align: right;\">   1061.1  </td><td style=\"text-align: right;\">     1.24863</td><td style=\"text-align: right;\"> 2.4868e+09 </td><td style=\"text-align: right;\"> 5.45607 </td><td>172.26.215.93</td><td style=\"text-align: right;\">90288</td><td style=\"text-align: right;\">     2.44508</td><td style=\"text-align: right;\">     826.237</td><td style=\"text-align: right;\">             1.6773 </td><td style=\"text-align: right;\">          1.6773  </td><td style=\"text-align: right;\">       1.6773 </td><td style=\"text-align: right;\"> 1691655303</td><td style=\"text-align: right;\">    6.99202 </td><td style=\"text-align: right;\">    2.74406 </td><td style=\"text-align: right;\"> 33.6531     </td><td style=\"text-align: right;\"> 12.5179     </td><td style=\"text-align: right;\">                   1</td><td>6b89ee81  </td><td style=\"text-align: right;\">     3.46896 </td><td style=\"text-align: right;\">     1.98711 </td></tr>\n",
       "<tr><td>FSR_Trainable_718568fc</td><td>2023-08-10_16-49-44</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.50555</td><td style=\"text-align: right;\">   1418.2  </td><td style=\"text-align: right;\">     1.26895</td><td style=\"text-align: right;\"> 1.91559e+16</td><td style=\"text-align: right;\">21.3013  </td><td>172.26.215.93</td><td style=\"text-align: right;\">80203</td><td style=\"text-align: right;\">     2.4479 </td><td style=\"text-align: right;\">    1146.8  </td><td style=\"text-align: right;\">             3.06246</td><td style=\"text-align: right;\">          3.06246 </td><td style=\"text-align: right;\">       3.06246</td><td style=\"text-align: right;\"> 1691653784</td><td style=\"text-align: right;\">   12.5709  </td><td style=\"text-align: right;\">   11.0467  </td><td style=\"text-align: right;\">  3.74987e+15</td><td style=\"text-align: right;\">  1.5537e+15 </td><td style=\"text-align: right;\">                   1</td><td>718568fc  </td><td style=\"text-align: right;\">     7.81545 </td><td style=\"text-align: right;\">    13.4859  </td></tr>\n",
       "<tr><td>FSR_Trainable_7da0f427</td><td>2023-08-10_16-57-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.41465</td><td style=\"text-align: right;\">   1453.59 </td><td style=\"text-align: right;\">     1.33589</td><td style=\"text-align: right;\"> 1.61621e+18</td><td style=\"text-align: right;\"> 0.84701 </td><td>172.26.215.93</td><td style=\"text-align: right;\">83090</td><td style=\"text-align: right;\">     2.59403</td><td style=\"text-align: right;\">    1130.23 </td><td style=\"text-align: right;\">            48.2915 </td><td style=\"text-align: right;\">          7.36827 </td><td style=\"text-align: right;\">      48.2915 </td><td style=\"text-align: right;\"> 1691654254</td><td style=\"text-align: right;\">    1.09252 </td><td style=\"text-align: right;\">    0.501068</td><td style=\"text-align: right;\">  2.02655e+14</td><td style=\"text-align: right;\">  5.15531e+14</td><td style=\"text-align: right;\">                   8</td><td>7da0f427  </td><td style=\"text-align: right;\">     0.485979</td><td style=\"text-align: right;\">     0.361031</td></tr>\n",
       "<tr><td>FSR_Trainable_7f028035</td><td>2023-08-10_17-14-24</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.5232 </td><td style=\"text-align: right;\">    629.654</td><td style=\"text-align: right;\">     1.15619</td><td style=\"text-align: right;\"> 5.08906e+17</td><td style=\"text-align: right;\"> 0.596824</td><td>172.26.215.93</td><td style=\"text-align: right;\">89030</td><td style=\"text-align: right;\">     2.329  </td><td style=\"text-align: right;\">     486.408</td><td style=\"text-align: right;\">           141.991  </td><td style=\"text-align: right;\">          1.30216 </td><td style=\"text-align: right;\">     141.991  </td><td style=\"text-align: right;\"> 1691655264</td><td style=\"text-align: right;\">    0.908462</td><td style=\"text-align: right;\">    0.244966</td><td style=\"text-align: right;\">  1.62962e+14</td><td style=\"text-align: right;\">  2.47784e+14</td><td style=\"text-align: right;\">                 100</td><td>7f028035  </td><td style=\"text-align: right;\">     0.428939</td><td style=\"text-align: right;\">     0.167885</td></tr>\n",
       "<tr><td>FSR_Trainable_804d9d8b</td><td>2023-08-10_16-34-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.71936</td><td style=\"text-align: right;\">   1466.55 </td><td style=\"text-align: right;\">     1.42704</td><td style=\"text-align: right;\"> 1.75013e+18</td><td style=\"text-align: right;\"> 0.849197</td><td>172.26.215.93</td><td style=\"text-align: right;\">73348</td><td style=\"text-align: right;\">     2.63547</td><td style=\"text-align: right;\">    1125.68 </td><td style=\"text-align: right;\">            57.6707 </td><td style=\"text-align: right;\">          3.63426 </td><td style=\"text-align: right;\">      57.6707 </td><td style=\"text-align: right;\"> 1691652868</td><td style=\"text-align: right;\">    1.11883 </td><td style=\"text-align: right;\">    0.50321 </td><td style=\"text-align: right;\">  1.81202e+14</td><td style=\"text-align: right;\">  5.50924e+14</td><td style=\"text-align: right;\">                  16</td><td>804d9d8b  </td><td style=\"text-align: right;\">     0.489703</td><td style=\"text-align: right;\">     0.359494</td></tr>\n",
       "<tr><td>FSR_Trainable_80b63509</td><td>2023-08-10_17-01-10</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.2848 </td><td style=\"text-align: right;\">   1565.57 </td><td style=\"text-align: right;\">     1.22902</td><td style=\"text-align: right;\"> 2.45838e+18</td><td style=\"text-align: right;\"> 0.806114</td><td>172.26.215.93</td><td style=\"text-align: right;\">83534</td><td style=\"text-align: right;\">     2.42426</td><td style=\"text-align: right;\">    1105.02 </td><td style=\"text-align: right;\">           225.58   </td><td style=\"text-align: right;\">          3.35686 </td><td style=\"text-align: right;\">     225.58   </td><td style=\"text-align: right;\"> 1691654470</td><td style=\"text-align: right;\">    0.869683</td><td style=\"text-align: right;\">    0.551129</td><td style=\"text-align: right;\">  2.04835e+14</td><td style=\"text-align: right;\">  8.77092e+14</td><td style=\"text-align: right;\">                  64</td><td>80b63509  </td><td style=\"text-align: right;\">     0.457183</td><td style=\"text-align: right;\">     0.348931</td></tr>\n",
       "<tr><td>FSR_Trainable_828fa7f4</td><td>2023-08-10_17-07-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.66778</td><td style=\"text-align: right;\">    716.372</td><td style=\"text-align: right;\">     1.2625 </td><td style=\"text-align: right;\"> 5.17152e+17</td><td style=\"text-align: right;\"> 0.627676</td><td>172.26.215.93</td><td style=\"text-align: right;\">86250</td><td style=\"text-align: right;\">     2.35242</td><td style=\"text-align: right;\">     556.183</td><td style=\"text-align: right;\">           180.226  </td><td style=\"text-align: right;\">          1.77376 </td><td style=\"text-align: right;\">     180.226  </td><td style=\"text-align: right;\"> 1691654820</td><td style=\"text-align: right;\">    0.940048</td><td style=\"text-align: right;\">    0.27512 </td><td style=\"text-align: right;\">  1.8994e+14 </td><td style=\"text-align: right;\">  2.40363e+14</td><td style=\"text-align: right;\">                 100</td><td>828fa7f4  </td><td style=\"text-align: right;\">     0.434795</td><td style=\"text-align: right;\">     0.192881</td></tr>\n",
       "<tr><td>FSR_Trainable_8307b7bd</td><td>2023-08-10_16-34-56</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    7.3456 </td><td style=\"text-align: right;\">   1563.88 </td><td style=\"text-align: right;\">     1.47464</td><td style=\"text-align: right;\"> 1.92747e+18</td><td style=\"text-align: right;\"> 0.965129</td><td>172.26.215.93</td><td style=\"text-align: right;\">74224</td><td style=\"text-align: right;\">     3.06343</td><td style=\"text-align: right;\">    1146.63 </td><td style=\"text-align: right;\">             3.07429</td><td style=\"text-align: right;\">          3.07429 </td><td style=\"text-align: right;\">       3.07429</td><td style=\"text-align: right;\"> 1691652896</td><td style=\"text-align: right;\">    1.531   </td><td style=\"text-align: right;\">    0.568943</td><td style=\"text-align: right;\">  1.79457e+14</td><td style=\"text-align: right;\">  7.22256e+14</td><td style=\"text-align: right;\">                   1</td><td>8307b7bd  </td><td style=\"text-align: right;\">     0.592355</td><td style=\"text-align: right;\">     0.372774</td></tr>\n",
       "<tr><td>FSR_Trainable_862b96c2</td><td>2023-08-10_16-52-14</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.6631 </td><td style=\"text-align: right;\">   1532.49 </td><td style=\"text-align: right;\">     1.27072</td><td style=\"text-align: right;\"> 2.25591e+18</td><td style=\"text-align: right;\"> 0.813652</td><td>172.26.215.93</td><td style=\"text-align: right;\">78990</td><td style=\"text-align: right;\">     2.45518</td><td style=\"text-align: right;\">    1110.37 </td><td style=\"text-align: right;\">           350.48   </td><td style=\"text-align: right;\">          4.9994  </td><td style=\"text-align: right;\">     350.48   </td><td style=\"text-align: right;\"> 1691653934</td><td style=\"text-align: right;\">    0.941431</td><td style=\"text-align: right;\">    0.536359</td><td style=\"text-align: right;\">  2.05073e+14</td><td style=\"text-align: right;\">  7.90023e+14</td><td style=\"text-align: right;\">                  64</td><td>862b96c2  </td><td style=\"text-align: right;\">     0.462315</td><td style=\"text-align: right;\">     0.351337</td></tr>\n",
       "<tr><td>FSR_Trainable_864eebf1</td><td>2023-08-10_16-33-44</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.78116</td><td style=\"text-align: right;\">   1461.43 </td><td style=\"text-align: right;\">     1.39888</td><td style=\"text-align: right;\"> 1.72882e+18</td><td style=\"text-align: right;\"> 0.859039</td><td>172.26.215.93</td><td style=\"text-align: right;\">72846</td><td style=\"text-align: right;\">     2.65031</td><td style=\"text-align: right;\">    1126.28 </td><td style=\"text-align: right;\">            45.9994 </td><td style=\"text-align: right;\">          6.46784 </td><td style=\"text-align: right;\">      45.9994 </td><td style=\"text-align: right;\"> 1691652824</td><td style=\"text-align: right;\">    1.16256 </td><td style=\"text-align: right;\">    0.49643 </td><td style=\"text-align: right;\">  1.684e+14  </td><td style=\"text-align: right;\">  5.02999e+14</td><td style=\"text-align: right;\">                   8</td><td>864eebf1  </td><td style=\"text-align: right;\">     0.497668</td><td style=\"text-align: right;\">     0.361371</td></tr>\n",
       "<tr><td>FSR_Trainable_874461c8</td><td>2023-08-10_17-13-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.65237</td><td style=\"text-align: right;\">    654.877</td><td style=\"text-align: right;\">     1.16233</td><td style=\"text-align: right;\"> 6.10257e+17</td><td style=\"text-align: right;\"> 0.601127</td><td>172.26.215.93</td><td style=\"text-align: right;\">88367</td><td style=\"text-align: right;\">     2.3503 </td><td style=\"text-align: right;\">     492.268</td><td style=\"text-align: right;\">           140.992  </td><td style=\"text-align: right;\">          1.15233 </td><td style=\"text-align: right;\">     140.992  </td><td style=\"text-align: right;\"> 1691655218</td><td style=\"text-align: right;\">    0.937994</td><td style=\"text-align: right;\">    0.252288</td><td style=\"text-align: right;\">  1.60704e+14</td><td style=\"text-align: right;\">  2.79263e+14</td><td style=\"text-align: right;\">                 100</td><td>874461c8  </td><td style=\"text-align: right;\">     0.43331 </td><td style=\"text-align: right;\">     0.167817</td></tr>\n",
       "<tr><td>FSR_Trainable_8cc0bbd7</td><td>2023-08-10_16-35-41</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.69787</td><td style=\"text-align: right;\">   1461.3  </td><td style=\"text-align: right;\">     1.4249 </td><td style=\"text-align: right;\"> 1.73834e+18</td><td style=\"text-align: right;\"> 0.857818</td><td>172.26.215.93</td><td style=\"text-align: right;\">74046</td><td style=\"text-align: right;\">     2.67248</td><td style=\"text-align: right;\">    1125.9  </td><td style=\"text-align: right;\">            54.6598 </td><td style=\"text-align: right;\">          3.13814 </td><td style=\"text-align: right;\">      54.6598 </td><td style=\"text-align: right;\"> 1691652941</td><td style=\"text-align: right;\">    1.11694 </td><td style=\"text-align: right;\">    0.49805 </td><td style=\"text-align: right;\">  1.87917e+14</td><td style=\"text-align: right;\">  5.17588e+14</td><td style=\"text-align: right;\">                  16</td><td>8cc0bbd7  </td><td style=\"text-align: right;\">     0.497252</td><td style=\"text-align: right;\">     0.360565</td></tr>\n",
       "<tr><td>FSR_Trainable_8ce7ea94</td><td>2023-08-10_16-56-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   13.1677 </td><td style=\"text-align: right;\">   1665.26 </td><td style=\"text-align: right;\">     2.26635</td><td style=\"text-align: right;\"> 2.01632e+18</td><td style=\"text-align: right;\"> 1.29513 </td><td>172.26.215.93</td><td style=\"text-align: right;\">82659</td><td style=\"text-align: right;\">     4.59625</td><td style=\"text-align: right;\">    1187.44 </td><td style=\"text-align: right;\">             7.9093 </td><td style=\"text-align: right;\">          7.9093  </td><td style=\"text-align: right;\">       7.9093 </td><td style=\"text-align: right;\"> 1691654160</td><td style=\"text-align: right;\">    2.73937 </td><td style=\"text-align: right;\">    0.599896</td><td style=\"text-align: right;\">  1.04602e+14</td><td style=\"text-align: right;\">  7.75097e+14</td><td style=\"text-align: right;\">                   1</td><td>8ce7ea94  </td><td style=\"text-align: right;\">     0.913839</td><td style=\"text-align: right;\">     0.381289</td></tr>\n",
       "<tr><td>FSR_Trainable_91f47775</td><td>2023-08-10_16-30-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.84299</td><td style=\"text-align: right;\">   1631.03 </td><td style=\"text-align: right;\">     1.4366 </td><td style=\"text-align: right;\"> 3.79258e+09</td><td style=\"text-align: right;\"> 6.14125 </td><td>172.26.215.93</td><td style=\"text-align: right;\">70800</td><td style=\"text-align: right;\">     2.47189</td><td style=\"text-align: right;\">    1115    </td><td style=\"text-align: right;\">             2.79443</td><td style=\"text-align: right;\">          2.79443 </td><td style=\"text-align: right;\">       2.79443</td><td style=\"text-align: right;\"> 1691652653</td><td style=\"text-align: right;\">    7.69214 </td><td style=\"text-align: right;\">    4.17672 </td><td style=\"text-align: right;\">  3.15224e+15</td><td style=\"text-align: right;\"> 10.193      </td><td style=\"text-align: right;\">                   1</td><td>91f47775  </td><td style=\"text-align: right;\">     3.60556 </td><td style=\"text-align: right;\">     2.53569 </td></tr>\n",
       "<tr><td>FSR_Trainable_943a5e4a</td><td>2023-08-10_17-18-41</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.49188</td><td style=\"text-align: right;\">    642.451</td><td style=\"text-align: right;\">     1.11854</td><td style=\"text-align: right;\"> 5.01076e+17</td><td style=\"text-align: right;\"> 0.597958</td><td>172.26.215.93</td><td style=\"text-align: right;\">91224</td><td style=\"text-align: right;\">     2.32137</td><td style=\"text-align: right;\">     499.02 </td><td style=\"text-align: right;\">           134.235  </td><td style=\"text-align: right;\">          1.03982 </td><td style=\"text-align: right;\">     134.235  </td><td style=\"text-align: right;\"> 1691655521</td><td style=\"text-align: right;\">    0.896841</td><td style=\"text-align: right;\">    0.248982</td><td style=\"text-align: right;\">  1.53605e+14</td><td style=\"text-align: right;\">  2.41921e+14</td><td style=\"text-align: right;\">                 100</td><td>943a5e4a  </td><td style=\"text-align: right;\">     0.426601</td><td style=\"text-align: right;\">     0.171357</td></tr>\n",
       "<tr><td>FSR_Trainable_95ce9ecd</td><td>2023-08-10_16-45-36</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    5.19394</td><td style=\"text-align: right;\">   1469.47 </td><td style=\"text-align: right;\">     1.34307</td><td style=\"text-align: right;\"> 1.80814e+18</td><td style=\"text-align: right;\"> 0.831578</td><td>172.26.215.93</td><td style=\"text-align: right;\">77185</td><td style=\"text-align: right;\">     2.53227</td><td style=\"text-align: right;\">    1120.23 </td><td style=\"text-align: right;\">           138.325  </td><td style=\"text-align: right;\">          4.32615 </td><td style=\"text-align: right;\">     138.325  </td><td style=\"text-align: right;\"> 1691653536</td><td style=\"text-align: right;\">    1.0415  </td><td style=\"text-align: right;\">    0.506464</td><td style=\"text-align: right;\">  2.052e+14  </td><td style=\"text-align: right;\">  5.86574e+14</td><td style=\"text-align: right;\">                  32</td><td>95ce9ecd  </td><td style=\"text-align: right;\">     0.474732</td><td style=\"text-align: right;\">     0.356846</td></tr>\n",
       "<tr><td>FSR_Trainable_9a8207c4</td><td>2023-08-10_16-59-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.46825</td><td style=\"text-align: right;\">   1452.76 </td><td style=\"text-align: right;\">     1.40399</td><td style=\"text-align: right;\"> 1.53313e+18</td><td style=\"text-align: right;\"> 0.84912 </td><td>172.26.215.93</td><td style=\"text-align: right;\">84925</td><td style=\"text-align: right;\">     2.59131</td><td style=\"text-align: right;\">    1137.78 </td><td style=\"text-align: right;\">            11.9382 </td><td style=\"text-align: right;\">          2.49234 </td><td style=\"text-align: right;\">      11.9382 </td><td style=\"text-align: right;\"> 1691654374</td><td style=\"text-align: right;\">    1.09931 </td><td style=\"text-align: right;\">    0.503219</td><td style=\"text-align: right;\">  1.99871e+14</td><td style=\"text-align: right;\">  5.04615e+14</td><td style=\"text-align: right;\">                   4</td><td>9a8207c4  </td><td style=\"text-align: right;\">     0.486104</td><td style=\"text-align: right;\">     0.363016</td></tr>\n",
       "<tr><td>FSR_Trainable_9c5e27f9</td><td>2023-08-10_16-30-37</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    4.41195</td><td style=\"text-align: right;\">    922.191</td><td style=\"text-align: right;\">     1.23855</td><td style=\"text-align: right;\"> 8.07567e+08</td><td style=\"text-align: right;\"> 5.23026 </td><td>172.26.215.93</td><td style=\"text-align: right;\">70359</td><td style=\"text-align: right;\">     2.34542</td><td style=\"text-align: right;\">     727.689</td><td style=\"text-align: right;\">             7.39056</td><td style=\"text-align: right;\">          1.65899 </td><td style=\"text-align: right;\">       7.39056</td><td style=\"text-align: right;\"> 1691652637</td><td style=\"text-align: right;\">    7.12585 </td><td style=\"text-align: right;\">    2.46748 </td><td style=\"text-align: right;\">  2.69475e+15</td><td style=\"text-align: right;\"> 13.9591     </td><td style=\"text-align: right;\">                   4</td><td>9c5e27f9  </td><td style=\"text-align: right;\">     3.42473 </td><td style=\"text-align: right;\">     1.80553 </td></tr>\n",
       "<tr><td>FSR_Trainable_a0f0109f</td><td>2023-08-10_16-56-40</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.2845 </td><td style=\"text-align: right;\">   1462.06 </td><td style=\"text-align: right;\">     1.34942</td><td style=\"text-align: right;\"> 1.78503e+18</td><td style=\"text-align: right;\"> 0.835207</td><td>172.26.215.93</td><td style=\"text-align: right;\">82401</td><td style=\"text-align: right;\">     2.55035</td><td style=\"text-align: right;\">    1118.69 </td><td style=\"text-align: right;\">           104.741  </td><td style=\"text-align: right;\">          6.28758 </td><td style=\"text-align: right;\">     104.741  </td><td style=\"text-align: right;\"> 1691654200</td><td style=\"text-align: right;\">    1.05947 </td><td style=\"text-align: right;\">    0.505893</td><td style=\"text-align: right;\">  2.05627e+14</td><td style=\"text-align: right;\">  5.84214e+14</td><td style=\"text-align: right;\">                  16</td><td>a0f0109f  </td><td style=\"text-align: right;\">     0.478716</td><td style=\"text-align: right;\">     0.356491</td></tr>\n",
       "<tr><td>FSR_Trainable_a4b78468</td><td>2023-08-10_16-58-37</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.03702</td><td style=\"text-align: right;\">   1434.37 </td><td style=\"text-align: right;\">     1.36104</td><td style=\"text-align: right;\"> 1.29413e+18</td><td style=\"text-align: right;\"> 0.843895</td><td>172.26.215.93</td><td style=\"text-align: right;\">83820</td><td style=\"text-align: right;\">     2.53555</td><td style=\"text-align: right;\">    1159.78 </td><td style=\"text-align: right;\">            42.4619 </td><td style=\"text-align: right;\">          6.13543 </td><td style=\"text-align: right;\">      42.4619 </td><td style=\"text-align: right;\"> 1691654317</td><td style=\"text-align: right;\">    1.00674 </td><td style=\"text-align: right;\">    0.4959  </td><td style=\"text-align: right;\">  2.02152e+14</td><td style=\"text-align: right;\">  4.30415e+14</td><td style=\"text-align: right;\">                   8</td><td>a4b78468  </td><td style=\"text-align: right;\">     0.475916</td><td style=\"text-align: right;\">     0.367979</td></tr>\n",
       "<tr><td>FSR_Trainable_a50448be</td><td>2023-08-10_17-17-14</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.69561</td><td style=\"text-align: right;\">    672.623</td><td style=\"text-align: right;\">     1.15704</td><td style=\"text-align: right;\"> 5.6269e+17 </td><td style=\"text-align: right;\"> 0.611461</td><td>172.26.215.93</td><td style=\"text-align: right;\">89824</td><td style=\"text-align: right;\">     2.37217</td><td style=\"text-align: right;\">     507.38 </td><td style=\"text-align: right;\">           148.164  </td><td style=\"text-align: right;\">          1.73738 </td><td style=\"text-align: right;\">     148.164  </td><td style=\"text-align: right;\"> 1691655434</td><td style=\"text-align: right;\">    0.942804</td><td style=\"text-align: right;\">    0.257181</td><td style=\"text-align: right;\">  1.64216e+14</td><td style=\"text-align: right;\">  2.59633e+14</td><td style=\"text-align: right;\">                 100</td><td>a50448be  </td><td style=\"text-align: right;\">     0.438803</td><td style=\"text-align: right;\">     0.172658</td></tr>\n",
       "<tr><td>FSR_Trainable_a7daa42d</td><td>2023-08-10_16-41-18</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.85246</td><td style=\"text-align: right;\">   1511.91 </td><td style=\"text-align: right;\">     1.29175</td><td style=\"text-align: right;\"> 2.11491e+18</td><td style=\"text-align: right;\"> 0.820007</td><td>172.26.215.93</td><td style=\"text-align: right;\">75690</td><td style=\"text-align: right;\">     2.48447</td><td style=\"text-align: right;\">    1111.94 </td><td style=\"text-align: right;\">           197.223  </td><td style=\"text-align: right;\">          6.84404 </td><td style=\"text-align: right;\">     197.223  </td><td style=\"text-align: right;\"> 1691653278</td><td style=\"text-align: right;\">    0.979175</td><td style=\"text-align: right;\">    0.526788</td><td style=\"text-align: right;\">  2.0448e+14 </td><td style=\"text-align: right;\">  7.27299e+14</td><td style=\"text-align: right;\">                  32</td><td>a7daa42d  </td><td style=\"text-align: right;\">     0.467509</td><td style=\"text-align: right;\">     0.352498</td></tr>\n",
       "<tr><td>FSR_Trainable_ab8af723</td><td>2023-08-10_16-57-40</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.0764 </td><td style=\"text-align: right;\">   1434.13 </td><td style=\"text-align: right;\">     1.36459</td><td style=\"text-align: right;\"> 1.26811e+18</td><td style=\"text-align: right;\"> 0.844503</td><td>172.26.215.93</td><td style=\"text-align: right;\">83314</td><td style=\"text-align: right;\">     2.53522</td><td style=\"text-align: right;\">    1163.68 </td><td style=\"text-align: right;\">            40.6035 </td><td style=\"text-align: right;\">          6.33264 </td><td style=\"text-align: right;\">      40.6035 </td><td style=\"text-align: right;\"> 1691654260</td><td style=\"text-align: right;\">    1.01296 </td><td style=\"text-align: right;\">    0.496006</td><td style=\"text-align: right;\">  2.0232e+14 </td><td style=\"text-align: right;\">  4.24451e+14</td><td style=\"text-align: right;\">                   8</td><td>ab8af723  </td><td style=\"text-align: right;\">     0.475651</td><td style=\"text-align: right;\">     0.368852</td></tr>\n",
       "<tr><td>FSR_Trainable_ace5461a</td><td>2023-08-10_16-32-31</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    6.16012</td><td style=\"text-align: right;\">   1435.62 </td><td style=\"text-align: right;\">     1.31908</td><td style=\"text-align: right;\"> 1.22471e+18</td><td style=\"text-align: right;\"> 0.884917</td><td>172.26.215.93</td><td style=\"text-align: right;\">72160</td><td style=\"text-align: right;\">     2.76703</td><td style=\"text-align: right;\">    1159.38 </td><td style=\"text-align: right;\">            14.1687 </td><td style=\"text-align: right;\">          2.72863 </td><td style=\"text-align: right;\">      14.1687 </td><td style=\"text-align: right;\"> 1691652751</td><td style=\"text-align: right;\">    1.256   </td><td style=\"text-align: right;\">    0.508609</td><td style=\"text-align: right;\">  1.60159e+14</td><td style=\"text-align: right;\">  4.19371e+14</td><td style=\"text-align: right;\">                   4</td><td>ace5461a  </td><td style=\"text-align: right;\">     0.511795</td><td style=\"text-align: right;\">     0.373122</td></tr>\n",
       "<tr><td>FSR_Trainable_ae274a48</td><td>2023-08-10_16-44-29</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    4.94143</td><td style=\"text-align: right;\">   1502.96 </td><td style=\"text-align: right;\">     1.31428</td><td style=\"text-align: right;\"> 2.05731e+18</td><td style=\"text-align: right;\"> 0.822353</td><td>172.26.215.93</td><td style=\"text-align: right;\">76443</td><td style=\"text-align: right;\">     2.49308</td><td style=\"text-align: right;\">    1114.42 </td><td style=\"text-align: right;\">           207.443  </td><td style=\"text-align: right;\">          6.699   </td><td style=\"text-align: right;\">     207.443  </td><td style=\"text-align: right;\"> 1691653469</td><td style=\"text-align: right;\">    0.994568</td><td style=\"text-align: right;\">    0.523094</td><td style=\"text-align: right;\">  2.06225e+14</td><td style=\"text-align: right;\">  7.03876e+14</td><td style=\"text-align: right;\">                  32</td><td>ae274a48  </td><td style=\"text-align: right;\">     0.468771</td><td style=\"text-align: right;\">     0.353582</td></tr>\n",
       "<tr><td>FSR_Trainable_b1ae2e48</td><td>2023-08-10_16-31-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    6.52239</td><td style=\"text-align: right;\">   1539.94 </td><td style=\"text-align: right;\">     1.37238</td><td style=\"text-align: right;\"> 2.11785e+18</td><td style=\"text-align: right;\"> 0.886262</td><td>172.26.215.93</td><td style=\"text-align: right;\">71253</td><td style=\"text-align: right;\">     2.85259</td><td style=\"text-align: right;\">    1117.69 </td><td style=\"text-align: right;\">            28.0993 </td><td style=\"text-align: right;\">          2.89066 </td><td style=\"text-align: right;\">      28.0993 </td><td style=\"text-align: right;\"> 1691652706</td><td style=\"text-align: right;\">    1.31349 </td><td style=\"text-align: right;\">    0.552583</td><td style=\"text-align: right;\">  1.8926e+14 </td><td style=\"text-align: right;\">  8.1257e+14 </td><td style=\"text-align: right;\">                   8</td><td>b1ae2e48  </td><td style=\"text-align: right;\">     0.530777</td><td style=\"text-align: right;\">     0.355485</td></tr>\n",
       "<tr><td>FSR_Trainable_b25d1191</td><td>2023-08-10_16-30-11</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    4.11484</td><td style=\"text-align: right;\">   1583.52 </td><td style=\"text-align: right;\">     1.22527</td><td style=\"text-align: right;\"> 5.2507e+09 </td><td style=\"text-align: right;\"> 6.03327 </td><td>172.26.215.93</td><td style=\"text-align: right;\">69690</td><td style=\"text-align: right;\">     2.41811</td><td style=\"text-align: right;\">    1105.35 </td><td style=\"text-align: right;\">            14.4147 </td><td style=\"text-align: right;\">          6.94356 </td><td style=\"text-align: right;\">      14.4147 </td><td style=\"text-align: right;\"> 1691652611</td><td style=\"text-align: right;\">    6.63427 </td><td style=\"text-align: right;\">    3.97893 </td><td style=\"text-align: right;\">  6.08238e+14</td><td style=\"text-align: right;\">  6.43612    </td><td style=\"text-align: right;\">                   2</td><td>b25d1191  </td><td style=\"text-align: right;\">     3.52989 </td><td style=\"text-align: right;\">     2.50339 </td></tr>\n",
       "<tr><td>FSR_Trainable_b60e7c50</td><td>2023-08-10_16-32-48</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    6.43802</td><td style=\"text-align: right;\">   1476.43 </td><td style=\"text-align: right;\">     1.37348</td><td style=\"text-align: right;\"> 1.61287e+18</td><td style=\"text-align: right;\"> 0.88879 </td><td>172.26.215.93</td><td style=\"text-align: right;\">72426</td><td style=\"text-align: right;\">     2.83042</td><td style=\"text-align: right;\">    1136.14 </td><td style=\"text-align: right;\">            14.6462 </td><td style=\"text-align: right;\">          3.84127 </td><td style=\"text-align: right;\">      14.6462 </td><td style=\"text-align: right;\"> 1691652768</td><td style=\"text-align: right;\">    1.31535 </td><td style=\"text-align: right;\">    0.516104</td><td style=\"text-align: right;\">  1.5489e+14 </td><td style=\"text-align: right;\">  5.63466e+14</td><td style=\"text-align: right;\">                   4</td><td>b60e7c50  </td><td style=\"text-align: right;\">     0.527383</td><td style=\"text-align: right;\">     0.361408</td></tr>\n",
       "<tr><td>FSR_Trainable_bd235651</td><td>2023-08-10_16-43-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.36869</td><td style=\"text-align: right;\">   1442.24 </td><td style=\"text-align: right;\">     1.40267</td><td style=\"text-align: right;\"> 1.44043e+18</td><td style=\"text-align: right;\"> 0.846859</td><td>172.26.215.93</td><td style=\"text-align: right;\">76650</td><td style=\"text-align: right;\">     2.56244</td><td style=\"text-align: right;\">    1142.42 </td><td style=\"text-align: right;\">           111.8    </td><td style=\"text-align: right;\">          7.28324 </td><td style=\"text-align: right;\">     111.8    </td><td style=\"text-align: right;\"> 1691653389</td><td style=\"text-align: right;\">    1.07592 </td><td style=\"text-align: right;\">    0.497854</td><td style=\"text-align: right;\">  2.02428e+14</td><td style=\"text-align: right;\">  4.58993e+14</td><td style=\"text-align: right;\">                  16</td><td>bd235651  </td><td style=\"text-align: right;\">     0.481547</td><td style=\"text-align: right;\">     0.365313</td></tr>\n",
       "<tr><td>FSR_Trainable_bdfb235c</td><td>2023-08-10_16-58-21</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    6.42885</td><td style=\"text-align: right;\">   1494.72 </td><td style=\"text-align: right;\">     1.42612</td><td style=\"text-align: right;\"> 1.87743e+18</td><td style=\"text-align: right;\"> 0.875112</td><td>172.26.215.93</td><td style=\"text-align: right;\">84003</td><td style=\"text-align: right;\">     2.73763</td><td style=\"text-align: right;\">    1120.52 </td><td style=\"text-align: right;\">            14.3131 </td><td style=\"text-align: right;\">          5.75646 </td><td style=\"text-align: right;\">      14.3131 </td><td style=\"text-align: right;\"> 1691654301</td><td style=\"text-align: right;\">    1.31007 </td><td style=\"text-align: right;\">    0.521058</td><td style=\"text-align: right;\">  1.68084e+14</td><td style=\"text-align: right;\">  6.27123e+14</td><td style=\"text-align: right;\">                   2</td><td>bdfb235c  </td><td style=\"text-align: right;\">     0.517088</td><td style=\"text-align: right;\">     0.358025</td></tr>\n",
       "<tr><td>FSR_Trainable_be396f70</td><td>2023-08-10_16-33-16</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.59031</td><td style=\"text-align: right;\">   1467.58 </td><td style=\"text-align: right;\">     1.33947</td><td style=\"text-align: right;\"> 1.74156e+18</td><td style=\"text-align: right;\"> 0.857652</td><td>172.26.215.93</td><td style=\"text-align: right;\">72627</td><td style=\"text-align: right;\">     2.65218</td><td style=\"text-align: right;\">    1126.55 </td><td style=\"text-align: right;\">            31.0376 </td><td style=\"text-align: right;\">          3.60484 </td><td style=\"text-align: right;\">      31.0376 </td><td style=\"text-align: right;\"> 1691652796</td><td style=\"text-align: right;\">    1.11625 </td><td style=\"text-align: right;\">    0.506271</td><td style=\"text-align: right;\">  1.72502e+14</td><td style=\"text-align: right;\">  5.27592e+14</td><td style=\"text-align: right;\">                   8</td><td>be396f70  </td><td style=\"text-align: right;\">     0.495336</td><td style=\"text-align: right;\">     0.362316</td></tr>\n",
       "<tr><td>FSR_Trainable_be818bb5</td><td>2023-08-10_16-56-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.67734</td><td style=\"text-align: right;\">   1352.28 </td><td style=\"text-align: right;\">     1.27015</td><td style=\"text-align: right;\"> 1.61704e+18</td><td style=\"text-align: right;\"> 0.794316</td><td>172.26.215.93</td><td style=\"text-align: right;\">81665</td><td style=\"text-align: right;\">     2.44296</td><td style=\"text-align: right;\">    1057.17 </td><td style=\"text-align: right;\">           231.631  </td><td style=\"text-align: right;\">          5.28367 </td><td style=\"text-align: right;\">     231.631  </td><td style=\"text-align: right;\"> 1691654194</td><td style=\"text-align: right;\">    0.945092</td><td style=\"text-align: right;\">    0.474413</td><td style=\"text-align: right;\">  2.04768e+14</td><td style=\"text-align: right;\">  5.66442e+14</td><td style=\"text-align: right;\">                  64</td><td>be818bb5  </td><td style=\"text-align: right;\">     0.460078</td><td style=\"text-align: right;\">     0.334238</td></tr>\n",
       "<tr><td>FSR_Trainable_c0605114</td><td>2023-08-10_16-29-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.4201 </td><td style=\"text-align: right;\">   1469.39 </td><td style=\"text-align: right;\">     1.30017</td><td style=\"text-align: right;\"> 3.75616e+16</td><td style=\"text-align: right;\">21.3541  </td><td>172.26.215.93</td><td style=\"text-align: right;\">66932</td><td style=\"text-align: right;\">     2.42948</td><td style=\"text-align: right;\">    1157.66 </td><td style=\"text-align: right;\">             5.00372</td><td style=\"text-align: right;\">          5.00372 </td><td style=\"text-align: right;\">       5.00372</td><td style=\"text-align: right;\"> 1691652568</td><td style=\"text-align: right;\">   12.4273  </td><td style=\"text-align: right;\">   11.215   </td><td style=\"text-align: right;\">  2.70163e+15</td><td style=\"text-align: right;\">  1.55009e+15</td><td style=\"text-align: right;\">                   1</td><td>c0605114  </td><td style=\"text-align: right;\">     7.80611 </td><td style=\"text-align: right;\">    13.5479  </td></tr>\n",
       "<tr><td>FSR_Trainable_c06d8814</td><td>2023-08-10_16-29-21</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">   26.002  </td><td style=\"text-align: right;\">   2421.24 </td><td style=\"text-align: right;\">     4.10214</td><td style=\"text-align: right;\"> 2.46393e+18</td><td style=\"text-align: right;\"> 2.54198 </td><td>172.26.215.93</td><td style=\"text-align: right;\">66744</td><td style=\"text-align: right;\">     9.2396 </td><td style=\"text-align: right;\">    1600.59 </td><td style=\"text-align: right;\">             5.13195</td><td style=\"text-align: right;\">          2.3201  </td><td style=\"text-align: right;\">       5.13195</td><td style=\"text-align: right;\"> 1691652561</td><td style=\"text-align: right;\">    5.71174 </td><td style=\"text-align: right;\">    1.0087  </td><td style=\"text-align: right;\">  6.90577e+13</td><td style=\"text-align: right;\">  1.41598e+15</td><td style=\"text-align: right;\">                   2</td><td>c06d8814  </td><td style=\"text-align: right;\">     1.97399 </td><td style=\"text-align: right;\">     0.567982</td></tr>\n",
       "<tr><td>FSR_Trainable_c392afee</td><td>2023-08-10_17-14-44</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.64875</td><td style=\"text-align: right;\">   1034.46 </td><td style=\"text-align: right;\">     1.20197</td><td style=\"text-align: right;\"> 2.34804e+09</td><td style=\"text-align: right;\"> 5.69465 </td><td>172.26.215.93</td><td style=\"text-align: right;\">90056</td><td style=\"text-align: right;\">     2.44192</td><td style=\"text-align: right;\">     840.801</td><td style=\"text-align: right;\">             2.23546</td><td style=\"text-align: right;\">          2.23546 </td><td style=\"text-align: right;\">       2.23546</td><td style=\"text-align: right;\"> 1691655284</td><td style=\"text-align: right;\">    7.32589 </td><td style=\"text-align: right;\">    2.68317 </td><td style=\"text-align: right;\"> 37.4841     </td><td style=\"text-align: right;\"> 11.0617     </td><td style=\"text-align: right;\">                   1</td><td>c392afee  </td><td style=\"text-align: right;\">     3.49653 </td><td style=\"text-align: right;\">     2.19812 </td></tr>\n",
       "<tr><td>FSR_Trainable_c3aa4657</td><td>2023-08-10_16-48-11</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    5.16585</td><td style=\"text-align: right;\">   1475.85 </td><td style=\"text-align: right;\">     1.32889</td><td style=\"text-align: right;\"> 1.84976e+18</td><td style=\"text-align: right;\"> 0.832972</td><td>172.26.215.93</td><td style=\"text-align: right;\">78763</td><td style=\"text-align: right;\">     2.53707</td><td style=\"text-align: right;\">    1120.66 </td><td style=\"text-align: right;\">           132.563  </td><td style=\"text-align: right;\">          4.56653 </td><td style=\"text-align: right;\">     132.563  </td><td style=\"text-align: right;\"> 1691653691</td><td style=\"text-align: right;\">    1.03803 </td><td style=\"text-align: right;\">    0.509593</td><td style=\"text-align: right;\">  2.04494e+14</td><td style=\"text-align: right;\">  6.0562e+14 </td><td style=\"text-align: right;\">                  32</td><td>c3aa4657  </td><td style=\"text-align: right;\">     0.476101</td><td style=\"text-align: right;\">     0.356871</td></tr>\n",
       "<tr><td>FSR_Trainable_c8fad061</td><td>2023-08-10_16-45-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.83341</td><td style=\"text-align: right;\">   1180.94 </td><td style=\"text-align: right;\">     1.3344 </td><td style=\"text-align: right;\"> 3.21882e+09</td><td style=\"text-align: right;\"> 5.73359 </td><td>172.26.215.93</td><td style=\"text-align: right;\">78577</td><td style=\"text-align: right;\">     2.43788</td><td style=\"text-align: right;\">     950.806</td><td style=\"text-align: right;\">             3.62641</td><td style=\"text-align: right;\">          3.62641 </td><td style=\"text-align: right;\">       3.62641</td><td style=\"text-align: right;\"> 1691653546</td><td style=\"text-align: right;\">    7.80032 </td><td style=\"text-align: right;\">    2.9719  </td><td style=\"text-align: right;\">  3.38674e+15</td><td style=\"text-align: right;\"> 13.9111     </td><td style=\"text-align: right;\">                   1</td><td>c8fad061  </td><td style=\"text-align: right;\">     3.5692  </td><td style=\"text-align: right;\">     2.1644  </td></tr>\n",
       "<tr><td>FSR_Trainable_c9f001c0</td><td>2023-08-10_16-49-05</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.45641</td><td style=\"text-align: right;\">    942.823</td><td style=\"text-align: right;\">     1.36952</td><td style=\"text-align: right;\"> 6.87406e+17</td><td style=\"text-align: right;\"> 0.728018</td><td>172.26.215.93</td><td style=\"text-align: right;\">74682</td><td style=\"text-align: right;\">     2.53433</td><td style=\"text-align: right;\">     781.632</td><td style=\"text-align: right;\">           801.618  </td><td style=\"text-align: right;\">          7.93368 </td><td style=\"text-align: right;\">     801.618  </td><td style=\"text-align: right;\"> 1691653745</td><td style=\"text-align: right;\">    1.07604 </td><td style=\"text-align: right;\">    0.348151</td><td style=\"text-align: right;\">  1.6978e+14 </td><td style=\"text-align: right;\">  2.97893e+14</td><td style=\"text-align: right;\">                 100</td><td>c9f001c0  </td><td style=\"text-align: right;\">     0.472774</td><td style=\"text-align: right;\">     0.255244</td></tr>\n",
       "<tr><td>FSR_Trainable_cc7ad45a</td><td>2023-08-10_17-02-12</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.74875</td><td style=\"text-align: right;\">    681.791</td><td style=\"text-align: right;\">     1.24576</td><td style=\"text-align: right;\"> 5.82777e+17</td><td style=\"text-align: right;\"> 0.617917</td><td>172.26.215.93</td><td style=\"text-align: right;\">84469</td><td style=\"text-align: right;\">     2.35115</td><td style=\"text-align: right;\">     524.853</td><td style=\"text-align: right;\">           183.911  </td><td style=\"text-align: right;\">          2.42949 </td><td style=\"text-align: right;\">     183.911  </td><td style=\"text-align: right;\"> 1691654532</td><td style=\"text-align: right;\">    0.960804</td><td style=\"text-align: right;\">    0.264702</td><td style=\"text-align: right;\">  1.83717e+14</td><td style=\"text-align: right;\">  2.83959e+14</td><td style=\"text-align: right;\">                 100</td><td>cc7ad45a  </td><td style=\"text-align: right;\">     0.438273</td><td style=\"text-align: right;\">     0.179644</td></tr>\n",
       "<tr><td>FSR_Trainable_ccb545df</td><td>2023-08-10_16-50-21</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.83233</td><td style=\"text-align: right;\">   1239.01 </td><td style=\"text-align: right;\">     1.26688</td><td style=\"text-align: right;\"> 4.06245e+09</td><td style=\"text-align: right;\"> 5.90106 </td><td>172.26.215.93</td><td style=\"text-align: right;\">80658</td><td style=\"text-align: right;\">     2.50103</td><td style=\"text-align: right;\">     976.598</td><td style=\"text-align: right;\">            12.8859 </td><td style=\"text-align: right;\">         12.8859  </td><td style=\"text-align: right;\">      12.8859 </td><td style=\"text-align: right;\"> 1691653821</td><td style=\"text-align: right;\">    7.85713 </td><td style=\"text-align: right;\">    2.98665 </td><td style=\"text-align: right;\">  3.375e+15  </td><td style=\"text-align: right;\"> 10.6358     </td><td style=\"text-align: right;\">                   1</td><td>ccb545df  </td><td style=\"text-align: right;\">     3.7068  </td><td style=\"text-align: right;\">     2.19426 </td></tr>\n",
       "<tr><td>FSR_Trainable_d3aecf5b</td><td>2023-08-10_17-08-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.69166</td><td style=\"text-align: right;\">    683.906</td><td style=\"text-align: right;\">     1.18069</td><td style=\"text-align: right;\"> 5.94446e+17</td><td style=\"text-align: right;\"> 0.607834</td><td>172.26.215.93</td><td style=\"text-align: right;\">86971</td><td style=\"text-align: right;\">     2.34706</td><td style=\"text-align: right;\">     518.604</td><td style=\"text-align: right;\">           152.336  </td><td style=\"text-align: right;\">          1.47774 </td><td style=\"text-align: right;\">     152.336  </td><td style=\"text-align: right;\"> 1691654918</td><td style=\"text-align: right;\">    0.945398</td><td style=\"text-align: right;\">    0.260697</td><td style=\"text-align: right;\">  1.63914e+14</td><td style=\"text-align: right;\">  2.80706e+14</td><td style=\"text-align: right;\">                 100</td><td>d3aecf5b  </td><td style=\"text-align: right;\">     0.436234</td><td style=\"text-align: right;\">     0.1716  </td></tr>\n",
       "<tr><td>FSR_Trainable_d6846f19</td><td>2023-08-10_16-50-03</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.30377</td><td style=\"text-align: right;\">   1264.74 </td><td style=\"text-align: right;\">     1.25442</td><td style=\"text-align: right;\"> 4.30785e+09</td><td style=\"text-align: right;\"> 5.75094 </td><td>172.26.215.93</td><td style=\"text-align: right;\">80434</td><td style=\"text-align: right;\">     2.38191</td><td style=\"text-align: right;\">     999.929</td><td style=\"text-align: right;\">             8.43695</td><td style=\"text-align: right;\">          8.43695 </td><td style=\"text-align: right;\">       8.43695</td><td style=\"text-align: right;\"> 1691653803</td><td style=\"text-align: right;\">    6.87788 </td><td style=\"text-align: right;\">    2.99677 </td><td style=\"text-align: right;\">  1.6659e+15 </td><td style=\"text-align: right;\">  8.03606    </td><td style=\"text-align: right;\">                   1</td><td>d6846f19  </td><td style=\"text-align: right;\">     3.47463 </td><td style=\"text-align: right;\">     2.27631 </td></tr>\n",
       "<tr><td>FSR_Trainable_dbad7f3e</td><td>2023-08-10_16-29-57</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    4.49947</td><td style=\"text-align: right;\">   1384.02 </td><td style=\"text-align: right;\">     1.25807</td><td style=\"text-align: right;\"> 1.75221e+17</td><td style=\"text-align: right;\">19.9608  </td><td>172.26.215.93</td><td style=\"text-align: right;\">69470</td><td style=\"text-align: right;\">     2.44006</td><td style=\"text-align: right;\">    1099.17 </td><td style=\"text-align: right;\">            10.3542 </td><td style=\"text-align: right;\">          4.94064 </td><td style=\"text-align: right;\">      10.3542 </td><td style=\"text-align: right;\"> 1691652597</td><td style=\"text-align: right;\">   12.4428  </td><td style=\"text-align: right;\">   10.7713  </td><td style=\"text-align: right;\">  3.33207e+15</td><td style=\"text-align: right;\">  7.5081e+15 </td><td style=\"text-align: right;\">                   2</td><td>dbad7f3e  </td><td style=\"text-align: right;\">     7.69552 </td><td style=\"text-align: right;\">    12.2653  </td></tr>\n",
       "<tr><td>FSR_Trainable_e23fb1f6</td><td>2023-08-10_17-03-27</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.45735</td><td style=\"text-align: right;\">    609.798</td><td style=\"text-align: right;\">     1.1677 </td><td style=\"text-align: right;\"> 4.05367e+17</td><td style=\"text-align: right;\"> 0.585368</td><td>172.26.215.93</td><td style=\"text-align: right;\">85378</td><td style=\"text-align: right;\">     2.27331</td><td style=\"text-align: right;\">     497.772</td><td style=\"text-align: right;\">           202.123  </td><td style=\"text-align: right;\">          1.92045 </td><td style=\"text-align: right;\">     202.123  </td><td style=\"text-align: right;\"> 1691654607</td><td style=\"text-align: right;\">    0.895118</td><td style=\"text-align: right;\">    0.228044</td><td style=\"text-align: right;\">  1.70549e+14</td><td style=\"text-align: right;\">  1.77682e+14</td><td style=\"text-align: right;\">                 100</td><td>e23fb1f6  </td><td style=\"text-align: right;\">     0.420762</td><td style=\"text-align: right;\">     0.164606</td></tr>\n",
       "<tr><td>FSR_Trainable_e265c692</td><td>2023-08-10_17-07-56</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.58467</td><td style=\"text-align: right;\">    672.818</td><td style=\"text-align: right;\">     1.25608</td><td style=\"text-align: right;\"> 7.07401e+17</td><td style=\"text-align: right;\"> 0.595054</td><td>172.26.215.93</td><td style=\"text-align: right;\">86538</td><td style=\"text-align: right;\">     2.3137 </td><td style=\"text-align: right;\">     489.794</td><td style=\"text-align: right;\">           143.978  </td><td style=\"text-align: right;\">          1.50506 </td><td style=\"text-align: right;\">     143.978  </td><td style=\"text-align: right;\"> 1691654876</td><td style=\"text-align: right;\">    0.922764</td><td style=\"text-align: right;\">    0.256841</td><td style=\"text-align: right;\">  1.83105e+14</td><td style=\"text-align: right;\">  3.00954e+14</td><td style=\"text-align: right;\">                 100</td><td>e265c692  </td><td style=\"text-align: right;\">     0.426926</td><td style=\"text-align: right;\">     0.168128</td></tr>\n",
       "<tr><td>FSR_Trainable_e5085378</td><td>2023-08-10_16-49-24</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   15.8516 </td><td style=\"text-align: right;\">   1556.96 </td><td style=\"text-align: right;\">     2.61892</td><td style=\"text-align: right;\"> 2.11298e+18</td><td style=\"text-align: right;\"> 1.43314 </td><td>172.26.215.93</td><td style=\"text-align: right;\">79798</td><td style=\"text-align: right;\">     5.30412</td><td style=\"text-align: right;\">    1113.19 </td><td style=\"text-align: right;\">            12.4236 </td><td style=\"text-align: right;\">         12.4236  </td><td style=\"text-align: right;\">      12.4236 </td><td style=\"text-align: right;\"> 1691653764</td><td style=\"text-align: right;\">    3.34399 </td><td style=\"text-align: right;\">    0.553405</td><td style=\"text-align: right;\">  8.31039e+13</td><td style=\"text-align: right;\">  7.29818e+14</td><td style=\"text-align: right;\">                   1</td><td>e5085378  </td><td style=\"text-align: right;\">     1.07489 </td><td style=\"text-align: right;\">     0.358253</td></tr>\n",
       "<tr><td>FSR_Trainable_e6e13434</td><td>2023-08-10_16-31-15</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    4.17062</td><td style=\"text-align: right;\">   1570.25 </td><td style=\"text-align: right;\">     1.25597</td><td style=\"text-align: right;\"> 5.12987e+09</td><td style=\"text-align: right;\"> 6.04615 </td><td>172.26.215.93</td><td style=\"text-align: right;\">71027</td><td style=\"text-align: right;\">     2.41862</td><td style=\"text-align: right;\">    1106.11 </td><td style=\"text-align: right;\">            10.7558 </td><td style=\"text-align: right;\">          5.16177 </td><td style=\"text-align: right;\">      10.7558 </td><td style=\"text-align: right;\"> 1691652675</td><td style=\"text-align: right;\">    6.68336 </td><td style=\"text-align: right;\">    3.91094 </td><td style=\"text-align: right;\">  8.07723e+14</td><td style=\"text-align: right;\">  6.57697    </td><td style=\"text-align: right;\">                   2</td><td>e6e13434  </td><td style=\"text-align: right;\">     3.52828 </td><td style=\"text-align: right;\">     2.51787 </td></tr>\n",
       "<tr><td>FSR_Trainable_e84164c1</td><td>2023-08-10_16-32-19</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    6.4005 </td><td style=\"text-align: right;\">   1482.15 </td><td style=\"text-align: right;\">     1.36025</td><td style=\"text-align: right;\"> 1.73897e+18</td><td style=\"text-align: right;\"> 0.882088</td><td>172.26.215.93</td><td style=\"text-align: right;\">71933</td><td style=\"text-align: right;\">     2.76023</td><td style=\"text-align: right;\">    1137.49 </td><td style=\"text-align: right;\">            17.4879 </td><td style=\"text-align: right;\">          4.60276 </td><td style=\"text-align: right;\">      17.4879 </td><td style=\"text-align: right;\"> 1691652739</td><td style=\"text-align: right;\">    1.32495 </td><td style=\"text-align: right;\">    0.525879</td><td style=\"text-align: right;\">  1.48949e+14</td><td style=\"text-align: right;\">  6.65362e+14</td><td style=\"text-align: right;\">                   4</td><td>e84164c1  </td><td style=\"text-align: right;\">     0.523201</td><td style=\"text-align: right;\">     0.358887</td></tr>\n",
       "<tr><td>FSR_Trainable_e95f5760</td><td>2023-08-10_16-31-35</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    6.11193</td><td style=\"text-align: right;\">   1506.67 </td><td style=\"text-align: right;\">     1.51761</td><td style=\"text-align: right;\"> 1.99429e+18</td><td style=\"text-align: right;\"> 0.898943</td><td>172.26.215.93</td><td style=\"text-align: right;\">70131</td><td style=\"text-align: right;\">     2.80501</td><td style=\"text-align: right;\">    1126    </td><td style=\"text-align: right;\">            75.5212 </td><td style=\"text-align: right;\">         19.6876  </td><td style=\"text-align: right;\">      75.5212 </td><td style=\"text-align: right;\"> 1691652695</td><td style=\"text-align: right;\">    1.2337  </td><td style=\"text-align: right;\">    0.522143</td><td style=\"text-align: right;\">  1.97325e+14</td><td style=\"text-align: right;\">  6.66131e+14</td><td style=\"text-align: right;\">                   4</td><td>e95f5760  </td><td style=\"text-align: right;\">     0.541077</td><td style=\"text-align: right;\">     0.357865</td></tr>\n",
       "<tr><td>FSR_Trainable_eb0d0c6e</td><td>2023-08-10_16-53-54</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.36416</td><td style=\"text-align: right;\">   1466.06 </td><td style=\"text-align: right;\">     1.37308</td><td style=\"text-align: right;\"> 1.70417e+18</td><td style=\"text-align: right;\"> 0.851777</td><td>172.26.215.93</td><td style=\"text-align: right;\">81898</td><td style=\"text-align: right;\">     2.60487</td><td style=\"text-align: right;\">    1130.2  </td><td style=\"text-align: right;\">            59.3028 </td><td style=\"text-align: right;\">         14.2753  </td><td style=\"text-align: right;\">      59.3028 </td><td style=\"text-align: right;\"> 1691654034</td><td style=\"text-align: right;\">    1.07878 </td><td style=\"text-align: right;\">    0.506561</td><td style=\"text-align: right;\">  2.03274e+14</td><td style=\"text-align: right;\">  5.59428e+14</td><td style=\"text-align: right;\">                   4</td><td>eb0d0c6e  </td><td style=\"text-align: right;\">     0.492096</td><td style=\"text-align: right;\">     0.359681</td></tr>\n",
       "<tr><td>FSR_Trainable_ecbdaff6</td><td>2023-08-10_16-32-22</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.72898</td><td style=\"text-align: right;\">   1461.94 </td><td style=\"text-align: right;\">     1.40813</td><td style=\"text-align: right;\"> 1.75518e+18</td><td style=\"text-align: right;\"> 0.858869</td><td>172.26.215.93</td><td style=\"text-align: right;\">71757</td><td style=\"text-align: right;\">     2.67114</td><td style=\"text-align: right;\">    1122.7  </td><td style=\"text-align: right;\">            30.5391 </td><td style=\"text-align: right;\">          3.58103 </td><td style=\"text-align: right;\">      30.5391 </td><td style=\"text-align: right;\"> 1691652742</td><td style=\"text-align: right;\">    1.14502 </td><td style=\"text-align: right;\">    0.498992</td><td style=\"text-align: right;\">  1.75446e+14</td><td style=\"text-align: right;\">  5.33591e+14</td><td style=\"text-align: right;\">                   8</td><td>ecbdaff6  </td><td style=\"text-align: right;\">     0.499878</td><td style=\"text-align: right;\">     0.358991</td></tr>\n",
       "<tr><td>FSR_Trainable_f0e0374c</td><td>2023-08-10_16-29-37</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    5.25054</td><td style=\"text-align: right;\">   1447.81 </td><td style=\"text-align: right;\">     1.28521</td><td style=\"text-align: right;\"> 5.71386e+16</td><td style=\"text-align: right;\">24.9379  </td><td>172.26.215.93</td><td style=\"text-align: right;\">67234</td><td style=\"text-align: right;\">     2.64658</td><td style=\"text-align: right;\">    1224.2  </td><td style=\"text-align: right;\">             2.11432</td><td style=\"text-align: right;\">          2.11432 </td><td style=\"text-align: right;\">       2.11432</td><td style=\"text-align: right;\"> 1691652577</td><td style=\"text-align: right;\">   16.5686  </td><td style=\"text-align: right;\">   11.3375  </td><td style=\"text-align: right;\">  7.90539e+15</td><td style=\"text-align: right;\">  2.646e+15  </td><td style=\"text-align: right;\">                   1</td><td>f0e0374c  </td><td style=\"text-align: right;\">    11.5815  </td><td style=\"text-align: right;\">    13.3564  </td></tr>\n",
       "<tr><td>FSR_Trainable_f21a52f1</td><td>2023-08-10_17-05-03</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.5208 </td><td style=\"text-align: right;\">    631.01 </td><td style=\"text-align: right;\">     1.17634</td><td style=\"text-align: right;\"> 4.36346e+17</td><td style=\"text-align: right;\"> 0.595863</td><td>172.26.215.93</td><td style=\"text-align: right;\">85715</td><td style=\"text-align: right;\">     2.31087</td><td style=\"text-align: right;\">     513.762</td><td style=\"text-align: right;\">           200.727  </td><td style=\"text-align: right;\">          1.51885 </td><td style=\"text-align: right;\">     200.727  </td><td style=\"text-align: right;\"> 1691654703</td><td style=\"text-align: right;\">    0.905569</td><td style=\"text-align: right;\">    0.23458 </td><td style=\"text-align: right;\">  1.74552e+14</td><td style=\"text-align: right;\">  1.92194e+14</td><td style=\"text-align: right;\">                 100</td><td>f21a52f1  </td><td style=\"text-align: right;\">     0.427429</td><td style=\"text-align: right;\">     0.168433</td></tr>\n",
       "<tr><td>FSR_Trainable_f2266733</td><td>2023-08-10_16-54-29</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.5133 </td><td style=\"text-align: right;\">   1446.32 </td><td style=\"text-align: right;\">     1.40062</td><td style=\"text-align: right;\"> 1.50303e+18</td><td style=\"text-align: right;\"> 0.867493</td><td>172.26.215.93</td><td style=\"text-align: right;\">82161</td><td style=\"text-align: right;\">     2.66414</td><td style=\"text-align: right;\">    1140.26 </td><td style=\"text-align: right;\">            19.2485 </td><td style=\"text-align: right;\">         10.4307  </td><td style=\"text-align: right;\">      19.2485 </td><td style=\"text-align: right;\"> 1691654069</td><td style=\"text-align: right;\">    1.1105  </td><td style=\"text-align: right;\">    0.499011</td><td style=\"text-align: right;\">  2.02178e+14</td><td style=\"text-align: right;\">  4.87815e+14</td><td style=\"text-align: right;\">                   2</td><td>f2266733  </td><td style=\"text-align: right;\">     0.503962</td><td style=\"text-align: right;\">     0.363531</td></tr>\n",
       "<tr><td>FSR_Trainable_f55b1351</td><td>2023-08-10_17-10-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.46573</td><td style=\"text-align: right;\">    636.048</td><td style=\"text-align: right;\">     1.15864</td><td style=\"text-align: right;\"> 5.86634e+17</td><td style=\"text-align: right;\"> 0.593066</td><td>172.26.215.93</td><td style=\"text-align: right;\">87557</td><td style=\"text-align: right;\">     2.30598</td><td style=\"text-align: right;\">     480.654</td><td style=\"text-align: right;\">           148.763  </td><td style=\"text-align: right;\">          1.72629 </td><td style=\"text-align: right;\">     148.763  </td><td style=\"text-align: right;\"> 1691655053</td><td style=\"text-align: right;\">    0.894965</td><td style=\"text-align: right;\">    0.246291</td><td style=\"text-align: right;\">  1.59328e+14</td><td style=\"text-align: right;\">  2.63519e+14</td><td style=\"text-align: right;\">                 100</td><td>f55b1351  </td><td style=\"text-align: right;\">     0.425658</td><td style=\"text-align: right;\">     0.167408</td></tr>\n",
       "<tr><td>FSR_Trainable_f6223373</td><td>2023-08-10_17-13-51</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.55452</td><td style=\"text-align: right;\">    661.863</td><td style=\"text-align: right;\">     1.16628</td><td style=\"text-align: right;\"> 6.11245e+17</td><td style=\"text-align: right;\"> 0.601482</td><td>172.26.215.93</td><td style=\"text-align: right;\">88568</td><td style=\"text-align: right;\">     2.33461</td><td style=\"text-align: right;\">     489.265</td><td style=\"text-align: right;\">           139.869  </td><td style=\"text-align: right;\">          1.38941 </td><td style=\"text-align: right;\">     139.869  </td><td style=\"text-align: right;\"> 1691655231</td><td style=\"text-align: right;\">    0.908721</td><td style=\"text-align: right;\">    0.259963</td><td style=\"text-align: right;\">  1.60445e+14</td><td style=\"text-align: right;\">  2.95308e+14</td><td style=\"text-align: right;\">                 100</td><td>f6223373  </td><td style=\"text-align: right;\">     0.430519</td><td style=\"text-align: right;\">     0.170964</td></tr>\n",
       "<tr><td>FSR_Trainable_f67426eb</td><td>2023-08-10_16-37-42</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.60319</td><td style=\"text-align: right;\">   1448.28 </td><td style=\"text-align: right;\">     1.34507</td><td style=\"text-align: right;\"> 1.53286e+18</td><td style=\"text-align: right;\"> 0.853166</td><td>172.26.215.93</td><td style=\"text-align: right;\">75179</td><td style=\"text-align: right;\">     2.61893</td><td style=\"text-align: right;\">    1136.19 </td><td style=\"text-align: right;\">           105.665  </td><td style=\"text-align: right;\">          6.32562 </td><td style=\"text-align: right;\">     105.665  </td><td style=\"text-align: right;\"> 1691653062</td><td style=\"text-align: right;\">    1.12151 </td><td style=\"text-align: right;\">    0.499596</td><td style=\"text-align: right;\">  1.7511e+14 </td><td style=\"text-align: right;\">  4.90837e+14</td><td style=\"text-align: right;\">                  16</td><td>f67426eb  </td><td style=\"text-align: right;\">     0.490113</td><td style=\"text-align: right;\">     0.363053</td></tr>\n",
       "<tr><td>FSR_Trainable_f718e66a</td><td>2023-08-10_17-14-10</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.6583 </td><td style=\"text-align: right;\">    652.575</td><td style=\"text-align: right;\">     1.16823</td><td style=\"text-align: right;\"> 5.65542e+17</td><td style=\"text-align: right;\"> 0.604269</td><td>172.26.215.93</td><td style=\"text-align: right;\">88799</td><td style=\"text-align: right;\">     2.36139</td><td style=\"text-align: right;\">     493.201</td><td style=\"text-align: right;\">           144.545  </td><td style=\"text-align: right;\">          1.47531 </td><td style=\"text-align: right;\">     144.545  </td><td style=\"text-align: right;\"> 1691655250</td><td style=\"text-align: right;\">    0.934436</td><td style=\"text-align: right;\">    0.25261 </td><td style=\"text-align: right;\">  1.64951e+14</td><td style=\"text-align: right;\">  2.67816e+14</td><td style=\"text-align: right;\">                 100</td><td>f718e66a  </td><td style=\"text-align: right;\">     0.434301</td><td style=\"text-align: right;\">     0.169968</td></tr>\n",
       "<tr><td>FSR_Trainable_fb056e32</td><td>2023-08-10_16-48-54</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   15.4227 </td><td style=\"text-align: right;\">   1522.07 </td><td style=\"text-align: right;\">     2.54935</td><td style=\"text-align: right;\"> 1.80874e+18</td><td style=\"text-align: right;\"> 1.43825 </td><td>172.26.215.93</td><td style=\"text-align: right;\">79519</td><td style=\"text-align: right;\">     5.25955</td><td style=\"text-align: right;\">    1152.33 </td><td style=\"text-align: right;\">            14.567  </td><td style=\"text-align: right;\">         14.567   </td><td style=\"text-align: right;\">      14.567  </td><td style=\"text-align: right;\"> 1691653734</td><td style=\"text-align: right;\">    3.26517 </td><td style=\"text-align: right;\">    0.57089 </td><td style=\"text-align: right;\">  1.13744e+14</td><td style=\"text-align: right;\">  8.34305e+14</td><td style=\"text-align: right;\">                   1</td><td>fb056e32  </td><td style=\"text-align: right;\">     1.07345 </td><td style=\"text-align: right;\">     0.364802</td></tr>\n",
       "<tr><td>FSR_Trainable_fb065147</td><td>2023-08-10_17-10-49</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.1483 </td><td style=\"text-align: right;\">    809.253</td><td style=\"text-align: right;\">     1.32597</td><td style=\"text-align: right;\"> 5.64347e+17</td><td style=\"text-align: right;\"> 0.673564</td><td>172.26.215.93</td><td style=\"text-align: right;\">87289</td><td style=\"text-align: right;\">     2.50187</td><td style=\"text-align: right;\">     639.472</td><td style=\"text-align: right;\">           199.903  </td><td style=\"text-align: right;\">          2.1481  </td><td style=\"text-align: right;\">     199.903  </td><td style=\"text-align: right;\"> 1691655049</td><td style=\"text-align: right;\">    1.01419 </td><td style=\"text-align: right;\">    0.304192</td><td style=\"text-align: right;\">  1.64062e+14</td><td style=\"text-align: right;\">  2.54141e+14</td><td style=\"text-align: right;\">                 100</td><td>fb065147  </td><td style=\"text-align: right;\">     0.460706</td><td style=\"text-align: right;\">     0.212858</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 16:29:01,150\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:01,156\tWARNING util.py:315 -- The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:01,157\tWARNING util.py:315 -- Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:01,158\tWARNING util.py:315 -- The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_26b73957_1_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-28-50/wandb/run-20230810_162900-26b73957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Syncing run FSR_Trainable_26b73957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/26b73957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:29:12,173\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.278 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:12,179\tWARNING util.py:315 -- The `process_trial_result` operation took 2.285 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:12,181\tWARNING util.py:315 -- Processing trial results took 2.286 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:12,183\tWARNING util.py:315 -- The `process_trial_result` operation took 2.288 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_3ba64bd6_2_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-28-55/wandb/run-20230810_162911-3ba64bd6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Syncing run FSR_Trainable_3ba64bd6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3ba64bd6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                mae_coord 4.18571\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                mae_force 1405.69307\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               mape_coord 1.21207\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               mape_force 6466662161127609.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                   metric 21.36247\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               rmse_coord 2.42137\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               rmse_force 1172.43144\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:       time_since_restore 7.32827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:         time_this_iter_s 7.32827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:             time_total_s 7.32827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:                timestamp 1691652549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               tmae_coord 12.01873\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:               tmae_force 10.89129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              tmape_coord 1127033283148680.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              tmape_force 268347925478664.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              trmse_coord 7.79206\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:              trmse_force 13.5704\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb:  View run FSR_Trainable_3ba64bd6 at: https://wandb.ai/seokjin/FSR-prediction/runs/3ba64bd6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66743)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162911-3ba64bd6/logs\n",
      "2023-08-10 16:29:19,236\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.465 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:19,244\tWARNING util.py:315 -- The `process_trial_result` operation took 2.474 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:19,245\tWARNING util.py:315 -- Processing trial results took 2.475 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:19,248\tWARNING util.py:315 -- The `process_trial_result` operation took 2.478 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c06d8814_3_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-02/wandb/run-20230810_162921-c06d8814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Syncing run FSR_Trainable_c06d8814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c06d8814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                mae_coord 26.00201\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                mae_force 2421.24354\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               mape_coord 4.10214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               mape_force 2.463925724964988e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                   metric 2.54198\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               rmse_coord 9.2396\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               rmse_force 1600.58989\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:       time_since_restore 5.13195\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:         time_this_iter_s 2.3201\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:             time_total_s 5.13195\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:                timestamp 1691652561\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               tmae_coord 5.71174\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:               tmae_force 1.0087\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              tmape_coord 69057746057844.42\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              tmape_force 1415982522238923.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              trmse_coord 1.97399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:              trmse_force 0.56798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb:  View run FSR_Trainable_c06d8814 at: https://wandb.ai/seokjin/FSR-prediction/runs/c06d8814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66930)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162921-c06d8814/logs\n",
      "2023-08-10 16:29:31,619\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.374 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:31,624\tWARNING util.py:315 -- The `process_trial_result` operation took 3.381 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:31,627\tWARNING util.py:315 -- Processing trial results took 3.384 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:31,630\tWARNING util.py:315 -- The `process_trial_result` operation took 3.387 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c0605114_4_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-13/wandb/run-20230810_162931-c0605114\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Syncing run FSR_Trainable_c0605114\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c0605114\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                mae_coord 4.4201\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                mae_force 1469.39097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               mape_coord 1.30017\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               mape_force 3.756158272729729e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                   metric 21.35405\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               rmse_coord 2.42948\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               rmse_force 1157.66195\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:       time_since_restore 5.00372\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:         time_this_iter_s 5.00372\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:             time_total_s 5.00372\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:                timestamp 1691652568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               tmae_coord 12.42726\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:               tmae_force 11.21503\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              tmape_coord 2701634362230814.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              tmape_force 1550087264764520.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              trmse_coord 7.80611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:              trmse_force 13.54794\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb:  View run FSR_Trainable_c0605114 at: https://wandb.ai/seokjin/FSR-prediction/runs/c0605114\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=67119)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162931-c0605114/logs\n",
      "2023-08-10 16:29:39,626\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.263 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:39,631\tWARNING util.py:315 -- The `process_trial_result` operation took 2.269 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:39,633\tWARNING util.py:315 -- Processing trial results took 2.271 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:39,635\tWARNING util.py:315 -- The `process_trial_result` operation took 2.273 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f0e0374c_5_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-23/wandb/run-20230810_162942-f0e0374c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Syncing run FSR_Trainable_f0e0374c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f0e0374c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                mae_coord 5.25054\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                mae_force 1447.80502\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               mape_coord 1.28521\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               mape_force 5.713855206051794e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                   metric 24.93792\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               rmse_coord 2.64658\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               rmse_force 1224.20366\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:       time_since_restore 2.11432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:         time_this_iter_s 2.11432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:             time_total_s 2.11432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:                timestamp 1691652577\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               tmae_coord 16.56857\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:               tmae_force 11.33754\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              tmape_coord 7905385601266466.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              tmape_force 2645999638534837.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              trmse_coord 11.58148\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:              trmse_force 13.35645\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb:  View run FSR_Trainable_f0e0374c at: https://wandb.ai/seokjin/FSR-prediction/runs/f0e0374c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69353)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162942-f0e0374c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:29:52,540\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.983 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:52,544\tWARNING util.py:315 -- The `process_trial_result` operation took 1.988 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:29:52,550\tWARNING util.py:315 -- Processing trial results took 1.994 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:29:52,554\tWARNING util.py:315 -- The `process_trial_result` operation took 1.999 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_dbad7f3e_6_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-35/wandb/run-20230810_162951-dbad7f3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Syncing run FSR_Trainable_dbad7f3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/dbad7f3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                mae_coord 4.49947\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                mae_force 1384.01681\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               mape_coord 1.25807\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               mape_force 1.7522109518755395e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                   metric 19.96079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               rmse_coord 2.44006\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               rmse_force 1099.1727\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:       time_since_restore 10.35418\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:         time_this_iter_s 4.94064\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:             time_total_s 10.35418\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:                timestamp 1691652597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               tmae_coord 12.44279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:               tmae_force 10.77129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              tmape_coord 3332069511805173.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              tmape_force 7508102062860626.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              trmse_coord 7.69552\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:              trmse_force 12.26528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb:  View run FSR_Trainable_dbad7f3e at: https://wandb.ai/seokjin/FSR-prediction/runs/dbad7f3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69574)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162951-dbad7f3e/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_b25d1191_7_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-45/wandb/run-20230810_163002-b25d1191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Syncing run FSR_Trainable_b25d1191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b25d1191\n",
      "2023-08-10 16:30:04,790\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.088 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:04,794\tWARNING util.py:315 -- The `process_trial_result` operation took 2.092 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:04,796\tWARNING util.py:315 -- Processing trial results took 2.094 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:04,799\tWARNING util.py:315 -- The `process_trial_result` operation took 2.098 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:11,888\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.676 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:11,894\tWARNING util.py:315 -- The `process_trial_result` operation took 2.682 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:11,898\tWARNING util.py:315 -- Processing trial results took 2.686 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:11,900\tWARNING util.py:315 -- The `process_trial_result` operation took 2.689 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: \\ 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_62726c18_8_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-29-55/wandb/run-20230810_163013-62726c18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Syncing run FSR_Trainable_62726c18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/62726c18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                mae_coord 4.11484\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                mae_force 1583.52086\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               mape_coord 1.22527\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               mape_force 5250702076.23062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                   metric 6.03327\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               rmse_coord 2.41811\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               rmse_force 1105.35308\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:       time_since_restore 14.41471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:         time_this_iter_s 6.94356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:             time_total_s 14.41471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:                timestamp 1691652611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               tmae_coord 6.63427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:               tmae_force 3.97893\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              tmape_coord 608237874628312.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              tmape_force 6.43612\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              trmse_coord 3.52989\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:              trmse_force 2.50339\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb:  View run FSR_Trainable_b25d1191 at: https://wandb.ai/seokjin/FSR-prediction/runs/b25d1191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=69792)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163002-b25d1191/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163013-62726c18/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70016)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e95f5760_9_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-10_16-30-06/wandb/run-20230810_163023-e95f5760\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Syncing run FSR_Trainable_e95f5760\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e95f5760\n",
      "2023-08-10 16:30:30,783\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.424 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:30,787\tWARNING util.py:315 -- The `process_trial_result` operation took 2.428 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:30,790\tWARNING util.py:315 -- Processing trial results took 2.431 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:30,800\tWARNING util.py:315 -- The `process_trial_result` operation took 2.440 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:35,948\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.244 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:35,951\tWARNING util.py:315 -- The `process_trial_result` operation took 2.247 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:35,952\tWARNING util.py:315 -- Processing trial results took 2.249 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:35,954\tWARNING util.py:315 -- The `process_trial_result` operation took 2.251 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_9c5e27f9_10_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-30-16/wandb/run-20230810_163037-9c5e27f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Syncing run FSR_Trainable_9c5e27f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9c5e27f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)4 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                mae_coord 4.41195\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                mae_force 922.19073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               mape_coord 1.23855\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               mape_force 807567232.39468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                   metric 5.23026\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               rmse_coord 2.34542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               rmse_force 727.68872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:       time_since_restore 7.39056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:         time_this_iter_s 1.65899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:             time_total_s 7.39056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:                timestamp 1691652637\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               tmae_coord 7.12585\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:               tmae_force 2.46748\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              tmape_coord 2694752486794325.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              tmape_force 13.95905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              trmse_coord 3.42473\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:              trmse_force 1.80553\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb:  View run FSR_Trainable_9c5e27f9 at: https://wandb.ai/seokjin/FSR-prediction/runs/9c5e27f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70457)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163037-9c5e27f9/logs\n",
      "2023-08-10 16:30:47,273\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.509 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:47,279\tWARNING util.py:315 -- The `process_trial_result` operation took 2.516 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:47,281\tWARNING util.py:315 -- Processing trial results took 2.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:47,284\tWARNING util.py:315 -- The `process_trial_result` operation took 2.521 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_597b75f1_11_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-30-26/wandb/run-20230810_163047-597b75f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Syncing run FSR_Trainable_597b75f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/597b75f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                mae_coord 4.97712\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                mae_force 1486.63081\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               mape_coord 1.28824\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               mape_force 7083990146962539.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                   metric 25.13519\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               rmse_coord 2.525\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               rmse_force 1167.81056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:       time_since_restore 5.93979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:         time_this_iter_s 5.93979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:             time_total_s 5.93979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:                timestamp 1691652644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               tmae_coord 16.20568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:               tmae_force 11.07778\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              tmape_coord 6458154980083088.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              tmape_force 590541799018990.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              trmse_coord 11.53911\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:              trmse_force 13.59608\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb:  View run FSR_Trainable_597b75f1 at: https://wandb.ai/seokjin/FSR-prediction/runs/597b75f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70685)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163047-597b75f1/logs\n",
      "2023-08-10 16:30:56,494\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.816 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:56,504\tWARNING util.py:315 -- The `process_trial_result` operation took 2.827 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:30:56,506\tWARNING util.py:315 -- Processing trial results took 2.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:30:56,508\tWARNING util.py:315 -- The `process_trial_result` operation took 2.832 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_91f47775_12_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-30-38/wandb/run-20230810_163058-91f47775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Syncing run FSR_Trainable_91f47775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/91f47775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                mae_coord 4.84299\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                mae_force 1631.02518\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               mape_coord 1.4366\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               mape_force 3792578211.17606\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                   metric 6.14125\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               rmse_coord 2.47189\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               rmse_force 1114.9985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:       time_since_restore 2.79443\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:         time_this_iter_s 2.79443\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:             time_total_s 2.79443\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:                timestamp 1691652653\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               tmae_coord 7.69214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:               tmae_force 4.17672\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              tmape_coord 3152243606198551.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              tmape_force 10.193\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              trmse_coord 3.60556\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:              trmse_force 2.53569\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb:  View run FSR_Trainable_91f47775 at: https://wandb.ai/seokjin/FSR-prediction/runs/91f47775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70909)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163058-91f47775/logs\n",
      "2023-08-10 16:31:10,384\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.447 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:10,391\tWARNING util.py:315 -- The `process_trial_result` operation took 2.455 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:10,400\tWARNING util.py:315 -- Processing trial results took 2.464 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:31:10,402\tWARNING util.py:315 -- The `process_trial_result` operation took 2.466 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e6e13434_13_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-30-50/wandb/run-20230810_163110-e6e13434\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Syncing run FSR_Trainable_e6e13434\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e6e13434\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                mae_coord 4.17062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                mae_force 1570.24568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               mape_coord 1.25597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               mape_force 5129865319.67264\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                   metric 6.04615\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               rmse_coord 2.41862\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               rmse_force 1106.11166\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:       time_since_restore 10.75582\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:         time_this_iter_s 5.16177\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:             time_total_s 10.75582\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:                timestamp 1691652675\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               tmae_coord 6.68336\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:               tmae_force 3.91094\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              tmape_coord 807722597904814.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              tmape_force 6.57697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              trmse_coord 3.52828\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:              trmse_force 2.51787\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb:  View run FSR_Trainable_e6e13434 at: https://wandb.ai/seokjin/FSR-prediction/runs/e6e13434\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71137)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163110-e6e13434/logs\n",
      "2023-08-10 16:31:21,761\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.490 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:21,766\tWARNING util.py:315 -- The `process_trial_result` operation took 2.496 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:21,770\tWARNING util.py:315 -- Processing trial results took 2.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:31:21,775\tWARNING util.py:315 -- The `process_trial_result` operation took 2.505 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_b1ae2e48_14_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-31-02/wandb/run-20230810_163122-b1ae2e48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Syncing run FSR_Trainable_b1ae2e48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b1ae2e48\n",
      "2023-08-10 16:31:35,339\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.463 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:35,345\tWARNING util.py:315 -- The `process_trial_result` operation took 2.471 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:35,348\tWARNING util.py:315 -- Processing trial results took 2.474 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:31:35,351\tWARNING util.py:315 -- The `process_trial_result` operation took 2.477 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_555dffc9_15_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-31-15/wandb/run-20230810_163136-555dffc9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Syncing run FSR_Trainable_555dffc9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/555dffc9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                mae_coord 6.11193\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                mae_force 1506.67082\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               mape_coord 1.51761\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               mape_force 1.9942942107962614e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                   metric 0.89894\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               rmse_coord 2.80501\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               rmse_force 1126.00263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:       time_since_restore 75.52116\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:         time_this_iter_s 19.68756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:             time_total_s 75.52116\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:                timestamp 1691652695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               tmae_coord 1.2337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:               tmae_force 0.52214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              tmape_coord 197324527212713.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              tmape_force 666130518259756.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              trmse_coord 0.54108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:              trmse_force 0.35787\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb:  View run FSR_Trainable_e95f5760 at: https://wandb.ai/seokjin/FSR-prediction/runs/e95f5760\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=70248)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163023-e95f5760/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)4 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                mae_coord 6.52239\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                mae_force 1539.94101\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               mape_coord 1.37238\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               mape_force 2.1178524669912886e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                   metric 0.88626\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               rmse_coord 2.85259\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               rmse_force 1117.68916\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:       time_since_restore 28.0993\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:         time_this_iter_s 2.89066\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:             time_total_s 28.0993\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:                timestamp 1691652706\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               tmae_coord 1.31349\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:               tmae_force 0.55258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              tmape_coord 189259659411386.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              tmape_force 812569546900707.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              trmse_coord 0.53078\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:              trmse_force 0.35549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb:  View run FSR_Trainable_b1ae2e48 at: https://wandb.ai/seokjin/FSR-prediction/runs/b1ae2e48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71355)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163122-b1ae2e48/logs\n",
      "2023-08-10 16:31:53,931\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.702 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:53,937\tWARNING util.py:315 -- The `process_trial_result` operation took 2.708 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:31:53,939\tWARNING util.py:315 -- Processing trial results took 2.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:31:53,941\tWARNING util.py:315 -- The `process_trial_result` operation took 2.713 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_ecbdaff6_16_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-31-28/wandb/run-20230810_163154-ecbdaff6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Syncing run FSR_Trainable_ecbdaff6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ecbdaff6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)3 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                mae_coord 5.61839\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                mae_force 1498.58411\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               mape_coord 1.28315\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               mape_force 2.0420176207841096e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                   metric 0.85225\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               rmse_coord 2.69716\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               rmse_force 1109.71857\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:       time_since_restore 28.28258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:         time_this_iter_s 3.39699\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:             time_total_s 28.28258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:                timestamp 1691652720\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               tmae_coord 1.12506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:               tmae_force 0.51828\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              tmape_coord 171456614400045.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              tmape_force 679028138430196.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              trmse_coord 0.49988\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:              trmse_force 0.35237\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb:  View run FSR_Trainable_555dffc9 at: https://wandb.ai/seokjin/FSR-prediction/runs/555dffc9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71582)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163136-555dffc9/logs\n",
      "2023-08-10 16:32:06,512\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.242 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:06,519\tWARNING util.py:315 -- The `process_trial_result` operation took 3.249 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:06,522\tWARNING util.py:315 -- Processing trial results took 3.252 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:32:06,525\tWARNING util.py:315 -- The `process_trial_result` operation took 3.255 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e84164c1_17_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-31-47/wandb/run-20230810_163207-e84164c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Syncing run FSR_Trainable_e84164c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e84164c1\n",
      "2023-08-10 16:32:21,484\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.751 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:21,489\tWARNING util.py:315 -- The `process_trial_result` operation took 2.757 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:21,491\tWARNING util.py:315 -- Processing trial results took 2.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:32:21,494\tWARNING util.py:315 -- The `process_trial_result` operation took 2.762 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                mae_coord 5.72898\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                mae_force 1461.93568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               mape_coord 1.40813\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               mape_force 1.7551755050088307e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                   metric 0.85887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               rmse_coord 2.67114\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               rmse_force 1122.70412\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:       time_since_restore 30.53908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:         time_this_iter_s 3.58103\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:             time_total_s 30.53908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:                timestamp 1691652742\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               tmae_coord 1.14502\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:               tmae_force 0.49899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              tmape_coord 175445956539824.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              tmape_force 533590531498213.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              trmse_coord 0.49988\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:              trmse_force 0.35899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb:  View run FSR_Trainable_ecbdaff6 at: https://wandb.ai/seokjin/FSR-prediction/runs/ecbdaff6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=71818)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163154-ecbdaff6/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_ace5461a_18_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-31-59/wandb/run-20230810_163222-ace5461a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Syncing run FSR_Trainable_ace5461a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ace5461a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Waiting for W&B process to finish... (success).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72038)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                mae_coord 6.16012\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                mae_force 1435.61631\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               mape_coord 1.31908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               mape_force 1.2247099747012255e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                   metric 0.88492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               rmse_coord 2.76703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               rmse_force 1159.38\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:       time_since_restore 14.16868\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:         time_this_iter_s 2.72863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:             time_total_s 14.16868\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:                timestamp 1691652751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               tmae_coord 1.256\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:               tmae_force 0.50861\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              tmape_coord 160158862761546.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              tmape_force 419371279025266.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              trmse_coord 0.51179\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:              trmse_force 0.37312\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb:  View run FSR_Trainable_ace5461a at: https://wandb.ai/seokjin/FSR-prediction/runs/ace5461a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163222-ace5461a/logs\n",
      "2023-08-10 16:32:38,059\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.256 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:38,062\tWARNING util.py:315 -- The `process_trial_result` operation took 2.260 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:38,066\tWARNING util.py:315 -- Processing trial results took 2.264 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:32:38,069\tWARNING util.py:315 -- The `process_trial_result` operation took 2.266 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72264)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_b60e7c50_19_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-32-14/wandb/run-20230810_163238-b60e7c50\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Syncing run FSR_Trainable_b60e7c50\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b60e7c50\n",
      "2023-08-10 16:32:49,209\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.419 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:49,216\tWARNING util.py:315 -- The `process_trial_result` operation took 2.427 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:32:49,217\tWARNING util.py:315 -- Processing trial results took 2.428 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:32:49,219\tWARNING util.py:315 -- The `process_trial_result` operation took 2.430 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_be396f70_20_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-32-31/wandb/run-20230810_163249-be396f70\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Syncing run FSR_Trainable_be396f70\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/be396f70\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                mae_coord 6.43802\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                mae_force 1476.4327\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               mape_coord 1.37348\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               mape_force 1.612873077636065e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                   metric 0.88879\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               rmse_coord 2.83042\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               rmse_force 1136.13782\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:       time_since_restore 14.64619\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:         time_this_iter_s 3.84127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:             time_total_s 14.64619\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:                timestamp 1691652768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               tmae_coord 1.31535\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:               tmae_force 0.5161\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              tmape_coord 154889724444945.75\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              tmape_force 563466406361315.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              trmse_coord 0.52738\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:              trmse_force 0.36141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb:  View run FSR_Trainable_b60e7c50 at: https://wandb.ai/seokjin/FSR-prediction/runs/b60e7c50\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72511)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163238-b60e7c50/logs\n",
      "2023-08-10 16:33:00,924\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.429 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:00,927\tWARNING util.py:315 -- The `process_trial_result` operation took 2.434 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:00,930\tWARNING util.py:315 -- Processing trial results took 2.436 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:33:00,932\tWARNING util.py:315 -- The `process_trial_result` operation took 2.439 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_864eebf1_21_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-32-42/wandb/run-20230810_163301-864eebf1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Syncing run FSR_Trainable_864eebf1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/864eebf1\n",
      "2023-08-10 16:33:12,547\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.856 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:12,552\tWARNING util.py:315 -- The `process_trial_result` operation took 1.862 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:12,553\tWARNING util.py:315 -- Processing trial results took 1.864 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:33:12,555\tWARNING util.py:315 -- The `process_trial_result` operation took 1.865 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_0ca736a5_22_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-32-53/wandb/run-20230810_163312-0ca736a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Syncing run FSR_Trainable_0ca736a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0ca736a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                mae_coord 5.59031\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                mae_force 1467.57769\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               mape_coord 1.33947\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               mape_force 1.7415620637929636e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                   metric 0.85765\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               rmse_coord 2.65218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               rmse_force 1126.55212\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:       time_since_restore 31.03756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:         time_this_iter_s 3.60484\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:             time_total_s 31.03756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:                timestamp 1691652796\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               tmae_coord 1.11625\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:               tmae_force 0.50627\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              tmape_coord 172501744795074.28\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              tmape_force 527592357505354.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              trmse_coord 0.49534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:              trmse_force 0.36232\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb:  View run FSR_Trainable_be396f70 at: https://wandb.ai/seokjin/FSR-prediction/runs/be396f70\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72732)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163249-be396f70/logs\n",
      "2023-08-10 16:33:35,025\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.085 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:35,029\tWARNING util.py:315 -- The `process_trial_result` operation took 2.091 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:35,031\tWARNING util.py:315 -- Processing trial results took 2.092 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:33:35,034\tWARNING util.py:315 -- The `process_trial_result` operation took 2.095 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_804d9d8b_23_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-33-06/wandb/run-20230810_163335-804d9d8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Syncing run FSR_Trainable_804d9d8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/804d9d8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                mae_coord 5.76648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                mae_force 1466.30245\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               mape_coord 1.44054\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               mape_force 1.7214885767653855e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                   metric 0.86044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               rmse_coord 2.68527\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               rmse_force 1124.72106\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:       time_since_restore 28.92226\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:         time_this_iter_s 3.69158\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:             time_total_s 28.92226\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:                timestamp 1691652818\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               tmae_coord 1.13188\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:               tmae_force 0.50301\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              tmape_coord 186060989126486.84\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              tmape_force 524718193745264.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              trmse_coord 0.49956\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:              trmse_force 0.36088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb:  View run FSR_Trainable_0ca736a5 at: https://wandb.ai/seokjin/FSR-prediction/runs/0ca736a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73172)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163312-0ca736a5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=72957)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163301-864eebf1/logs\n",
      "2023-08-10 16:33:55,826\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.667 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:55,837\tWARNING util.py:315 -- The `process_trial_result` operation took 2.679 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:33:55,845\tWARNING util.py:315 -- Processing trial results took 2.686 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:33:55,854\tWARNING util.py:315 -- The `process_trial_result` operation took 2.696 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_3cac7c0f_24_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-33-28/wandb/run-20230810_163357-3cac7c0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Syncing run FSR_Trainable_3cac7c0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3cac7c0f\n",
      "2023-08-10 16:34:08,886\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.662 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:08,891\tWARNING util.py:315 -- The `process_trial_result` operation took 2.668 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:08,892\tWARNING util.py:315 -- Processing trial results took 2.670 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:34:08,894\tWARNING util.py:315 -- The `process_trial_result` operation took 2.672 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_4a2b16da_25_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-33-49/wandb/run-20230810_163409-4a2b16da\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Syncing run FSR_Trainable_4a2b16da\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4a2b16da\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                mae_coord 5.71936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                mae_force 1466.55433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               mape_coord 1.42704\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               mape_force 1.7501297837336786e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                   metric 0.8492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               rmse_coord 2.63547\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               rmse_force 1125.67898\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:       time_since_restore 57.67072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:         time_this_iter_s 3.63426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:             time_total_s 57.67072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:                timestamp 1691652868\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               tmae_coord 1.11883\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:               tmae_force 0.50321\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              tmape_coord 181201685257479.47\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              tmape_force 550923947716750.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              trmse_coord 0.4897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:              trmse_force 0.35949\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb:  View run FSR_Trainable_804d9d8b at: https://wandb.ai/seokjin/FSR-prediction/runs/804d9d8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73403)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163335-804d9d8b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                mae_coord 5.76522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                mae_force 1470.14145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               mape_coord 1.42156\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               mape_force 1.7766975762444467e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                   metric 0.85738\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               rmse_coord 2.66796\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               rmse_force 1126.17168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:       time_since_restore 45.63795\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:         time_this_iter_s 2.60084\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:             time_total_s 45.63795\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:                timestamp 1691652879\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               tmae_coord 1.13469\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:               tmae_force 0.50352\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              tmape_coord 188485883008075.12\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              tmape_force 551993272825035.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              trmse_coord 0.49767\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:              trmse_force 0.3597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb:  View run FSR_Trainable_3cac7c0f at: https://wandb.ai/seokjin/FSR-prediction/runs/3cac7c0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73647)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163357-3cac7c0f/logs\n",
      "2023-08-10 16:34:47,833\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.647 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:47,839\tWARNING util.py:315 -- The `process_trial_result` operation took 2.654 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:47,842\tWARNING util.py:315 -- Processing trial results took 2.657 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:34:47,844\tWARNING util.py:315 -- The `process_trial_result` operation took 2.659 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_8cc0bbd7_26_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-34-01/wandb/run-20230810_163448-8cc0bbd7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Syncing run FSR_Trainable_8cc0bbd7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8cc0bbd7\n",
      "2023-08-10 16:34:58,106\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.999 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:58,114\tWARNING util.py:315 -- The `process_trial_result` operation took 2.008 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:34:58,117\tWARNING util.py:315 -- Processing trial results took 2.010 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:34:58,119\tWARNING util.py:315 -- The `process_trial_result` operation took 2.012 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_8307b7bd_27_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-34-40/wandb/run-20230810_163459-8307b7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Syncing run FSR_Trainable_8307b7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8307b7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                mae_coord 5.46127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                mae_force 1452.99743\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               mape_coord 1.31771\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               mape_force 1.6498038426654415e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                   metric 0.85818\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               rmse_coord 2.66139\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               rmse_force 1124.86377\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:       time_since_restore 52.84942\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:         time_this_iter_s 7.16638\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:             time_total_s 52.84942\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:                timestamp 1691652897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               tmae_coord 1.08223\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:               tmae_force 0.49506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              tmape_coord 177100804551016.78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              tmape_force 476227441111041.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              trmse_coord 0.49602\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:              trmse_force 0.36216\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb:  View run FSR_Trainable_4a2b16da at: https://wandb.ai/seokjin/FSR-prediction/runs/4a2b16da\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=73861)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163409-4a2b16da/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb:              trmse_force \n",
      "2023-08-10 16:35:13,502\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.495 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:13,510\tWARNING util.py:315 -- The `process_trial_result` operation took 2.503 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:13,512\tWARNING util.py:315 -- Processing trial results took 2.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:35:13,517\tWARNING util.py:315 -- The `process_trial_result` operation took 2.510 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_1b9499ed_28_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-34-53/wandb/run-20230810_163514-1b9499ed\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Syncing run FSR_Trainable_1b9499ed\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1b9499ed\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                mae_coord 6.7537\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                mae_force 1833.82311\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               mape_coord 1.32875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               mape_force 3.344684595598409e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                   metric 0.98575\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               rmse_coord 3.07924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               rmse_force 1142.20188\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:       time_since_restore 3.22222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:         time_this_iter_s 3.22222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:             time_total_s 3.22222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:                timestamp 1691652911\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               tmae_coord 1.3765\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:               tmae_force 0.69985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              tmape_coord 89423157279808.27\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              tmape_force 1395095111642024.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              trmse_coord 0.59654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:              trmse_force 0.38921\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb:  View run FSR_Trainable_1b9499ed at: https://wandb.ai/seokjin/FSR-prediction/runs/1b9499ed\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163514-1b9499ed/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74568)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c9f001c0_29_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-35-07/wandb/run-20230810_163525-c9f001c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Syncing run FSR_Trainable_c9f001c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c9f001c0\n",
      "2023-08-10 16:35:27,415\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.209 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:27,419\tWARNING util.py:315 -- The `process_trial_result` operation took 2.213 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:27,423\tWARNING util.py:315 -- Processing trial results took 2.218 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:35:27,425\tWARNING util.py:315 -- The `process_trial_result` operation took 2.220 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_62905e3e_30_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-35-18/wandb/run-20230810_163536-62905e3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Syncing run FSR_Trainable_62905e3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/62905e3e\n",
      "2023-08-10 16:35:38,502\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.156 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:38,504\tWARNING util.py:315 -- The `process_trial_result` operation took 2.159 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:35:38,506\tWARNING util.py:315 -- Processing trial results took 2.161 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:35:38,507\tWARNING util.py:315 -- The `process_trial_result` operation took 2.162 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                mae_coord 5.69787\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                mae_force 1461.30305\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               mape_coord 1.4249\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               mape_force 1.7383394267220598e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                   metric 0.85782\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               rmse_coord 2.67248\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               rmse_force 1125.899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:       time_since_restore 54.65984\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:         time_this_iter_s 3.13814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:             time_total_s 54.65984\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:                timestamp 1691652941\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               tmae_coord 1.11694\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:               tmae_force 0.49805\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              tmape_coord 187917430602941.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              tmape_force 517587877778348.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              trmse_coord 0.49725\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:              trmse_force 0.36057\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb:  View run FSR_Trainable_8cc0bbd7 at: https://wandb.ai/seokjin/FSR-prediction/runs/8cc0bbd7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74108)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163448-8cc0bbd7/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:36:02,338\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.264 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:36:02,343\tWARNING util.py:315 -- The `process_trial_result` operation took 2.270 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:36:02,346\tWARNING util.py:315 -- Processing trial results took 2.273 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:36:02,348\tWARNING util.py:315 -- The `process_trial_result` operation took 2.275 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f67426eb_31_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-35-29/wandb/run-20230810_163601-f67426eb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Syncing run FSR_Trainable_f67426eb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f67426eb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                mae_coord 5.00263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                mae_force 1024.40406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               mape_coord 1.31055\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               mape_force 8.782768829123544e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                   metric 0.7278\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               rmse_coord 2.46287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               rmse_force 845.92534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:       time_since_restore 467.68696\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:         time_this_iter_s 4.69393\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:             time_total_s 467.68696\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:                timestamp 1691653023\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               tmae_coord 1.00971\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:               tmae_force 0.37154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              tmape_coord 199405634519712.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              tmape_force 363174811796639.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              trmse_coord 0.46355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:              trmse_force 0.26425\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb:  View run FSR_Trainable_26b73957 at: https://wandb.ai/seokjin/FSR-prediction/runs/26b73957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=66571)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_162900-26b73957/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_2594bb2c_32_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-35-52/wandb/run-20230810_163723-2594bb2c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Syncing run FSR_Trainable_2594bb2c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2594bb2c\n",
      "2023-08-10 16:37:28,904\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.263 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:37:28,907\tWARNING util.py:315 -- The `process_trial_result` operation took 2.267 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:37:28,910\tWARNING util.py:315 -- Processing trial results took 2.270 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:37:28,915\tWARNING util.py:315 -- The `process_trial_result` operation took 2.275 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: \\ 0.007 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: | 0.007 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                mae_coord 5.60319\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                mae_force 1448.27572\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               mape_coord 1.34507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               mape_force 1.5328624804158907e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                   metric 0.85317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               rmse_coord 2.61893\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               rmse_force 1136.18549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:       time_since_restore 105.66473\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:         time_this_iter_s 6.32562\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:             time_total_s 105.66473\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:                timestamp 1691653062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               tmae_coord 1.12151\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:               tmae_force 0.4996\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              tmape_coord 175109769248826.06\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              tmape_force 490836564865544.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              trmse_coord 0.49011\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:              trmse_force 0.36305\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb:  View run FSR_Trainable_f67426eb at: https://wandb.ai/seokjin/FSR-prediction/runs/f67426eb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75236)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163601-f67426eb/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_a7daa42d_33_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-37-15/wandb/run-20230810_163800-a7daa42d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Syncing run FSR_Trainable_a7daa42d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a7daa42d\n",
      "2023-08-10 16:38:03,001\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.248 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:38:03,004\tWARNING util.py:315 -- The `process_trial_result` operation took 2.252 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:38:03,006\tWARNING util.py:315 -- Processing trial results took 2.254 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:38:03,008\tWARNING util.py:315 -- The `process_trial_result` operation took 2.256 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                mae_coord 5.63964\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                mae_force 1449.3341\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               mape_coord 1.35404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               mape_force 1.526970325830578e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                   metric 0.85389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               rmse_coord 2.61885\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               rmse_force 1136.6806\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:       time_since_restore 198.32908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:         time_this_iter_s 5.59449\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:             time_total_s 198.32908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:                timestamp 1691653133\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               tmae_coord 1.12873\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:               tmae_force 0.50095\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              tmape_coord 175622049907212.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              tmape_force 491080356095670.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              trmse_coord 0.49046\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:              trmse_force 0.36343\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb:  View run FSR_Trainable_62905e3e at: https://wandb.ai/seokjin/FSR-prediction/runs/62905e3e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75004)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163536-62905e3e/logs\n",
      "2023-08-10 16:39:12,743\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.632 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:39:12,746\tWARNING util.py:315 -- The `process_trial_result` operation took 2.635 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:39:12,750\tWARNING util.py:315 -- Processing trial results took 2.640 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:39:12,752\tWARNING util.py:315 -- The `process_trial_result` operation took 2.642 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_5d8ca6cc_34_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-37-53/wandb/run-20230810_163913-5d8ca6cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Syncing run FSR_Trainable_5d8ca6cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/5d8ca6cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                mae_coord 5.61093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                mae_force 1444.48739\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               mape_coord 1.38088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               mape_force 1.474846842640852e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                   metric 0.85474\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               rmse_coord 2.62252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               rmse_force 1139.77141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:       time_since_restore 184.93543\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:         time_this_iter_s 11.47344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:             time_total_s 184.93543\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:                timestamp 1691653223\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               tmae_coord 1.11467\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:               tmae_force 0.49864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              tmape_coord 175182033827920.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              tmape_force 470828271927837.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              trmse_coord 0.49032\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:              trmse_force 0.36442\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb:  View run FSR_Trainable_2594bb2c at: https://wandb.ai/seokjin/FSR-prediction/runs/2594bb2c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75503)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163723-2594bb2c/logs\n",
      "2023-08-10 16:40:42,526\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.135 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:40:42,530\tWARNING util.py:315 -- The `process_trial_result` operation took 2.139 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:40:42,531\tWARNING util.py:315 -- Processing trial results took 2.141 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:40:42,534\tWARNING util.py:315 -- The `process_trial_result` operation took 2.144 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_32d31ca1_35_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-39-05/wandb/run-20230810_164043-32d31ca1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Syncing run FSR_Trainable_32d31ca1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/32d31ca1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                mae_coord 4.67974\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                mae_force 1447.3124\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               mape_coord 1.28051\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               mape_force 2.033791754035085e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                   metric 21.03337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               rmse_coord 2.4507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               rmse_force 1202.29701\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:       time_since_restore 4.83285\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:         time_this_iter_s 4.83285\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:             time_total_s 4.83285\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:                timestamp 1691653240\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               tmae_coord 14.05327\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:               tmae_force 12.06342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              tmape_coord 7706660306918327.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              tmape_force 8948137908918268.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              trmse_coord 8.05382\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:              trmse_force 12.97955\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb:  View run FSR_Trainable_32d31ca1 at: https://wandb.ai/seokjin/FSR-prediction/runs/32d31ca1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76273)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164043-32d31ca1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-10 16:41:04,466\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.071 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:04,471\tWARNING util.py:315 -- The `process_trial_result` operation took 2.077 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:04,472\tWARNING util.py:315 -- Processing trial results took 2.079 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:41:04,476\tWARNING util.py:315 -- The `process_trial_result` operation took 2.082 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                mae_coord 4.7695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                mae_force 1520.57913\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               mape_coord 1.28127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               mape_force 2.182318402940343e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                   metric 0.81648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               rmse_coord 2.46772\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               rmse_force 1110.61547\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:       time_since_restore 111.09943\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:         time_this_iter_s 4.08137\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:             time_total_s 111.09943\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:                timestamp 1691653261\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               tmae_coord 0.96284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:               tmae_force 0.52932\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              tmape_coord 206495791220217.62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              tmape_force 746987551096335.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              trmse_coord 0.46455\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:              trmse_force 0.35193\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb:  View run FSR_Trainable_5d8ca6cc at: https://wandb.ai/seokjin/FSR-prediction/runs/5d8ca6cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76004)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163913-5d8ca6cc/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_ae274a48_36_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-40-35/wandb/run-20230810_164105-ae274a48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Syncing run FSR_Trainable_ae274a48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ae274a48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                mae_coord 4.85246\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                mae_force 1511.90937\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               mape_coord 1.29175\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               mape_force 2.114907435759413e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                   metric 0.82001\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               rmse_coord 2.48447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               rmse_force 1111.93722\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:       time_since_restore 197.22347\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:         time_this_iter_s 6.84404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:             time_total_s 197.22347\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:                timestamp 1691653278\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               tmae_coord 0.97918\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:               tmae_force 0.52679\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              tmape_coord 204480323672621.84\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              tmape_force 727299036973680.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              trmse_coord 0.46751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:              trmse_force 0.3525\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb:  View run FSR_Trainable_a7daa42d at: https://wandb.ai/seokjin/FSR-prediction/runs/a7daa42d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=75744)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163800-a7daa42d/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_bd235651_37_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-40-54/wandb/run-20230810_164122-bd235651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Syncing run FSR_Trainable_bd235651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bd235651\n",
      "2023-08-10 16:41:24,853\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.475 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:24,861\tWARNING util.py:315 -- The `process_trial_result` operation took 2.483 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:24,863\tWARNING util.py:315 -- Processing trial results took 2.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:41:24,866\tWARNING util.py:315 -- The `process_trial_result` operation took 2.489 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:37,383\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.889 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:37,388\tWARNING util.py:315 -- The `process_trial_result` operation took 2.895 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:41:37,390\tWARNING util.py:315 -- Processing trial results took 2.897 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:41:37,392\tWARNING util.py:315 -- The `process_trial_result` operation took 2.900 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_0d2c4fda_38_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-41-14/wandb/run-20230810_164139-0d2c4fda\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Syncing run FSR_Trainable_0d2c4fda\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0d2c4fda\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                mae_coord 4.88406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                mae_force 1511.92468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               mape_coord 1.30092\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               mape_force 2.1295789566012754e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                   metric 0.8205\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               rmse_coord 2.48398\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               rmse_force 1112.59296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:       time_since_restore 85.48924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:         time_this_iter_s 2.70097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:             time_total_s 85.48924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:                timestamp 1691653380\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               tmae_coord 0.98798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:               tmae_force 0.52531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              tmape_coord 206774741943804.16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              tmape_force 722996406220235.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              trmse_coord 0.46775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:              trmse_force 0.35275\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb:  View run FSR_Trainable_0d2c4fda at: https://wandb.ai/seokjin/FSR-prediction/runs/0d2c4fda\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76959)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164139-0d2c4fda/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                mae_coord 5.36869\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                mae_force 1442.24364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               mape_coord 1.40267\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               mape_force 1.4404274911680056e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                   metric 0.84686\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               rmse_coord 2.56244\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               rmse_force 1142.41852\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:       time_since_restore 111.80038\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:         time_this_iter_s 7.28324\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:             time_total_s 111.80038\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:                timestamp 1691653389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               tmae_coord 1.07592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:               tmae_force 0.49785\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              tmape_coord 202427652851762.78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              tmape_force 458992990826522.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              trmse_coord 0.48155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:              trmse_force 0.36531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb:  View run FSR_Trainable_bd235651 at: https://wandb.ai/seokjin/FSR-prediction/runs/bd235651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76731)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164122-bd235651/logs\n",
      "2023-08-10 16:43:19,812\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.241 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:19,815\tWARNING util.py:315 -- The `process_trial_result` operation took 2.245 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:19,816\tWARNING util.py:315 -- Processing trial results took 2.246 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:43:19,817\tWARNING util.py:315 -- The `process_trial_result` operation took 2.247 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_95ce9ecd_39_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-41-30/wandb/run-20230810_164319-95ce9ecd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Syncing run FSR_Trainable_95ce9ecd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/95ce9ecd\n",
      "2023-08-10 16:43:30,267\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.475 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:30,271\tWARNING util.py:315 -- The `process_trial_result` operation took 2.480 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:30,274\tWARNING util.py:315 -- Processing trial results took 2.482 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:43:30,276\tWARNING util.py:315 -- The `process_trial_result` operation took 2.484 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_5525c5fb_40_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-43-12/wandb/run-20230810_164332-5525c5fb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Syncing run FSR_Trainable_5525c5fb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/5525c5fb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)4 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                mae_coord 4.95632\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                mae_force 1356.18323\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               mape_coord 1.34222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               mape_force 2.0133168633534157e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                   metric 20.73904\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               rmse_coord 2.49746\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               rmse_force 1105.38741\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:       time_since_restore 3.38925\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:         time_this_iter_s 3.38925\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:             time_total_s 3.38925\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:                timestamp 1691653407\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               tmae_coord 15.24948\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:               tmae_force 11.05017\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              tmape_coord 1.083303509648136e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              tmape_force 8526747448326640.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              trmse_coord 8.45413\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:              trmse_force 12.2849\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb:  View run FSR_Trainable_5525c5fb at: https://wandb.ai/seokjin/FSR-prediction/runs/5525c5fb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77465)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164332-5525c5fb/logs\n",
      "2023-08-10 16:43:48,189\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.452 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:48,193\tWARNING util.py:315 -- The `process_trial_result` operation took 2.457 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:43:48,196\tWARNING util.py:315 -- Processing trial results took 2.460 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:43:48,198\tWARNING util.py:315 -- The `process_trial_result` operation took 2.462 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_10524936_41_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-43-24/wandb/run-20230810_164349-10524936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Syncing run FSR_Trainable_10524936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/10524936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                mae_coord 5.13763\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                mae_force 1341.889\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               mape_coord 1.32825\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               mape_force 3.844829913403161e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                   metric 20.91391\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               rmse_coord 2.5158\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               rmse_force 1086.76344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:       time_since_restore 3.24751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:         time_this_iter_s 3.24751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:             time_total_s 3.24751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:                timestamp 1691653425\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               tmae_coord 15.64956\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:               tmae_force 12.86252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              tmape_coord 1.2460380828720518e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              tmape_force 1.6132325130156504e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              trmse_coord 8.42552\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:              trmse_force 12.48839\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb:  View run FSR_Trainable_10524936 at: https://wandb.ai/seokjin/FSR-prediction/runs/10524936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77694)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164349-10524936/logs\n",
      "2023-08-10 16:44:07,948\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.906 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:44:07,958\tWARNING util.py:315 -- The `process_trial_result` operation took 2.917 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:44:07,959\tWARNING util.py:315 -- Processing trial results took 2.918 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:44:07,961\tWARNING util.py:315 -- The `process_trial_result` operation took 2.920 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_487e3dc8_42_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-43-42/wandb/run-20230810_164409-487e3dc8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Syncing run FSR_Trainable_487e3dc8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/487e3dc8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                mae_coord 4.94143\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                mae_force 1502.96383\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               mape_coord 1.31428\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               mape_force 2.0573148353049866e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                   metric 0.82235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               rmse_coord 2.49308\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               rmse_force 1114.41982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:       time_since_restore 207.44303\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:         time_this_iter_s 6.699\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:             time_total_s 207.44303\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:                timestamp 1691653469\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               tmae_coord 0.99457\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:               tmae_force 0.52309\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              tmape_coord 206224655160460.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              tmape_force 703875918256048.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              trmse_coord 0.46877\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:              trmse_force 0.35358\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb:  View run FSR_Trainable_ae274a48 at: https://wandb.ai/seokjin/FSR-prediction/runs/ae274a48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=76502)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164105-ae274a48/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_0a4bcaa3_43_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-44-01/wandb/run-20230810_164448-0a4bcaa3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Syncing run FSR_Trainable_0a4bcaa3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0a4bcaa3\n",
      "2023-08-10 16:44:51,301\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.108 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:44:51,303\tWARNING util.py:315 -- The `process_trial_result` operation took 2.111 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:44:51,306\tWARNING util.py:315 -- Processing trial results took 2.114 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:44:51,308\tWARNING util.py:315 -- The `process_trial_result` operation took 2.116 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                mae_coord 5.35259\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                mae_force 1472.15062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               mape_coord 1.34902\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               mape_force 1.7415037428404544e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                   metric 0.85929\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               rmse_coord 2.63176\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               rmse_force 1133.908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:       time_since_restore 29.21144\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:         time_this_iter_s 6.94429\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:             time_total_s 29.21144\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:                timestamp 1691653512\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               tmae_coord 1.07617\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:               tmae_force 0.50798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              tmape_coord 201318310541384.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              tmape_force 571235877445069.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              trmse_coord 0.49936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:              trmse_force 0.35993\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb:  View run FSR_Trainable_0a4bcaa3 at: https://wandb.ai/seokjin/FSR-prediction/runs/0a4bcaa3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78164)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164448-0a4bcaa3/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:45:31,732\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.122 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:45:31,736\tWARNING util.py:315 -- The `process_trial_result` operation took 2.127 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:45:31,739\tWARNING util.py:315 -- Processing trial results took 2.130 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:45:31,741\tWARNING util.py:315 -- The `process_trial_result` operation took 2.132 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_2a7340c1_44_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-44-41/wandb/run-20230810_164531-2a7340c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Syncing run FSR_Trainable_2a7340c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2a7340c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                mae_coord 4.2268\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                mae_force 1296.79182\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               mape_coord 1.19988\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               mape_force 4757098453.93595\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                   metric 5.79846\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               rmse_coord 2.40199\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               rmse_force 1014.49281\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:       time_since_restore 5.83635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:         time_this_iter_s 5.83635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:             time_total_s 5.83635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:                timestamp 1691653529\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               tmae_coord 6.80791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:               tmae_force 3.12523\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              tmape_coord 1346173303662641.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              tmape_force 8.61141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              trmse_coord 3.49149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:              trmse_force 2.30697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb:  View run FSR_Trainable_2a7340c1 at: https://wandb.ai/seokjin/FSR-prediction/runs/2a7340c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78406)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164531-2a7340c1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77247)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164319-95ce9ecd/logs\n",
      "2023-08-10 16:45:49,421\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.762 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:45:49,428\tWARNING util.py:315 -- The `process_trial_result` operation took 2.770 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:45:49,430\tWARNING util.py:315 -- Processing trial results took 2.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:45:49,432\tWARNING util.py:315 -- The `process_trial_result` operation took 2.774 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c8fad061_45_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-45-23/wandb/run-20230810_164551-c8fad061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Syncing run FSR_Trainable_c8fad061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c8fad061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                mae_coord 4.83341\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                mae_force 1180.94125\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               mape_coord 1.3344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               mape_force 3218816245.5636\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                   metric 5.73359\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               rmse_coord 2.43788\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               rmse_force 950.80595\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:       time_since_restore 3.62641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:         time_this_iter_s 3.62641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:             time_total_s 3.62641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:                timestamp 1691653546\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               tmae_coord 7.80032\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:               tmae_force 2.9719\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              tmape_coord 3386736798112424.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              tmape_force 13.91113\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              trmse_coord 3.5692\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:              trmse_force 2.1644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb:  View run FSR_Trainable_c8fad061 at: https://wandb.ai/seokjin/FSR-prediction/runs/c8fad061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78649)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164551-c8fad061/logs\n",
      "2023-08-10 16:46:02,093\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.197 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:46:02,099\tWARNING util.py:315 -- The `process_trial_result` operation took 2.203 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:46:02,101\tWARNING util.py:315 -- Processing trial results took 2.205 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:46:02,103\tWARNING util.py:315 -- The `process_trial_result` operation took 2.208 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c3aa4657_46_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-45-43/wandb/run-20230810_164602-c3aa4657\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Syncing run FSR_Trainable_c3aa4657\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c3aa4657\n",
      "2023-08-10 16:46:14,633\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.163 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:46:14,637\tWARNING util.py:315 -- The `process_trial_result` operation took 2.168 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:46:14,652\tWARNING util.py:315 -- Processing trial results took 2.183 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:46:14,655\tWARNING util.py:315 -- The `process_trial_result` operation took 2.185 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_862b96c2_47_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-45-54/wandb/run-20230810_164614-862b96c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Syncing run FSR_Trainable_862b96c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/862b96c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                mae_coord 4.46755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                mae_force 1553.39365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               mape_coord 1.24995\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               mape_force 2.3905737694662047e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                   metric 0.81274\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               rmse_coord 2.44907\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               rmse_force 1107.80168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:       time_since_restore 238.16952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:         time_this_iter_s 4.82371\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:             time_total_s 238.16952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:                timestamp 1691653688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               tmae_coord 0.90687\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:               tmae_force 0.54517\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              tmape_coord 205562609043679.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              tmape_force 843434079289825.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              trmse_coord 0.46269\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:              trmse_force 0.35005\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb:  View run FSR_Trainable_487e3dc8 at: https://wandb.ai/seokjin/FSR-prediction/runs/487e3dc8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=77921)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164409-487e3dc8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164602-c3aa4657/logs\n",
      "2023-08-10 16:48:34,779\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.392 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:48:34,786\tWARNING util.py:315 -- The `process_trial_result` operation took 3.400 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:48:34,788\tWARNING util.py:315 -- Processing trial results took 3.402 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:48:34,790\tWARNING util.py:315 -- The `process_trial_result` operation took 3.404 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=78868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_1e628a56_48_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-46-06/wandb/run-20230810_164837-1e628a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Syncing run FSR_Trainable_1e628a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1e628a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_fb056e32_49_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-48-23/wandb/run-20230810_164851-fb056e32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Syncing run FSR_Trainable_fb056e32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fb056e32\n",
      "2023-08-10 16:48:57,159\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.584 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:48:57,162\tWARNING util.py:315 -- The `process_trial_result` operation took 2.588 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:48:57,165\tWARNING util.py:315 -- Processing trial results took 2.591 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:48:57,167\tWARNING util.py:315 -- The `process_trial_result` operation took 2.593 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                mae_coord 15.42271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                mae_force 1522.07306\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               mape_coord 2.54935\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               mape_force 1.8087439578061821e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                   metric 1.43825\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               rmse_coord 5.25955\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               rmse_force 1152.33408\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:       time_since_restore 14.56698\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:         time_this_iter_s 14.56698\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:             time_total_s 14.56698\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:                timestamp 1691653734\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               tmae_coord 3.26517\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:               tmae_force 0.57089\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              tmape_coord 113744478275512.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              tmape_force 834305418379773.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              trmse_coord 1.07345\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:              trmse_force 0.3648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb:  View run FSR_Trainable_fb056e32 at: https://wandb.ai/seokjin/FSR-prediction/runs/fb056e32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79618)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164851-fb056e32/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)8 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                mae_coord 5.45641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                mae_force 942.82347\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               mape_coord 1.36952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               mape_force 6.87405845849771e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                   metric 0.72802\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               rmse_coord 2.53433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               rmse_force 781.63156\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:       time_since_restore 801.61791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:         time_this_iter_s 7.93368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:             time_total_s 801.61791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:                timestamp 1691653745\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               tmae_coord 1.07604\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:               tmae_force 0.34815\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              tmape_coord 169780091567709.66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              tmape_force 297892891673089.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              trmse_coord 0.47277\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:              trmse_force 0.25524\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb:  View run FSR_Trainable_c9f001c0 at: https://wandb.ai/seokjin/FSR-prediction/runs/c9f001c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=74784)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_163525-c9f001c0/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e5085378_50_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-48-40/wandb/run-20230810_164921-e5085378\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Syncing run FSR_Trainable_e5085378\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e5085378\n",
      "2023-08-10 16:49:27,180\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.731 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:27,187\tWARNING util.py:315 -- The `process_trial_result` operation took 2.739 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:27,188\tWARNING util.py:315 -- Processing trial results took 2.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:49:27,191\tWARNING util.py:315 -- The `process_trial_result` operation took 2.743 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                mae_coord 15.8516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                mae_force 1556.96355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               mape_coord 2.61892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               mape_force 2.112979712459481e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                   metric 1.43314\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               rmse_coord 5.30412\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               rmse_force 1113.19192\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:       time_since_restore 12.42361\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:         time_this_iter_s 12.42361\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:             time_total_s 12.42361\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:                timestamp 1691653764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               tmae_coord 3.34399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:               tmae_force 0.5534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              tmape_coord 83103925846907.22\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              tmape_force 729818451603931.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              trmse_coord 1.07489\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:              trmse_force 0.35825\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb:  View run FSR_Trainable_e5085378 at: https://wandb.ai/seokjin/FSR-prediction/runs/e5085378\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79868)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164921-e5085378/logs\n",
      "2023-08-10 16:49:34,530\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.420 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:34,536\tWARNING util.py:315 -- The `process_trial_result` operation took 3.427 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:34,540\tWARNING util.py:315 -- Processing trial results took 3.430 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:49:34,542\tWARNING util.py:315 -- The `process_trial_result` operation took 3.433 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_0cc277c6_51_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-49-12/wandb/run-20230810_164936-0cc277c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Syncing run FSR_Trainable_0cc277c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0cc277c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                mae_coord 4.60991\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                mae_force 1467.64899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               mape_coord 1.33387\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               mape_force 6.974335364714369e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                   metric 21.18164\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               rmse_coord 2.44394\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               rmse_force 1182.67721\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:       time_since_restore 3.77236\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:         time_this_iter_s 3.77236\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:             time_total_s 3.77236\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:                timestamp 1691653771\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               tmae_coord 12.60926\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:               tmae_force 11.34334\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              tmape_coord 3935981100342043.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              tmape_force 2483413870328896.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              trmse_coord 7.77869\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:              trmse_force 13.40295\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb:  View run FSR_Trainable_0cc277c6 at: https://wandb.ai/seokjin/FSR-prediction/runs/0cc277c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80086)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164936-0cc277c6/logs\n",
      "2023-08-10 16:49:47,298\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.820 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:47,304\tWARNING util.py:315 -- The `process_trial_result` operation took 2.827 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:49:47,306\tWARNING util.py:315 -- Processing trial results took 2.828 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:49:47,308\tWARNING util.py:315 -- The `process_trial_result` operation took 2.830 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_718568fc_52_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-49-27/wandb/run-20230810_164950-718568fc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Syncing run FSR_Trainable_718568fc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/718568fc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                mae_coord 4.50555\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                mae_force 1418.19654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               mape_coord 1.26895\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               mape_force 1.9155915321845308e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                   metric 21.30133\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               rmse_coord 2.4479\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               rmse_force 1146.79942\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:       time_since_restore 3.06246\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:         time_this_iter_s 3.06246\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:             time_total_s 3.06246\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:                timestamp 1691653784\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               tmae_coord 12.57089\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:               tmae_force 11.04671\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              tmape_coord 3749868646411267.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              tmape_force 1553702466911900.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              trmse_coord 7.81545\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:              trmse_force 13.48588\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb:  View run FSR_Trainable_718568fc at: https://wandb.ai/seokjin/FSR-prediction/runs/718568fc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80315)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164950-718568fc/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_d6846f19_53_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-49-41/wandb/run-20230810_165004-d6846f19\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Syncing run FSR_Trainable_d6846f19\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d6846f19\n",
      "2023-08-10 16:50:06,066\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.790 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:06,071\tWARNING util.py:315 -- The `process_trial_result` operation took 2.796 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:06,073\tWARNING util.py:315 -- Processing trial results took 2.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:50:06,075\tWARNING util.py:315 -- The `process_trial_result` operation took 2.800 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                mae_coord 4.30377\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                mae_force 1264.74137\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               mape_coord 1.25442\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               mape_force 4307851817.81325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                   metric 5.75094\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               rmse_coord 2.38191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               rmse_force 999.92876\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:       time_since_restore 8.43695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:         time_this_iter_s 8.43695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:             time_total_s 8.43695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:                timestamp 1691653803\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               tmae_coord 6.87788\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:               tmae_force 2.99677\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              tmape_coord 1665900556797681.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              tmape_force 8.03606\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              trmse_coord 3.47463\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:              trmse_force 2.27631\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb:  View run FSR_Trainable_d6846f19 at: https://wandb.ai/seokjin/FSR-prediction/runs/d6846f19\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80538)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165004-d6846f19/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_ccb545df_54_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-49-54/wandb/run-20230810_165018-ccb545df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Syncing run FSR_Trainable_ccb545df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ccb545df\n",
      "2023-08-10 16:50:24,230\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.263 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:24,235\tWARNING util.py:315 -- The `process_trial_result` operation took 2.268 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:24,235\tWARNING util.py:315 -- Processing trial results took 2.269 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:50:24,236\tWARNING util.py:315 -- The `process_trial_result` operation took 2.270 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                mae_coord 4.83233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                mae_force 1239.0129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               mape_coord 1.26688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               mape_force 4062453283.55332\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                   metric 5.90106\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               rmse_coord 2.50103\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               rmse_force 976.59837\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:       time_since_restore 12.88587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:         time_this_iter_s 12.88587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:             time_total_s 12.88587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:                timestamp 1691653821\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               tmae_coord 7.85713\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:               tmae_force 2.98665\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              tmape_coord 3375002074418102.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              tmape_force 10.6358\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              trmse_coord 3.7068\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:              trmse_force 2.19426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb:  View run FSR_Trainable_ccb545df at: https://wandb.ai/seokjin/FSR-prediction/runs/ccb545df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80762)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165018-ccb545df/logs\n",
      "2023-08-10 16:50:31,839\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.615 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:31,850\tWARNING util.py:315 -- The `process_trial_result` operation took 2.628 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:31,852\tWARNING util.py:315 -- Processing trial results took 2.630 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:50:31,853\tWARNING util.py:315 -- The `process_trial_result` operation took 2.632 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_6ad6b355_55_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-50-09/wandb/run-20230810_165035-6ad6b355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Syncing run FSR_Trainable_6ad6b355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6ad6b355\n",
      "2023-08-10 16:50:45,262\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.471 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:45,265\tWARNING util.py:315 -- The `process_trial_result` operation took 2.476 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:50:45,267\tWARNING util.py:315 -- Processing trial results took 2.477 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:50:45,268\tWARNING util.py:315 -- The `process_trial_result` operation took 2.478 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_0f412368_56_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-50-24/wandb/run-20230810_165046-0f412368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Syncing run FSR_Trainable_0f412368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0f412368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                mae_coord 5.11881\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                mae_force 1491.87153\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               mape_coord 1.30753\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               mape_force 1.9456230885272074e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                   metric 0.83147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               rmse_coord 2.53279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               rmse_force 1120.09313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:       time_since_restore 55.64701\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:         time_this_iter_s 3.33329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:             time_total_s 55.64701\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:                timestamp 1691653897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               tmae_coord 1.03144\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:               tmae_force 0.51979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              tmape_coord 205764213891206.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              tmape_force 670248366496797.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              trmse_coord 0.47582\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:              trmse_force 0.35566\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb:  View run FSR_Trainable_0f412368 at: https://wandb.ai/seokjin/FSR-prediction/runs/0f412368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81213)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165046-0f412368/logs\n",
      "2023-08-10 16:51:58,319\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.105 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:51:58,323\tWARNING util.py:315 -- The `process_trial_result` operation took 3.110 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:51:58,326\tWARNING util.py:315 -- Processing trial results took 3.113 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:51:58,328\tWARNING util.py:315 -- The `process_trial_result` operation took 3.115 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_68a03a62_57_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-50-38/wandb/run-20230810_165200-68a03a62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Syncing run FSR_Trainable_68a03a62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/68a03a62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)8 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                mae_coord 4.6631\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                mae_force 1532.48582\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               mape_coord 1.27072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               mape_force 2.2559149764242714e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                   metric 0.81365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               rmse_coord 2.45518\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               rmse_force 1110.36962\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:       time_since_restore 350.47979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:         time_this_iter_s 4.9994\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:             time_total_s 350.47979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:                timestamp 1691653934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               tmae_coord 0.94143\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:               tmae_force 0.53636\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              tmape_coord 205073177842412.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              tmape_force 790023426008292.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              trmse_coord 0.46232\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:              trmse_force 0.35134\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb:  View run FSR_Trainable_862b96c2 at: https://wandb.ai/seokjin/FSR-prediction/runs/862b96c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79088)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164614-862b96c2/logs\n",
      "2023-08-10 16:52:35,009\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.711 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:52:35,015\tWARNING util.py:315 -- The `process_trial_result` operation took 2.717 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:52:35,016\tWARNING util.py:315 -- Processing trial results took 2.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:52:35,017\tWARNING util.py:315 -- The `process_trial_result` operation took 2.719 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_be818bb5_58_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-51-51/wandb/run-20230810_165239-be818bb5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Syncing run FSR_Trainable_be818bb5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/be818bb5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                mae_coord 4.81211\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                mae_force 1518.61227\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               mape_coord 1.28504\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               mape_force 2.1545413832520287e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                   metric 0.82043\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               rmse_coord 2.48097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               rmse_force 1113.75494\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:       time_since_restore 128.03497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:         time_this_iter_s 4.0618\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:             time_total_s 128.03497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:                timestamp 1691653959\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               tmae_coord 0.97176\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:               tmae_force 0.5291\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              tmape_coord 204712861426224.62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              tmape_force 739493131637521.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              trmse_coord 0.46741\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:              trmse_force 0.35302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb:  View run FSR_Trainable_6ad6b355 at: https://wandb.ai/seokjin/FSR-prediction/runs/6ad6b355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=80982)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165035-6ad6b355/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_eb0d0c6e_59_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-52-28/wandb/run-20230810_165301-eb0d0c6e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Syncing run FSR_Trainable_eb0d0c6e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/eb0d0c6e\n",
      "2023-08-10 16:53:11,679\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.279 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:53:11,681\tWARNING util.py:315 -- The `process_trial_result` operation took 2.282 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:53:11,684\tWARNING util.py:315 -- Processing trial results took 2.285 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:53:11,686\tWARNING util.py:315 -- The `process_trial_result` operation took 2.287 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                mae_coord 5.36416\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                mae_force 1466.05833\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               mape_coord 1.37308\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               mape_force 1.7041702322082952e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                   metric 0.85178\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               rmse_coord 2.60487\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               rmse_force 1130.19696\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:       time_since_restore 59.30281\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:         time_this_iter_s 14.27528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:             time_total_s 59.30281\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:                timestamp 1691654034\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               tmae_coord 1.07878\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:               tmae_force 0.50656\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              tmape_coord 203274139787604.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              tmape_force 559427744599282.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              trmse_coord 0.4921\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:              trmse_force 0.35968\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb:  View run FSR_Trainable_eb0d0c6e at: https://wandb.ai/seokjin/FSR-prediction/runs/eb0d0c6e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81956)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165301-eb0d0c6e/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f2266733_60_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-52-53/wandb/run-20230810_165417-f2266733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Syncing run FSR_Trainable_f2266733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f2266733\n",
      "2023-08-10 16:54:19,358\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.289 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:54:19,361\tWARNING util.py:315 -- The `process_trial_result` operation took 2.293 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:54:19,364\tWARNING util.py:315 -- Processing trial results took 2.296 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:54:19,366\tWARNING util.py:315 -- The `process_trial_result` operation took 2.298 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: \\ 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                mae_coord 5.5133\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                mae_force 1446.317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               mape_coord 1.40062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               mape_force 1.503032522354205e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                   metric 0.86749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               rmse_coord 2.66414\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               rmse_force 1140.256\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:       time_since_restore 19.24853\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:         time_this_iter_s 10.43068\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:             time_total_s 19.24853\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:                timestamp 1691654069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               tmae_coord 1.1105\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:               tmae_force 0.49901\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              tmape_coord 202177996944773.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              tmape_force 487815194852190.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              trmse_coord 0.50396\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:              trmse_force 0.36353\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb:  View run FSR_Trainable_f2266733 at: https://wandb.ai/seokjin/FSR-prediction/runs/f2266733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82219)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165417-f2266733/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:55:00,459\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.869 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:55:00,462\tWARNING util.py:315 -- The `process_trial_result` operation took 2.873 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:55:00,464\tWARNING util.py:315 -- Processing trial results took 2.875 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:55:00,465\tWARNING util.py:315 -- The `process_trial_result` operation took 2.876 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_a0f0109f_61_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-54-08/wandb/run-20230810_165500-a0f0109f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Syncing run FSR_Trainable_a0f0109f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a0f0109f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                mae_coord 4.54054\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                mae_force 1540.2016\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               mape_coord 1.25274\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               mape_force 2.3042616152975306e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                   metric 0.81208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               rmse_coord 2.44567\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               rmse_force 1109.29497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:       time_since_restore 210.30265\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:         time_this_iter_s 2.8035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:             time_total_s 210.30265\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:                timestamp 1691654136\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               tmae_coord 0.9183\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:               tmae_force 0.5394\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              tmape_coord 204650979977734.28\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              tmape_force 807411512709346.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              trmse_coord 0.46108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:              trmse_force 0.35099\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb:  View run FSR_Trainable_68a03a62 at: https://wandb.ai/seokjin/FSR-prediction/runs/68a03a62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81481)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165200-68a03a62/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 16:56:02,731\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.652 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:02,736\tWARNING util.py:315 -- The `process_trial_result` operation took 2.659 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:02,739\tWARNING util.py:315 -- Processing trial results took 2.662 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:56:02,741\tWARNING util.py:315 -- The `process_trial_result` operation took 2.664 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_8ce7ea94_62_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-54-48/wandb/run-20230810_165601-8ce7ea94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Syncing run FSR_Trainable_8ce7ea94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8ce7ea94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)5 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                mae_coord 13.16775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                mae_force 1665.25998\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               mape_coord 2.26635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               mape_force 2.0163164709040005e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                   metric 1.29513\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               rmse_coord 4.59625\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               rmse_force 1187.44119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:       time_since_restore 7.9093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:         time_this_iter_s 7.9093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:             time_total_s 7.9093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:                timestamp 1691654160\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               tmae_coord 2.73937\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:               tmae_force 0.5999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              tmape_coord 104601669822847.61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              tmape_force 775097242616610.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              trmse_coord 0.91384\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:              trmse_force 0.38129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb:  View run FSR_Trainable_8ce7ea94 at: https://wandb.ai/seokjin/FSR-prediction/runs/8ce7ea94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82715)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165601-8ce7ea94/logs\n",
      "2023-08-10 16:56:25,784\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.932 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:25,790\tWARNING util.py:315 -- The `process_trial_result` operation took 2.939 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:25,792\tWARNING util.py:315 -- Processing trial results took 2.942 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:56:25,795\tWARNING util.py:315 -- The `process_trial_result` operation took 2.945 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_281c7f09_63_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-55-52/wandb/run-20230810_165630-281c7f09\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Syncing run FSR_Trainable_281c7f09\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/281c7f09\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                mae_coord 10.8857\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                mae_force 1656.5733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               mape_coord 1.99841\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               mape_force 1.8557604161728343e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                   metric 1.17594\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               rmse_coord 3.79727\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               rmse_force 1242.16499\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:       time_since_restore 5.94887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:         time_this_iter_s 5.94887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:             time_total_s 5.94887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:                timestamp 1691654182\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               tmae_coord 2.32268\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:               tmae_force 0.64365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              tmape_coord 154267570822621.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              tmape_force 909568875080656.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              trmse_coord 0.77768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:              trmse_force 0.39827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb:  View run FSR_Trainable_281c7f09 at: https://wandb.ai/seokjin/FSR-prediction/runs/281c7f09\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82946)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165630-281c7f09/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165239-be818bb5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=81722)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: / 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                mae_coord 5.2845\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                mae_force 1462.05952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               mape_coord 1.34942\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               mape_force 1.7850272075979395e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                   metric 0.83521\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               rmse_coord 2.55035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               rmse_force 1118.68759\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:       time_since_restore 104.74065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:         time_this_iter_s 6.28758\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:             time_total_s 104.74065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:                timestamp 1691654200\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               tmae_coord 1.05947\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:               tmae_force 0.50589\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              tmape_coord 205627281861291.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              tmape_force 584214144391206.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              trmse_coord 0.47872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:              trmse_force 0.35649\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb:  View run FSR_Trainable_a0f0109f at: https://wandb.ai/seokjin/FSR-prediction/runs/a0f0109f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165500-a0f0109f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82459)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2023-08-10 16:56:50,233\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.327 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:50,239\tWARNING util.py:315 -- The `process_trial_result` operation took 2.333 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:56:50,243\tWARNING util.py:315 -- Processing trial results took 2.337 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:56:50,275\tWARNING util.py:315 -- The `process_trial_result` operation took 2.370 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_7da0f427_64_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-56-16/wandb/run-20230810_165650-7da0f427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Syncing run FSR_Trainable_7da0f427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7da0f427\n",
      "2023-08-10 16:57:02,622\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.694 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:02,625\tWARNING util.py:315 -- The `process_trial_result` operation took 2.698 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:02,627\tWARNING util.py:315 -- Processing trial results took 2.700 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:57:02,633\tWARNING util.py:315 -- The `process_trial_result` operation took 2.706 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_ab8af723_65_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-56-42/wandb/run-20230810_165702-ab8af723\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Syncing run FSR_Trainable_ab8af723\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ab8af723\n",
      "2023-08-10 16:57:12,865\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.273 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:12,869\tWARNING util.py:315 -- The `process_trial_result` operation took 2.277 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:12,872\tWARNING util.py:315 -- Processing trial results took 2.281 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:57:12,874\tWARNING util.py:315 -- The `process_trial_result` operation took 2.282 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_80b63509_66_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-56-54/wandb/run-20230810_165715-80b63509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Syncing run FSR_Trainable_80b63509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/80b63509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: - 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: \\ 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                mae_coord 5.41465\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                mae_force 1453.58957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               mape_coord 1.33589\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               mape_force 1.6162106846908739e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                   metric 0.84701\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               rmse_coord 2.59403\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               rmse_force 1130.23363\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:       time_since_restore 48.29146\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:         time_this_iter_s 7.36827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:             time_total_s 48.29146\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:                timestamp 1691654254\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               tmae_coord 1.09252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:               tmae_force 0.50107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              tmape_coord 202655443938966.66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              tmape_force 515530686919532.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              trmse_coord 0.48598\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:              trmse_force 0.36103\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb:  View run FSR_Trainable_7da0f427 at: https://wandb.ai/seokjin/FSR-prediction/runs/7da0f427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83198)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165650-7da0f427/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                mae_coord 5.0764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                mae_force 1434.12892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               mape_coord 1.36459\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               mape_force 1.2681088712976873e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                   metric 0.8445\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               rmse_coord 2.53522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               rmse_force 1163.67903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:       time_since_restore 40.60355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:         time_this_iter_s 6.33264\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:             time_total_s 40.60355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:                timestamp 1691654260\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               tmae_coord 1.01296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:               tmae_force 0.49601\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              tmape_coord 202320361565633.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              tmape_force 424450925464181.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              trmse_coord 0.47565\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:              trmse_force 0.36885\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb:  View run FSR_Trainable_ab8af723 at: https://wandb.ai/seokjin/FSR-prediction/runs/ab8af723\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83419)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165702-ab8af723/logs\n",
      "2023-08-10 16:57:58,091\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.364 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:58,096\tWARNING util.py:315 -- The `process_trial_result` operation took 2.369 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:57:58,098\tWARNING util.py:315 -- Processing trial results took 2.371 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:57:58,099\tWARNING util.py:315 -- The `process_trial_result` operation took 2.373 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_a4b78468_67_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-57-07/wandb/run-20230810_165758-a4b78468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Syncing run FSR_Trainable_a4b78468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a4b78468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_bdfb235c_68_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-57-49/wandb/run-20230810_165813-bdfb235c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Syncing run FSR_Trainable_bdfb235c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bdfb235c\n",
      "2023-08-10 16:58:16,189\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.943 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:16,193\tWARNING util.py:315 -- The `process_trial_result` operation took 2.949 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:16,198\tWARNING util.py:315 -- Processing trial results took 2.953 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:58:16,200\tWARNING util.py:315 -- The `process_trial_result` operation took 2.955 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                mae_coord 4.90702\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                mae_force 914.65342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               mape_coord 1.2843\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               mape_force 5.941620666578369e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                   metric 0.69939\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               rmse_coord 2.39259\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               rmse_force 758.37926\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:       time_since_restore 567.93534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:         time_this_iter_s 5.48537\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:             time_total_s 567.93534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:                timestamp 1691654296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               tmae_coord 0.98693\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:               tmae_force 0.33328\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              tmape_coord 193171946779859.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              tmape_force 249752226259499.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              trmse_coord 0.4498\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:              trmse_force 0.2496\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb:  View run FSR_Trainable_1e628a56 at: https://wandb.ai/seokjin/FSR-prediction/runs/1e628a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=79405)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_164837-1e628a56/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-10 16:58:40,748\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.960 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:40,756\tWARNING util.py:315 -- The `process_trial_result` operation took 2.969 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:40,759\tWARNING util.py:315 -- Processing trial results took 2.972 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:58:40,761\tWARNING util.py:315 -- The `process_trial_result` operation took 2.974 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                mae_coord 5.03702\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                mae_force 1434.37019\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               mape_coord 1.36104\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               mape_force 1.2941294853213998e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                   metric 0.8439\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               rmse_coord 2.53555\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               rmse_force 1159.78097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:       time_since_restore 42.46192\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:         time_this_iter_s 6.13543\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:             time_total_s 42.46192\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:                timestamp 1691654317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               tmae_coord 1.00674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:               tmae_force 0.4959\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              tmape_coord 202151822871345.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              tmape_force 430415055940312.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              trmse_coord 0.47592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:              trmse_force 0.36798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb:  View run FSR_Trainable_a4b78468 at: https://wandb.ai/seokjin/FSR-prediction/runs/a4b78468\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165758-a4b78468/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_618f8440_69_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-58-04/wandb/run-20230810_165840-618f8440\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Syncing run FSR_Trainable_618f8440\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/618f8440\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83889)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)3 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)3 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165840-618f8440/logs\n",
      "2023-08-10 16:58:52,018\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.100 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:52,027\tWARNING util.py:315 -- The `process_trial_result` operation took 3.111 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:58:52,033\tWARNING util.py:315 -- Processing trial results took 3.117 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:58:52,035\tWARNING util.py:315 -- The `process_trial_result` operation took 3.119 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84354)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_cc7ad45a_70_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-58-31/wandb/run-20230810_165855-cc7ad45a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Syncing run FSR_Trainable_cc7ad45a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/cc7ad45a\n",
      "2023-08-10 16:59:08,727\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.677 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:08,735\tWARNING util.py:315 -- The `process_trial_result` operation took 3.687 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:08,737\tWARNING util.py:315 -- Processing trial results took 3.688 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:59:08,739\tWARNING util.py:315 -- The `process_trial_result` operation took 3.690 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_33be0461_71_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-58-46/wandb/run-20230810_165912-33be0461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Syncing run FSR_Trainable_33be0461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/33be0461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                mae_coord 5.42584\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                mae_force 1450.85963\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               mape_coord 1.39629\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               mape_force 1.4715019567649887e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                   metric 0.85099\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               rmse_coord 2.58801\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               rmse_force 1145.96172\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:       time_since_restore 14.28635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:         time_this_iter_s 3.26894\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:             time_total_s 14.28635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:                timestamp 1691654358\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               tmae_coord 1.08795\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:               tmae_force 0.50471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              tmape_coord 203495384563373.84\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              tmape_force 497809838450456.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              trmse_coord 0.48607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:              trmse_force 0.36492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb:  View run FSR_Trainable_33be0461 at: https://wandb.ai/seokjin/FSR-prediction/runs/33be0461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84811)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165912-33be0461/logs\n",
      "2023-08-10 16:59:25,886\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.159 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:25,891\tWARNING util.py:315 -- The `process_trial_result` operation took 3.165 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:25,893\tWARNING util.py:315 -- Processing trial results took 3.167 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:59:25,895\tWARNING util.py:315 -- The `process_trial_result` operation took 3.169 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_9a8207c4_72_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-59-01/wandb/run-20230810_165930-9a8207c4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Syncing run FSR_Trainable_9a8207c4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9a8207c4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                mae_coord 5.46825\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                mae_force 1452.76412\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               mape_coord 1.40399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               mape_force 1.5331299190602857e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                   metric 0.84912\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               rmse_coord 2.59131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               rmse_force 1137.77878\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:       time_since_restore 11.93816\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:         time_this_iter_s 2.49234\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:             time_total_s 11.93816\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:                timestamp 1691654374\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               tmae_coord 1.09931\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:               tmae_force 0.50322\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              tmape_coord 199871287691768.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              tmape_force 504614751167094.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              trmse_coord 0.4861\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:              trmse_force 0.36302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb:  View run FSR_Trainable_9a8207c4 at: https://wandb.ai/seokjin/FSR-prediction/runs/9a8207c4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85031)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165930-9a8207c4/logs\n",
      "2023-08-10 16:59:41,880\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.463 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:41,884\tWARNING util.py:315 -- The `process_trial_result` operation took 2.468 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:41,886\tWARNING util.py:315 -- Processing trial results took 2.470 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:59:41,889\tWARNING util.py:315 -- The `process_trial_result` operation took 2.473 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_072855d3_73_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-59-19/wandb/run-20230810_165944-072855d3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Syncing run FSR_Trainable_072855d3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/072855d3\n",
      "2023-08-10 16:59:54,778\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.236 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:54,783\tWARNING util.py:315 -- The `process_trial_result` operation took 2.242 s, which may be a performance bottleneck.\n",
      "2023-08-10 16:59:54,785\tWARNING util.py:315 -- Processing trial results took 2.244 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 16:59:54,787\tWARNING util.py:315 -- The `process_trial_result` operation took 2.246 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e23fb1f6_74_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-59-36/wandb/run-20230810_170000-e23fb1f6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Syncing run FSR_Trainable_e23fb1f6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e23fb1f6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                mae_coord 4.2848\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                mae_force 1565.57064\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               mape_coord 1.22902\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               mape_force 2.4583817079171743e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                   metric 0.80611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               rmse_coord 2.42426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               rmse_force 1105.02425\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:       time_since_restore 225.58002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:         time_this_iter_s 3.35686\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:             time_total_s 225.58002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:                timestamp 1691654470\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               tmae_coord 0.86968\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:               tmae_force 0.55113\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              tmape_coord 204834623780475.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              tmape_force 877092110490799.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              trmse_coord 0.45718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:              trmse_force 0.34893\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb:  View run FSR_Trainable_80b63509 at: https://wandb.ai/seokjin/FSR-prediction/runs/80b63509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83633)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165715-80b63509/logs\n",
      "2023-08-10 17:01:31,719\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.706 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:01:31,722\tWARNING util.py:315 -- The `process_trial_result` operation took 2.711 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:01:31,725\tWARNING util.py:315 -- Processing trial results took 2.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:01:31,728\tWARNING util.py:315 -- The `process_trial_result` operation took 2.717 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f21a52f1_75_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_16-59-50/wandb/run-20230810_170134-f21a52f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Syncing run FSR_Trainable_f21a52f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f21a52f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                mae_coord 4.74875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                mae_force 681.79131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               mape_coord 1.24576\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               mape_force 5.827765913326148e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                   metric 0.61792\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               rmse_coord 2.35115\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               rmse_force 524.85269\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:       time_since_restore 183.91107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:         time_this_iter_s 2.42949\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:             time_total_s 183.91107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:                timestamp 1691654532\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               tmae_coord 0.9608\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:               tmae_force 0.2647\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              tmape_coord 183717110621294.75\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              tmape_force 283958619036686.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              trmse_coord 0.43827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:              trmse_force 0.17964\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb:  View run FSR_Trainable_cc7ad45a at: https://wandb.ai/seokjin/FSR-prediction/runs/cc7ad45a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84590)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165855-cc7ad45a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 17:02:41,143\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.688 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:02:41,147\tWARNING util.py:315 -- The `process_trial_result` operation took 2.693 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:02:41,148\tWARNING util.py:315 -- Processing trial results took 2.694 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:02:41,151\tWARNING util.py:315 -- The `process_trial_result` operation took 2.697 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_4e236230_76_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-01-25/wandb/run-20230810_170240-4e236230\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Syncing run FSR_Trainable_4e236230\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4e236230\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                mae_coord 4.45735\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                mae_force 609.79833\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               mape_coord 1.1677\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               mape_force 4.0536675905902035e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                   metric 0.58537\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               rmse_coord 2.27331\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               rmse_force 497.77154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:       time_since_restore 202.12314\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:         time_this_iter_s 1.92045\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:             time_total_s 202.12314\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:                timestamp 1691654607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               tmae_coord 0.89512\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:               tmae_force 0.22804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              tmape_coord 170548649388500.16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              tmape_force 177681606625937.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              trmse_coord 0.42076\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:              trmse_force 0.16461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb:  View run FSR_Trainable_e23fb1f6 at: https://wandb.ai/seokjin/FSR-prediction/runs/e23fb1f6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85484)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170000-e23fb1f6/logs\n",
      "2023-08-10 17:03:49,450\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.932 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:03:49,452\tWARNING util.py:315 -- The `process_trial_result` operation took 2.938 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:03:49,457\tWARNING util.py:315 -- Processing trial results took 2.943 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:03:49,458\tWARNING util.py:315 -- The `process_trial_result` operation took 2.944 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_828fa7f4_77_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-02-30/wandb/run-20230810_170352-828fa7f4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Syncing run FSR_Trainable_828fa7f4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/828fa7f4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                mae_coord 4.5208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                mae_force 631.01021\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               mape_coord 1.17634\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               mape_force 4.36345597462482e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                   metric 0.59586\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               rmse_coord 2.31087\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               rmse_force 513.76183\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:       time_since_restore 200.72697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:         time_this_iter_s 1.51885\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:             time_total_s 200.72697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:                timestamp 1691654703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               tmae_coord 0.90557\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:               tmae_force 0.23458\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              tmape_coord 174552376699694.16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              tmape_force 192193768939443.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              trmse_coord 0.42743\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:              trmse_force 0.16843\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb:  View run FSR_Trainable_f21a52f1 at: https://wandb.ai/seokjin/FSR-prediction/runs/f21a52f1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85772)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170134-f21a52f1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165944-072855d3/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_165944-072855d3/logs\n",
      "2023-08-10 17:05:21,308\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.375 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:21,315\tWARNING util.py:315 -- The `process_trial_result` operation took 2.384 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:21,316\tWARNING util.py:315 -- Processing trial results took 2.385 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:05:21,318\tWARNING util.py:315 -- The `process_trial_result` operation took 2.387 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85259)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_e265c692_78_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-03-43/wandb/run-20230810_170525-e265c692\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Syncing run FSR_Trainable_e265c692\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e265c692\n",
      "2023-08-10 17:05:37,489\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.230 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:37,492\tWARNING util.py:315 -- The `process_trial_result` operation took 2.235 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:37,495\tWARNING util.py:315 -- Processing trial results took 2.238 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:05:37,498\tWARNING util.py:315 -- The `process_trial_result` operation took 2.241 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_51c503cd_79_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-05-17/wandb/run-20230810_170541-51c503cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Syncing run FSR_Trainable_51c503cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/51c503cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                mae_coord 4.97698\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                mae_force 1477.85811\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               mape_coord 1.3081\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               mape_force 1.9820970322780744e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                   metric 0.81788\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               rmse_coord 2.48998\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               rmse_force 1098.40809\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:       time_since_restore 177.827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:         time_this_iter_s 4.69077\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:             time_total_s 177.827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:                timestamp 1691654736\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               tmae_coord 1.0044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:               tmae_force 0.51559\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              tmape_coord 206046628547139.78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              tmape_force 684727295095743.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              trmse_coord 0.46905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:              trmse_force 0.34882\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb:  View run FSR_Trainable_4e236230 at: https://wandb.ai/seokjin/FSR-prediction/runs/4e236230\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86039)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170240-4e236230/logs\n",
      "2023-08-10 17:05:55,901\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.176 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:55,905\tWARNING util.py:315 -- The `process_trial_result` operation took 2.181 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:05:55,907\tWARNING util.py:315 -- Processing trial results took 2.183 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:05:55,908\tWARNING util.py:315 -- The `process_trial_result` operation took 2.185 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_d3aecf5b_80_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-05-33/wandb/run-20230810_170559-d3aecf5b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Syncing run FSR_Trainable_d3aecf5b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d3aecf5b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                mae_coord 4.66778\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                mae_force 716.37188\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               mape_coord 1.2625\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               mape_force 5.171521420831585e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                   metric 0.62768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               rmse_coord 2.35242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               rmse_force 556.18251\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:       time_since_restore 180.22633\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:         time_this_iter_s 1.77376\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:             time_total_s 180.22633\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:                timestamp 1691654820\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               tmae_coord 0.94005\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:               tmae_force 0.27512\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              tmape_coord 189939672740697.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              tmape_force 240362548204894.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              trmse_coord 0.43479\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:              trmse_force 0.19288\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb:  View run FSR_Trainable_828fa7f4 at: https://wandb.ai/seokjin/FSR-prediction/runs/828fa7f4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86309)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170352-828fa7f4/logs\n",
      "2023-08-10 17:07:20,331\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.114 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:07:20,336\tWARNING util.py:315 -- The `process_trial_result` operation took 2.119 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:07:20,342\tWARNING util.py:315 -- Processing trial results took 2.125 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:07:20,344\tWARNING util.py:315 -- The `process_trial_result` operation took 2.128 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_fb065147_81_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-05-51/wandb/run-20230810_170724-fb065147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Syncing run FSR_Trainable_fb065147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fb065147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                mae_coord 4.58467\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                mae_force 672.81839\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               mape_coord 1.25608\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               mape_force 7.074006678221558e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                   metric 0.59505\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               rmse_coord 2.3137\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               rmse_force 489.79381\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:       time_since_restore 143.9779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:         time_this_iter_s 1.50506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:             time_total_s 143.9779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:                timestamp 1691654876\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               tmae_coord 0.92276\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:               tmae_force 0.25684\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              tmape_coord 183104709074775.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              tmape_force 300954154727792.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              trmse_coord 0.42693\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:              trmse_force 0.16813\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb:  View run FSR_Trainable_e265c692 at: https://wandb.ai/seokjin/FSR-prediction/runs/e265c692\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86607)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170525-e265c692/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                mae_coord 4.74324\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                mae_force 719.79737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               mape_coord 1.25262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               mape_force 6.702672463226098e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                   metric 0.61671\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               rmse_coord 2.3567\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               rmse_force 519.0875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:       time_since_restore 140.51027\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:         time_this_iter_s 1.38039\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:             time_total_s 140.51027\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:                timestamp 1691654887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               tmae_coord 0.95234\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:               tmae_force 0.27494\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              tmape_coord 169985483786386.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              tmape_force 296122185577921.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              trmse_coord 0.43656\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:              trmse_force 0.18016\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb:  View run FSR_Trainable_51c503cd at: https://wandb.ai/seokjin/FSR-prediction/runs/51c503cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=86823)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170541-51c503cd/logs\n",
      "2023-08-10 17:08:15,339\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.499 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:15,345\tWARNING util.py:315 -- The `process_trial_result` operation took 2.506 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:15,351\tWARNING util.py:315 -- Processing trial results took 2.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:08:15,353\tWARNING util.py:315 -- The `process_trial_result` operation took 2.513 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f55b1351_82_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-07-14/wandb/run-20230810_170819-f55b1351\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Syncing run FSR_Trainable_f55b1351\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f55b1351\n",
      "2023-08-10 17:08:33,402\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.539 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:33,406\tWARNING util.py:315 -- The `process_trial_result` operation took 2.544 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:33,408\tWARNING util.py:315 -- Processing trial results took 2.547 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:08:33,411\tWARNING util.py:315 -- The `process_trial_result` operation took 2.549 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_19390f08_83_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-08-11/wandb/run-20230810_170837-19390f08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Syncing run FSR_Trainable_19390f08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/19390f08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                mae_coord 4.69166\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                mae_force 683.90583\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               mape_coord 1.18069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               mape_force 5.944463714771485e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                   metric 0.60783\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               rmse_coord 2.34706\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               rmse_force 518.60394\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:       time_since_restore 152.33611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:         time_this_iter_s 1.47774\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:             time_total_s 152.33611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:                timestamp 1691654918\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               tmae_coord 0.9454\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:               tmae_force 0.2607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              tmape_coord 163913650889871.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              tmape_force 280705616975243.66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              trmse_coord 0.43623\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:              trmse_force 0.1716\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb:  View run FSR_Trainable_d3aecf5b at: https://wandb.ai/seokjin/FSR-prediction/runs/d3aecf5b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87058)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170559-d3aecf5b/logs\n",
      "2023-08-10 17:08:57,145\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.017 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:57,147\tWARNING util.py:315 -- The `process_trial_result` operation took 2.020 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:08:57,150\tWARNING util.py:315 -- Processing trial results took 2.023 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:08:57,152\tWARNING util.py:315 -- The `process_trial_result` operation took 2.026 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_362152c3_84_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-08-28/wandb/run-20230810_170900-362152c3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Syncing run FSR_Trainable_362152c3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/362152c3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)8 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                mae_coord 5.1483\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                mae_force 809.25286\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               mape_coord 1.32597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               mape_force 5.643467923892845e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                   metric 0.67356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               rmse_coord 2.50187\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               rmse_force 639.47248\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:       time_since_restore 199.90258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:         time_this_iter_s 2.1481\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:             time_total_s 199.90258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:                timestamp 1691655049\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               tmae_coord 1.01419\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:               tmae_force 0.30419\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              tmape_coord 164062280339198.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              tmape_force 254140695889323.62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              trmse_coord 0.46071\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:              trmse_force 0.21286\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb:  View run FSR_Trainable_fb065147 at: https://wandb.ai/seokjin/FSR-prediction/runs/fb065147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87349)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170724-fb065147/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170724-fb065147/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170819-f55b1351/logs\n",
      "2023-08-10 17:11:07,111\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:07,115\tWARNING util.py:315 -- The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:07,116\tWARNING util.py:315 -- Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:11:07,117\tWARNING util.py:315 -- The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87627)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_874461c8_85_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-08-52/wandb/run-20230810_171110-874461c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Syncing run FSR_Trainable_874461c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/874461c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                mae_coord 4.60737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                mae_force 663.7565\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               mape_coord 1.17506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               mape_force 5.6121387154170566e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                   metric 0.60107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               rmse_coord 2.32711\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               rmse_force 498.49253\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:       time_since_restore 146.65199\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:         time_this_iter_s 1.58454\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:             time_total_s 146.65199\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:                timestamp 1691655065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               tmae_coord 0.92194\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:               tmae_force 0.25596\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              tmape_coord 164635101608076.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              tmape_force 266786828698339.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              trmse_coord 0.42966\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:              trmse_force 0.17141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb:  View run FSR_Trainable_19390f08 at: https://wandb.ai/seokjin/FSR-prediction/runs/19390f08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170837-19390f08/logs\n",
      "2023-08-10 17:11:20,277\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:20,279\tWARNING util.py:315 -- The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:20,283\tWARNING util.py:315 -- Processing trial results took 1.836 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:11:20,284\tWARNING util.py:315 -- The `process_trial_result` operation took 1.838 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=87852)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f6223373_86_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-11-03/wandb/run-20230810_171126-f6223373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Syncing run FSR_Trainable_f6223373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f6223373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                mae_coord 4.84352\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                mae_force 687.12771\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               mape_coord 1.22802\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               mape_force 5.948018167098577e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                   metric 0.60658\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               rmse_coord 2.35775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               rmse_force 518.08791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:       time_since_restore 142.68664\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:         time_this_iter_s 1.41018\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:             time_total_s 142.68664\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:                timestamp 1691655087\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               tmae_coord 0.96355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:               tmae_force 0.2627\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              tmape_coord 157708297900539.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              tmape_force 281466494661778.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              trmse_coord 0.43337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:              trmse_force 0.17321\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb:  View run FSR_Trainable_362152c3 at: https://wandb.ai/seokjin/FSR-prediction/runs/362152c3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_170900-362152c3/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88090)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2023-08-10 17:11:34,335\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.960 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:34,337\tWARNING util.py:315 -- The `process_trial_result` operation took 1.963 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:34,342\tWARNING util.py:315 -- Processing trial results took 1.968 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:11:34,343\tWARNING util.py:315 -- The `process_trial_result` operation took 1.969 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_f718e66a_87_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-11-16/wandb/run-20230810_171137-f718e66a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Syncing run FSR_Trainable_f718e66a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f718e66a\n",
      "2023-08-10 17:11:50,646\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.236 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:50,652\tWARNING util.py:315 -- The `process_trial_result` operation took 2.243 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:11:50,655\tWARNING util.py:315 -- Processing trial results took 2.246 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:11:50,661\tWARNING util.py:315 -- The `process_trial_result` operation took 2.252 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_7f028035_88_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-11-30/wandb/run-20230810_171154-7f028035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Syncing run FSR_Trainable_7f028035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7f028035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                mae_coord 4.65237\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                mae_force 654.87654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               mape_coord 1.16233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               mape_force 6.102571784996045e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                   metric 0.60113\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               rmse_coord 2.3503\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               rmse_force 492.26791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:       time_since_restore 140.9922\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:         time_this_iter_s 1.15233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:             time_total_s 140.9922\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:                timestamp 1691655218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               tmae_coord 0.93799\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:               tmae_force 0.25229\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              tmape_coord 160704122676949.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              tmape_force 279262926581641.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              trmse_coord 0.43331\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:              trmse_force 0.16782\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb:  View run FSR_Trainable_874461c8 at: https://wandb.ai/seokjin/FSR-prediction/runs/874461c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88437)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171110-874461c8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                mae_coord 4.55452\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                mae_force 661.86282\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               mape_coord 1.16628\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               mape_force 6.112449625393576e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                   metric 0.60148\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               rmse_coord 2.33461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               rmse_force 489.26476\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:       time_since_restore 139.86927\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:         time_this_iter_s 1.38941\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:             time_total_s 139.86927\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:                timestamp 1691655231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               tmae_coord 0.90872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:               tmae_force 0.25996\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              tmape_coord 160445359774479.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              tmape_force 295308124094203.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              trmse_coord 0.43052\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:              trmse_force 0.17096\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb:  View run FSR_Trainable_f6223373 at: https://wandb.ai/seokjin/FSR-prediction/runs/f6223373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88667)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171126-f6223373/logs\n",
      "2023-08-10 17:14:00,307\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.811 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:00,314\tWARNING util.py:315 -- The `process_trial_result` operation took 2.819 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:00,316\tWARNING util.py:315 -- Processing trial results took 2.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:14:00,318\tWARNING util.py:315 -- The `process_trial_result` operation took 2.823 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_07769fcd_89_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-11-46/wandb/run-20230810_171404-07769fcd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Syncing run FSR_Trainable_07769fcd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/07769fcd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-10 17:14:13,364\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.176 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:13,369\tWARNING util.py:315 -- The `process_trial_result` operation took 2.183 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:13,370\tWARNING util.py:315 -- Processing trial results took 2.184 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:14:13,372\tWARNING util.py:315 -- The `process_trial_result` operation took 2.185 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                mae_coord 4.6583\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                mae_force 652.57522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               mape_coord 1.16823\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               mape_force 5.65541518671238e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                   metric 0.60427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               rmse_coord 2.36139\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               rmse_force 493.20099\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:       time_since_restore 144.54542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:         time_this_iter_s 1.47531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:             time_total_s 144.54542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:                timestamp 1691655250\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               tmae_coord 0.93444\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:               tmae_force 0.25261\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              tmape_coord 164951070601060.22\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              tmape_force 267816177030667.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              trmse_coord 0.4343\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:              trmse_force 0.16997\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb:  View run FSR_Trainable_f718e66a at: https://wandb.ai/seokjin/FSR-prediction/runs/f718e66a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=88891)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171137-f718e66a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_1eb906b8_90_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-13-54/wandb/run-20230810_171416-1eb906b8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Syncing run FSR_Trainable_1eb906b8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1eb906b8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-10 17:14:29,246\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.643 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:29,248\tWARNING util.py:315 -- The `process_trial_result` operation took 2.646 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:29,250\tWARNING util.py:315 -- Processing trial results took 2.648 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:14:29,252\tWARNING util.py:315 -- The `process_trial_result` operation took 2.651 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                mae_coord 4.5232\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                mae_force 629.65418\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               mape_coord 1.15619\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               mape_force 5.0890621335558656e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                   metric 0.59682\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               rmse_coord 2.329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               rmse_force 486.40751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:       time_since_restore 141.9914\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:         time_this_iter_s 1.30216\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:             time_total_s 141.9914\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:                timestamp 1691655264\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               tmae_coord 0.90846\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:               tmae_force 0.24497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              tmape_coord 162961559826043.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              tmape_force 247783653829807.97\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              trmse_coord 0.42894\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:              trmse_force 0.16788\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb:  View run FSR_Trainable_7f028035 at: https://wandb.ai/seokjin/FSR-prediction/runs/7f028035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89119)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171154-7f028035/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_a50448be_91_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-14-09/wandb/run-20230810_171433-a50448be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Syncing run FSR_Trainable_a50448be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a50448be\n",
      "2023-08-10 17:14:46,654\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.453 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:46,660\tWARNING util.py:315 -- The `process_trial_result` operation took 2.460 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:14:46,662\tWARNING util.py:315 -- Processing trial results took 2.462 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:14:46,664\tWARNING util.py:315 -- The `process_trial_result` operation took 2.464 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_c392afee_92_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-14-24/wandb/run-20230810_171451-c392afee\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Syncing run FSR_Trainable_c392afee\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c392afee\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                mae_coord 4.64875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                mae_force 1034.46038\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               mape_coord 1.20197\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               mape_force 2348037709.70534\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                   metric 5.69465\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               rmse_coord 2.44192\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               rmse_force 840.80115\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:       time_since_restore 2.23546\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:         time_this_iter_s 2.23546\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:             time_total_s 2.23546\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:                timestamp 1691655284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               tmae_coord 7.32589\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:               tmae_force 2.68317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              tmape_coord 37.48414\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              tmape_force 11.06169\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              trmse_coord 3.49653\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:              trmse_force 2.19812\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb:  View run FSR_Trainable_c392afee at: https://wandb.ai/seokjin/FSR-prediction/runs/c392afee\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90147)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171451-c392afee/logs\n",
      "2023-08-10 17:15:05,760\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.100 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:05,764\tWARNING util.py:315 -- The `process_trial_result` operation took 2.105 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:05,767\tWARNING util.py:315 -- Processing trial results took 2.108 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:15:05,769\tWARNING util.py:315 -- The `process_trial_result` operation took 2.110 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_6b89ee81_93_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-14-42/wandb/run-20230810_171509-6b89ee81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Syncing run FSR_Trainable_6b89ee81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6b89ee81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                mae_coord 4.44362\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                mae_force 1061.09879\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               mape_coord 1.24863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               mape_force 2486798498.04586\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                   metric 5.45607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               rmse_coord 2.44508\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               rmse_force 826.23726\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:       time_since_restore 1.6773\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:         time_this_iter_s 1.6773\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:             time_total_s 1.6773\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:                timestamp 1691655303\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               tmae_coord 6.99202\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:               tmae_force 2.74406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              tmape_coord 33.65309\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              tmape_force 12.51791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              trmse_coord 3.46896\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:              trmse_force 1.98711\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb:  View run FSR_Trainable_6b89ee81 at: https://wandb.ai/seokjin/FSR-prediction/runs/6b89ee81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90381)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171509-6b89ee81/logs\n",
      "2023-08-10 17:15:24,113\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.067 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:24,120\tWARNING util.py:315 -- The `process_trial_result` operation took 2.075 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:24,121\tWARNING util.py:315 -- Processing trial results took 2.076 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:15:24,122\tWARNING util.py:315 -- The `process_trial_result` operation took 2.077 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_15f12775_94_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-15-02/wandb/run-20230810_171528-15f12775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Syncing run FSR_Trainable_15f12775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/15f12775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)5 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                mae_coord 4.44401\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                mae_force 1400.20488\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               mape_coord 1.13329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               mape_force 5.5324192319298504e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                   metric 24.21407\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               rmse_coord 2.46332\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               rmse_force 1165.68533\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:       time_since_restore 2.41903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:         time_this_iter_s 2.41903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:             time_total_s 2.41903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:                timestamp 1691655322\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               tmae_coord 15.53201\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:               tmae_force 10.43968\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              tmape_coord 5426949140995057.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              tmape_force 2512610379113913.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              trmse_coord 11.3314\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:              trmse_force 12.88267\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb:  View run FSR_Trainable_15f12775 at: https://wandb.ai/seokjin/FSR-prediction/runs/15f12775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90615)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171528-15f12775/logs\n",
      "2023-08-10 17:15:45,115\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.862 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:45,121\tWARNING util.py:315 -- The `process_trial_result` operation took 1.869 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:15:45,123\tWARNING util.py:315 -- Processing trial results took 1.871 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:15:45,124\tWARNING util.py:315 -- The `process_trial_result` operation took 1.873 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_4d753b8c_95_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-15-19/wandb/run-20230810_171548-4d753b8c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Syncing run FSR_Trainable_4d753b8c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4d753b8c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)5 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                mae_coord 4.65392\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                mae_force 1374.49748\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               mape_coord 1.24851\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               mape_force 1.9021598243504202e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                   metric 23.39596\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               rmse_coord 2.44934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               rmse_force 1094.46476\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:       time_since_restore 2.13544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:         time_this_iter_s 2.13544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:             time_total_s 2.13544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:                timestamp 1691655343\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               tmae_coord 15.83249\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:               tmae_force 10.77603\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              tmape_coord 6383720576671006.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              tmape_force 8110605227245545.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              trmse_coord 11.2374\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:              trmse_force 12.15855\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb:  View run FSR_Trainable_4d753b8c at: https://wandb.ai/seokjin/FSR-prediction/runs/4d753b8c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=90848)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171548-4d753b8c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171404-07769fcd/logs\n",
      "2023-08-10 17:16:02,495\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:16:02,497\tWARNING util.py:315 -- The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:16:02,499\tWARNING util.py:315 -- Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:16:02,503\tWARNING util.py:315 -- The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89459)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_39c7ad9f_96_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-15-41/wandb/run-20230810_171606-39c7ad9f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Syncing run FSR_Trainable_39c7ad9f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/39c7ad9f\n",
      "2023-08-10 17:16:18,261\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.408 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:16:18,265\tWARNING util.py:315 -- The `process_trial_result` operation took 2.413 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:16:18,267\tWARNING util.py:315 -- Processing trial results took 2.415 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:16:18,271\tWARNING util.py:315 -- The `process_trial_result` operation took 2.420 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_943a5e4a_97_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-15-59/wandb/run-20230810_171622-943a5e4a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Syncing run FSR_Trainable_943a5e4a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/943a5e4a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                mae_coord 4.65162\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                mae_force 696.38963\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               mape_coord 1.22376\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               mape_force 5.670297457660861e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                   metric 0.62204\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               rmse_coord 2.34571\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               rmse_force 529.35438\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:       time_since_restore 145.7024\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:         time_this_iter_s 1.23819\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:             time_total_s 145.7024\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:                timestamp 1691655418\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               tmae_coord 0.93397\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:               tmae_force 0.27378\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              tmape_coord 162575824993805.34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              tmape_force 275712663013261.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              trmse_coord 0.43525\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:              trmse_force 0.18679\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb:  View run FSR_Trainable_1eb906b8 at: https://wandb.ai/seokjin/FSR-prediction/runs/1eb906b8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89683)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171416-1eb906b8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-10 17:17:17,075\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.352 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:17:17,079\tWARNING util.py:315 -- The `process_trial_result` operation took 2.358 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:17:17,082\tWARNING util.py:315 -- Processing trial results took 2.360 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:17:17,084\tWARNING util.py:315 -- The `process_trial_result` operation took 2.362 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                mae_coord 4.69561\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                mae_force 672.62336\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               mape_coord 1.15704\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               mape_force 5.626902898912077e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                   metric 0.61146\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               rmse_coord 2.37217\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               rmse_force 507.3802\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:       time_since_restore 148.16356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:         time_this_iter_s 1.73738\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:             time_total_s 148.16356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:                timestamp 1691655434\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               tmae_coord 0.9428\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:               tmae_force 0.25718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              tmape_coord 164215693760483.12\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              tmape_force 259632747272889.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              trmse_coord 0.4388\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:              trmse_force 0.17266\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb:  View run FSR_Trainable_a50448be at: https://wandb.ai/seokjin/FSR-prediction/runs/a50448be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=89913)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171433-a50448be/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_2d03179b_98_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-16-13/wandb/run-20230810_171721-2d03179b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Syncing run FSR_Trainable_2d03179b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2d03179b\n",
      "2023-08-10 17:17:32,548\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.038 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:17:32,552\tWARNING util.py:315 -- The `process_trial_result` operation took 2.043 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:17:32,554\tWARNING util.py:315 -- Processing trial results took 2.045 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:17:32,556\tWARNING util.py:315 -- The `process_trial_result` operation took 2.048 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_291c0121_99_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-10_17-17-12/wandb/run-20230810_171736-291c0121\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Syncing run FSR_Trainable_291c0121\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/291c0121\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                mae_coord 4.54167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                mae_force 665.56106\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               mape_coord 1.11697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               mape_force 4.97453030073194e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                   metric 0.59777\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               rmse_coord 2.31281\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               rmse_force 519.27232\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:       time_since_restore 141.78621\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:         time_this_iter_s 1.02218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:             time_total_s 141.78621\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:                timestamp 1691655516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               tmae_coord 0.91126\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:               tmae_force 0.25271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              tmape_coord 153983167166576.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              tmape_force 243831231762690.88\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              trmse_coord 0.4267\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:              trmse_force 0.17107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb:  View run FSR_Trainable_39c7ad9f at: https://wandb.ai/seokjin/FSR-prediction/runs/39c7ad9f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91091)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171606-39c7ad9f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91310)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171622-943a5e4a/logs\n",
      "2023-08-10 17:18:49,444\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.677 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:18:49,447\tWARNING util.py:315 -- The `process_trial_result` operation took 1.681 s, which may be a performance bottleneck.\n",
      "2023-08-10 17:18:49,449\tWARNING util.py:315 -- Processing trial results took 1.683 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 17:18:49,449\tWARNING util.py:315 -- The `process_trial_result` operation took 1.684 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_16-28-50/FSR_Trainable_42211eeb_100_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_Simple_2023-08-10_17-17-28/wandb/run-20230810_171852-42211eeb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Syncing run FSR_Trainable_42211eeb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/42211eeb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                mae_coord 4.56423\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                mae_force 641.45249\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               mape_coord 1.14484\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               mape_force 5.663835969861656e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                   metric 0.59687\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               rmse_coord 2.3298\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               rmse_force 487.22998\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:       time_since_restore 117.69779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:         time_this_iter_s 0.79555\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:             time_total_s 117.69779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:                timestamp 1691655561\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               tmae_coord 0.9112\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:               tmae_force 0.24862\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              tmape_coord 156250080489850.22\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              tmape_force 260909849301195.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              trmse_coord 0.42854\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:              trmse_force 0.16833\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb:  View run FSR_Trainable_2d03179b at: https://wandb.ai/seokjin/FSR-prediction/runs/2d03179b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91584)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171721-2d03179b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171736-291c0121/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=91814)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: \\ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                mae_coord 4.63281\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                mae_force 649.23069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               mape_coord 1.17697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               mape_force 5.035177760837405e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                   metric 0.60191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               rmse_coord 2.33824\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               rmse_force 512.54218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:       time_since_restore 67.74167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:         time_this_iter_s 0.51504\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:             time_total_s 67.74167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:                timestamp 1691655598\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               tmae_coord 0.92317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:               tmae_force 0.2502\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              tmape_coord 155256012944390.06\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              tmape_force 241513778729870.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              trmse_coord 0.42916\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:              trmse_force 0.17274\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb:  View run FSR_Trainable_42211eeb at: https://wandb.ai/seokjin/FSR-prediction/runs/42211eeb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=92123)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_171852-42211eeb/logs\n",
      "2023-08-10 17:20:03,287\tINFO tune.py:1111 -- Total run time: 3072.88 seconds (3068.53 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
