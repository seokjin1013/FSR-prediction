{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1_ANN_GNN\n",
    "\n",
    "Index_X = FSR_for_force, FSR_for_coord\n",
    "\n",
    "Index_y = force, x_coord, y_coord\n",
    "\n",
    "Data = Splited by Time\n",
    "\n",
    "## Run result\n",
    "\n",
    "https://wandb.ai/seokjin/FSR-prediction/groups/FSR_Trainable_2023-08-17_12-08-36/workspace?workspace=user-seokjin\n",
    "\n",
    "## Experiment id\n",
    "\n",
    "FSR_Trainable_2023-08-17_12-08-36\n",
    "\n",
    "## Best metric (RMSE)\n",
    "\n",
    "200.373\n",
    "\n",
    "0.943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_searchspace(trial):\n",
    "    model = trial.suggest_categorical('model', ['fsr_model.FSRGraphNeuralNetwork'])\n",
    "    if model == 'fsr_model.LSTM':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.CNN_LSTM':\n",
    "        trial.suggest_categorical('model_args/cnn_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_categorical('model_args/lstm_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/cnn_num_layer', 1, 8)\n",
    "        trial.suggest_int('model_args/lstm_num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.ANN':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.FSRGraphNeuralNetwork':\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    trial.suggest_categorical('criterion', ['torch.nn.MSELoss'])\n",
    "    trial.suggest_categorical('optimizer', [\n",
    "        'torch.optim.Adam',\n",
    "        'torch.optim.NAdam',\n",
    "        'torch.optim.Adagrad',\n",
    "        'torch.optim.RAdam',\n",
    "        'torch.optim.SGD',\n",
    "    ])\n",
    "    trial.suggest_float('optimizer_args/lr', 1e-5, 1e-1, log=True)\n",
    "    imputer = trial.suggest_categorical('imputer', ['sklearn.impute.SimpleImputer'])\n",
    "    if imputer == 'sklearn.impute.SimpleImputer':\n",
    "        trial.suggest_categorical('imputer_args/strategy', [\n",
    "            'mean',\n",
    "            'median',\n",
    "        ])\n",
    "    trial.suggest_categorical('scaler', [ \n",
    "        'sklearn.preprocessing.StandardScaler',\n",
    "        'sklearn.preprocessing.MinMaxScaler',\n",
    "        'sklearn.preprocessing.RobustScaler',\n",
    "    ])\n",
    "    return {\n",
    "        'index_X': ['FSR_for_force', 'FSR_for_coord'],\n",
    "        'index_y': ['force', 'x_coord', 'y_coord'],\n",
    "        'data_loader': 'fsr_data.get_index_splited_by_time'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 12:08:36,627] A new study created in memory with name: optuna\n"
     ]
    }
   ],
   "source": [
    "import ray.tune\n",
    "import ray.air\n",
    "import ray.air.integrations.wandb\n",
    "import ray.tune.schedulers\n",
    "from fsr_trainable import FSR_Trainable\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "\n",
    "tuner = ray.tune.Tuner(\n",
    "    trainable=ray.tune.with_resources(\n",
    "        FSR_Trainable, {'cpu':2},\n",
    "    ),\n",
    "    tune_config=ray.tune.TuneConfig(\n",
    "        num_samples=100,\n",
    "        scheduler=ray.tune.schedulers.ASHAScheduler(\n",
    "            max_t=100,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2,\n",
    "            brackets=1,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "        search_alg=ray.tune.search.optuna.OptunaSearch(\n",
    "            space=define_searchspace,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "    ), \n",
    "    run_config=ray.air.RunConfig(\n",
    "        callbacks=[\n",
    "            ray.air.integrations.wandb.WandbLoggerCallback(project='FSR-prediction'),\n",
    "        ],\n",
    "        checkpoint_config=ray.air.CheckpointConfig(\n",
    "            num_to_keep=3,\n",
    "            checkpoint_score_attribute='metric',\n",
    "            checkpoint_score_order='min',\n",
    "            checkpoint_frequency=5,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 12:08:39,064\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-08-17 12:08:41,591\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-17 12:26:37</td></tr>\n",
       "<tr><td>Running for: </td><td>00:17:55.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>2.8/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=22<br>Bracket: Iter 64.000: -2.432535759950399 | Iter 32.000: -2.694090694840546 | Iter 16.000: -3.3438244971557607 | Iter 8.000: -5.291825802289218 | Iter 4.000: -7.044716131172346 | Iter 2.000: -9.524799701579688 | Iter 1.000: -25.706096967412048<br>Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 78<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_43fcd44e</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_43fcd44e_3_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-08-55/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_4d5dc9c2</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_4d5dc9c2_4_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-03/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_ca6ab145</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ca6ab145_6_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-25/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_5cc7b50b</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5cc7b50b_8_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-53/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_e0139bc1</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e0139bc1_11_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-10-40/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_edbf5674</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_edbf5674_23_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-13-24/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_63cd847d</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_63cd847d_29_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-34/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_971919c0</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_971919c0_30_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-47/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_d853c660</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d853c660_31_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-03/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_60e69b40</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_60e69b40_32_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-19/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a729e8d5</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a729e8d5_33_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-31/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_11c78141</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_11c78141_34_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-43/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_9d1f0ebb</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9d1f0ebb_35_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-53/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_64a7a150</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_64a7a150_36_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-02/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_351613df</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_351613df_37_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-11/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_7ecfe12d</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7ecfe12d_38_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-20/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_2f1488dc</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2f1488dc_39_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-31/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_2a10d033</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2a10d033_40_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-39/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_43872776</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_43872776_41_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-48/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_531ddeb1</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_531ddeb1_42_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-58/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_98575263</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_98575263_43_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-07/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_52703439</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_52703439_44_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-14/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_7bb60977</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7bb60977_45_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-24/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_d0631592</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d0631592_46_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-33/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_2c66a9b4</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2c66a9b4_47_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-44/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a618a14f</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a618a14f_48_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-53/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_1c1b9820</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1c1b9820_49_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-01/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_38c148a5</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_38c148a5_50_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-08/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_417f094f</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_417f094f_51_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-17/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_30eac9ce</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_30eac9ce_52_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-23/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_8ac82c65</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8ac82c65_53_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-31/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_46e653c7</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_46e653c7_54_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-39/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a1730c8a</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1730c8a_55_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-49/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_6205df9b</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6205df9b_56_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-56/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_fc0be644</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fc0be644_57_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-05/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_f7f52756</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_f7f52756_58_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-12/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_478dea9a</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_478dea9a_59_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-20/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_6baa37a1</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6baa37a1_60_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-28/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_fee9192e</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fee9192e_61_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-38/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_08dd982a</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_08dd982a_62_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-46/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_3834e2c6</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_3834e2c6_63_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-56/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_fb5da508</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fb5da508_64_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-03/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_1fb63a46</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1fb63a46_65_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-13/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_bfffe96c</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_bfffe96c_66_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-21/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_83963611</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_83963611_67_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-30/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_95e10e0c</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_95e10e0c_68_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-38/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_225e0ef4</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_225e0ef4_69_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-47/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_9230f8bf</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9230f8bf_70_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-53/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_5df754b0</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5df754b0_71_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-04/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a10d27d1</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a10d27d1_72_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-11/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_5837f84a</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5837f84a_73_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-20/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_7cd96ac9</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7cd96ac9_74_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-27/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_ce8f2ddc</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce8f2ddc_75_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-36/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_ce3191bc</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce3191bc_76_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-45/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_16c1edc2</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16c1edc2_77_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-54/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_04c92bb8</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_04c92bb8_78_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-01/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_fe1ae516</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fe1ae516_79_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-10/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_876067fd</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_876067fd_80_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-18/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_cd6ea670</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_cd6ea670_81_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-27/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a67f43be</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a67f43be_82_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-35/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_2acb15cf</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2acb15cf_83_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-45/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_32a8a03b</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_32a8a03b_84_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-52/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_e26788fe</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e26788fe_85_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-02/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_16d165c1</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16d165c1_86_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-11/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_ae231229</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ae231229_87_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-20/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_9a435255</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9a435255_88_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-28/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_1d6566d5</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1d6566d5_89_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-36/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_479e6a56</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_479e6a56_90_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-43/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_a1ef9b8b</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1ef9b8b_91_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-52/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_8f8427c8</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8f8427c8_92_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-00/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_b4e7377c</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_b4e7377c_93_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-11/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_676ec781</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_676ec781_94_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-19/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_67d56bc6</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_67d56bc6_95_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-29/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_dbe40062</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_dbe40062_96_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-37/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_75837ea5</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_75837ea5_97_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-49/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_184ab78c</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_184ab78c_98_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-00/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_1857e24d</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1857e24d_99_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-12/error.txt</td></tr>\n",
       "<tr><td>FSR_Trainable_17d3bd89</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_17d3bd89_100_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_Simple_2023-08-17_12-26-21/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc                 </th><th>criterion       </th><th>data_loader         </th><th>imputer             </th><th>imputer_args/strateg\n",
       "y       </th><th>index_X             </th><th>index_y             </th><th>model               </th><th style=\"text-align: right;\">  model_args/num_layer</th><th>optimizer          </th><th style=\"text-align: right;\">  optimizer_args/lr</th><th>scaler              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   tmae_force</th><th style=\"text-align: right;\">   trmse_force</th><th style=\"text-align: right;\">   tmape_force</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_28d7c7bd</td><td>TERMINATED</td><td>172.26.215.93:260106</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_4580</td><td>[&#x27;force&#x27;, &#x27;x_co_40c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     4</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        5.76972e-05</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       86.4322  </td><td style=\"text-align: right;\">     6.6287  </td><td style=\"text-align: right;\">  10.1529     </td><td style=\"text-align: right;\">  40.9412     </td></tr>\n",
       "<tr><td>FSR_Trainable_37c9b0d4</td><td>TERMINATED</td><td>172.26.215.93:260182</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_8840</td><td>[&#x27;force&#x27;, &#x27;x_co_7f80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.0894781  </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       79.9954  </td><td style=\"text-align: right;\">     0.733688</td><td style=\"text-align: right;\">   1.1279     </td><td style=\"text-align: right;\">   1.96922    </td></tr>\n",
       "<tr><td>FSR_Trainable_46857252</td><td>TERMINATED</td><td>172.26.215.93:260884</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_ee40</td><td>[&#x27;force&#x27;, &#x27;x_co_de80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000136013</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       71.7677  </td><td style=\"text-align: right;\">     5.59973 </td><td style=\"text-align: right;\">   9.45295    </td><td style=\"text-align: right;\">  25.5246     </td></tr>\n",
       "<tr><td>FSR_Trainable_26d6aa8b</td><td>TERMINATED</td><td>172.26.215.93:261372</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6e40</td><td>[&#x27;force&#x27;, &#x27;x_co_b2c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     4</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000131881</td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.13524 </td><td style=\"text-align: right;\">   439.644   </td><td style=\"text-align: right;\">1125.62       </td><td style=\"text-align: right;\">   4.65801e+17</td></tr>\n",
       "<tr><td>FSR_Trainable_2cac426f</td><td>TERMINATED</td><td>172.26.215.93:261870</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_8f40</td><td>[&#x27;force&#x27;, &#x27;x_co_74c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     8</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.0220201  </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        2.70467 </td><td style=\"text-align: right;\">   141.196   </td><td style=\"text-align: right;\"> 229.988      </td><td style=\"text-align: right;\">1036.14       </td></tr>\n",
       "<tr><td>FSR_Trainable_21069100</td><td>TERMINATED</td><td>172.26.215.93:262131</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_a900</td><td>[&#x27;force&#x27;, &#x27;x_co_c700</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     5</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00030263 </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.968869</td><td style=\"text-align: right;\">   666.291   </td><td style=\"text-align: right;\">1412.98       </td><td style=\"text-align: right;\">   6.68374e+17</td></tr>\n",
       "<tr><td>FSR_Trainable_958c204f</td><td>TERMINATED</td><td>172.26.215.93:262598</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_f4c0</td><td>[&#x27;force&#x27;, &#x27;x_co_d000</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     7</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.0774584  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        2.37061 </td><td style=\"text-align: right;\">727584       </td><td style=\"text-align: right;\">   1.46318e+06</td><td style=\"text-align: right;\">   1.33789e+21</td></tr>\n",
       "<tr><td>FSR_Trainable_0ef02b34</td><td>TERMINATED</td><td>172.26.215.93:262818</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_ce00</td><td>[&#x27;force&#x27;, &#x27;x_co_8840</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     7</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.00141911 </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        3.24243 </td><td style=\"text-align: right;\">    18.0935  </td><td style=\"text-align: right;\">  30.051      </td><td style=\"text-align: right;\">   4.29378e+16</td></tr>\n",
       "<tr><td>FSR_Trainable_0f6bd4bc</td><td>TERMINATED</td><td>172.26.215.93:263073</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_4840</td><td>[&#x27;force&#x27;, &#x27;x_co_ec00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00547964 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       70.7007  </td><td style=\"text-align: right;\">     0.512146</td><td style=\"text-align: right;\">   0.834946   </td><td style=\"text-align: right;\">   2.62194    </td></tr>\n",
       "<tr><td>FSR_Trainable_a1f9db66</td><td>TERMINATED</td><td>172.26.215.93:263304</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_1a40</td><td>[&#x27;force&#x27;, &#x27;x_co_7a40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     7</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.000152438</td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.36804 </td><td style=\"text-align: right;\">   747.44    </td><td style=\"text-align: right;\">1225.91       </td><td style=\"text-align: right;\">   1.48304e+18</td></tr>\n",
       "<tr><td>FSR_Trainable_60504e3e</td><td>TERMINATED</td><td>172.26.215.93:263405</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_74c0</td><td>[&#x27;force&#x27;, &#x27;x_co_5f80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     4</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        5.80233e-05</td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.928297</td><td style=\"text-align: right;\">   297.867   </td><td style=\"text-align: right;\"> 588.196      </td><td style=\"text-align: right;\">   2.71384e+17</td></tr>\n",
       "<tr><td>FSR_Trainable_ab967e63</td><td>TERMINATED</td><td>172.26.215.93:263718</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_0e00</td><td>[&#x27;force&#x27;, &#x27;x_co_6900</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     5</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000952098</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.55367 </td><td style=\"text-align: right;\">    64.8415  </td><td style=\"text-align: right;\"> 112.746      </td><td style=\"text-align: right;\"> 435.797      </td></tr>\n",
       "<tr><td>FSR_Trainable_952233df</td><td>TERMINATED</td><td>172.26.215.93:263964</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_4e40</td><td>[&#x27;force&#x27;, &#x27;x_co_1b00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        1.24416e-05</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       68.5182  </td><td style=\"text-align: right;\">     1.27909 </td><td style=\"text-align: right;\">   1.90709    </td><td style=\"text-align: right;\">   6.65513    </td></tr>\n",
       "<tr><td>FSR_Trainable_887a8ade</td><td>TERMINATED</td><td>172.26.215.93:264200</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_b940</td><td>[&#x27;force&#x27;, &#x27;x_co_7b00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        1.59923e-05</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       73.4473  </td><td style=\"text-align: right;\">     0.672258</td><td style=\"text-align: right;\">   1.14549    </td><td style=\"text-align: right;\">   2.83104    </td></tr>\n",
       "<tr><td>FSR_Trainable_bbd0c5e6</td><td>TERMINATED</td><td>172.26.215.93:264430</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_eb40</td><td>[&#x27;force&#x27;, &#x27;x_co_7440</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        1.99223e-05</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       73.3609  </td><td style=\"text-align: right;\">     0.61522 </td><td style=\"text-align: right;\">   0.992971   </td><td style=\"text-align: right;\">   1.98131    </td></tr>\n",
       "<tr><td>FSR_Trainable_c7777b46</td><td>TERMINATED</td><td>172.26.215.93:264752</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_3940</td><td>[&#x27;force&#x27;, &#x27;x_co_7340</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        2.31118e-05</td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       77.7375  </td><td style=\"text-align: right;\">     0.774982</td><td style=\"text-align: right;\">   1.19518    </td><td style=\"text-align: right;\">   2.87813    </td></tr>\n",
       "<tr><td>FSR_Trainable_b32403dc</td><td>TERMINATED</td><td>172.26.215.93:265032</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_6740</td><td>[&#x27;force&#x27;, &#x27;x_co_6940</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00832486 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       76.5429  </td><td style=\"text-align: right;\">     0.48362 </td><td style=\"text-align: right;\">   0.766764   </td><td style=\"text-align: right;\">   2.18819    </td></tr>\n",
       "<tr><td>FSR_Trainable_7c048b8f</td><td>TERMINATED</td><td>172.26.215.93:265510</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6f80</td><td>[&#x27;force&#x27;, &#x27;x_co_0c40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00374212 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       76.1398  </td><td style=\"text-align: right;\">     0.559438</td><td style=\"text-align: right;\">   0.909787   </td><td style=\"text-align: right;\">   2.89002    </td></tr>\n",
       "<tr><td>FSR_Trainable_fd359cb8</td><td>TERMINATED</td><td>172.26.215.93:265742</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_9a00</td><td>[&#x27;force&#x27;, &#x27;x_co_af00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00411881 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       74.1287  </td><td style=\"text-align: right;\">     0.586962</td><td style=\"text-align: right;\">   0.947658   </td><td style=\"text-align: right;\">   3.09283    </td></tr>\n",
       "<tr><td>FSR_Trainable_8690cda0</td><td>TERMINATED</td><td>172.26.215.93:266058</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_50c0</td><td>[&#x27;force&#x27;, &#x27;x_co_2580</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00525257 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       80.3247  </td><td style=\"text-align: right;\">     0.610148</td><td style=\"text-align: right;\">   0.9978     </td><td style=\"text-align: right;\">   3.2393     </td></tr>\n",
       "<tr><td>FSR_Trainable_10ef409d</td><td>TERMINATED</td><td>172.26.215.93:266330</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_35c0</td><td>[&#x27;force&#x27;, &#x27;x_co_c400</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00458682 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       75.6755  </td><td style=\"text-align: right;\">     0.575011</td><td style=\"text-align: right;\">   0.949953   </td><td style=\"text-align: right;\">   3.0756     </td></tr>\n",
       "<tr><td>FSR_Trainable_619004dc</td><td>TERMINATED</td><td>172.26.215.93:266603</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1c00</td><td>[&#x27;force&#x27;, &#x27;x_co_32c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00637019 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       68.1091  </td><td style=\"text-align: right;\">     0.624229</td><td style=\"text-align: right;\">   1.02933    </td><td style=\"text-align: right;\">   3.26813    </td></tr>\n",
       "<tr><td>FSR_Trainable_43fcd44e</td><td>ERROR     </td><td>172.26.215.93:260367</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_fe80</td><td>[&#x27;force&#x27;, &#x27;x_co_f4c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     4</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.0869721  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_4d5dc9c2</td><td>ERROR     </td><td>172.26.215.93:260528</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_c0c0</td><td>[&#x27;force&#x27;, &#x27;x_co_fac0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     8</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0139041  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_ca6ab145</td><td>ERROR     </td><td>172.26.215.93:261124</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_8580</td><td>[&#x27;force&#x27;, &#x27;x_co_a980</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        1.25998e-05</td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_5cc7b50b</td><td>ERROR     </td><td>172.26.215.93:261621</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_9dc0</td><td>[&#x27;force&#x27;, &#x27;x_co_a780</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.017724   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_e0139bc1</td><td>ERROR     </td><td>172.26.215.93:262367</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_c940</td><td>[&#x27;force&#x27;, &#x27;x_co_8f00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     7</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.0226831  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_edbf5674</td><td>ERROR     </td><td>172.26.215.93:265288</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>median</td><td>[&#x27;FSR_for_force_1b40</td><td>[&#x27;force&#x27;, &#x27;x_co_01c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     2</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00953069 </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_63cd847d</td><td>ERROR     </td><td>172.26.215.93:266822</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_da00</td><td>[&#x27;force&#x27;, &#x27;x_co_9c40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0133672  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_971919c0</td><td>ERROR     </td><td>172.26.215.93:267061</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_f0c0</td><td>[&#x27;force&#x27;, &#x27;x_co_b640</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0141848  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_d853c660</td><td>ERROR     </td><td>172.26.215.93:267307</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d140</td><td>[&#x27;force&#x27;, &#x27;x_co_7b80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.013209   </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_60e69b40</td><td>ERROR     </td><td>172.26.215.93:267558</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_be00</td><td>[&#x27;force&#x27;, &#x27;x_co_d380</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0159255  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a729e8d5</td><td>ERROR     </td><td>172.26.215.93:267938</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_ca00</td><td>[&#x27;force&#x27;, &#x27;x_co_dd80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0230273  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_11c78141</td><td>ERROR     </td><td>172.26.215.93:268193</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1200</td><td>[&#x27;force&#x27;, &#x27;x_co_c380</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0124241  </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_9d1f0ebb</td><td>ERROR     </td><td>172.26.215.93:268428</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1ec0</td><td>[&#x27;force&#x27;, &#x27;x_co_aa80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0137725  </td><td>sklearn.preproc_cb70</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_64a7a150</td><td>ERROR     </td><td>172.26.215.93:268674</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_58c0</td><td>[&#x27;force&#x27;, &#x27;x_co_3b80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0167095  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_351613df</td><td>ERROR     </td><td>172.26.215.93:268770</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_5e00</td><td>[&#x27;force&#x27;, &#x27;x_co_a2c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0240651  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_7ecfe12d</td><td>ERROR     </td><td>172.26.215.93:269090</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_7740</td><td>[&#x27;force&#x27;, &#x27;x_co_4bc0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.011614   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_2f1488dc</td><td>ERROR     </td><td>172.26.215.93:269187</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_5f40</td><td>[&#x27;force&#x27;, &#x27;x_co_3c80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0126314  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_2a10d033</td><td>ERROR     </td><td>172.26.215.93:269511</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_e7c0</td><td>[&#x27;force&#x27;, &#x27;x_co_5940</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.011909   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_43872776</td><td>ERROR     </td><td>172.26.215.93:269614</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_f2c0</td><td>[&#x27;force&#x27;, &#x27;x_co_4040</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0156105  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_531ddeb1</td><td>ERROR     </td><td>172.26.215.93:269936</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_5100</td><td>[&#x27;force&#x27;, &#x27;x_co_ec80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0130022  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_98575263</td><td>ERROR     </td><td>172.26.215.93:270033</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_5380</td><td>[&#x27;force&#x27;, &#x27;x_co_ca80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0144092  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_52703439</td><td>ERROR     </td><td>172.26.215.93:270361</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_14c0</td><td>[&#x27;force&#x27;, &#x27;x_co_e640</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0162647  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_7bb60977</td><td>ERROR     </td><td>172.26.215.93:270458</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_ca40</td><td>[&#x27;force&#x27;, &#x27;x_co_f440</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0258954  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_d0631592</td><td>ERROR     </td><td>172.26.215.93:270784</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_e580</td><td>[&#x27;force&#x27;, &#x27;x_co_1440</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0137003  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_2c66a9b4</td><td>ERROR     </td><td>172.26.215.93:270883</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d700</td><td>[&#x27;force&#x27;, &#x27;x_co_09c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0138555  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a618a14f</td><td>ERROR     </td><td>172.26.215.93:271209</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_e480</td><td>[&#x27;force&#x27;, &#x27;x_co_ff00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0129593  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_1c1b9820</td><td>ERROR     </td><td>172.26.215.93:271308</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d740</td><td>[&#x27;force&#x27;, &#x27;x_co_3880</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0145822  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_38c148a5</td><td>ERROR     </td><td>172.26.215.93:271627</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d6c0</td><td>[&#x27;force&#x27;, &#x27;x_co_0300</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0134821  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_417f094f</td><td>ERROR     </td><td>172.26.215.93:271720</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1c00</td><td>[&#x27;force&#x27;, &#x27;x_co_31c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0145084  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_30eac9ce</td><td>ERROR     </td><td>172.26.215.93:272048</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_3d80</td><td>[&#x27;force&#x27;, &#x27;x_co_4d40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0171843  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_8ac82c65</td><td>ERROR     </td><td>172.26.215.93:272144</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_f500</td><td>[&#x27;force&#x27;, &#x27;x_co_fc40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0133105  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_46e653c7</td><td>ERROR     </td><td>172.26.215.93:272465</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_f900</td><td>[&#x27;force&#x27;, &#x27;x_co_e480</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0156192  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a1730c8a</td><td>ERROR     </td><td>172.26.215.93:272564</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_36c0</td><td>[&#x27;force&#x27;, &#x27;x_co_d800</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.014706   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_6205df9b</td><td>ERROR     </td><td>172.26.215.93:272879</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d700</td><td>[&#x27;force&#x27;, &#x27;x_co_4e80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0174187  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_fc0be644</td><td>ERROR     </td><td>172.26.215.93:272975</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d0c0</td><td>[&#x27;force&#x27;, &#x27;x_co_f6c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0146288  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_f7f52756</td><td>ERROR     </td><td>172.26.215.93:273299</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_e240</td><td>[&#x27;force&#x27;, &#x27;x_co_0740</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0117668  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_478dea9a</td><td>ERROR     </td><td>172.26.215.93:273397</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_f580</td><td>[&#x27;force&#x27;, &#x27;x_co_5580</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0126672  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_6baa37a1</td><td>ERROR     </td><td>172.26.215.93:273721</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_4580</td><td>[&#x27;force&#x27;, &#x27;x_co_8540</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0141257  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_fee9192e</td><td>ERROR     </td><td>172.26.215.93:273818</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6380</td><td>[&#x27;force&#x27;, &#x27;x_co_e680</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0267732  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_08dd982a</td><td>ERROR     </td><td>172.26.215.93:274144</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1580</td><td>[&#x27;force&#x27;, &#x27;x_co_13c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0143003  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_3834e2c6</td><td>ERROR     </td><td>172.26.215.93:274237</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_d500</td><td>[&#x27;force&#x27;, &#x27;x_co_b9c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0111278  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_fb5da508</td><td>ERROR     </td><td>172.26.215.93:274559</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_c940</td><td>[&#x27;force&#x27;, &#x27;x_co_69c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0150779  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_1fb63a46</td><td>ERROR     </td><td>172.26.215.93:274655</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_23c0</td><td>[&#x27;force&#x27;, &#x27;x_co_6240</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0167244  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_bfffe96c</td><td>ERROR     </td><td>172.26.215.93:274979</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_af00</td><td>[&#x27;force&#x27;, &#x27;x_co_7880</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0134403  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_83963611</td><td>ERROR     </td><td>172.26.215.93:275078</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6bc0</td><td>[&#x27;force&#x27;, &#x27;x_co_11c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0136568  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_95e10e0c</td><td>ERROR     </td><td>172.26.215.93:275400</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_22c0</td><td>[&#x27;force&#x27;, &#x27;x_co_0cc0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0150855  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_225e0ef4</td><td>ERROR     </td><td>172.26.215.93:275494</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_13c0</td><td>[&#x27;force&#x27;, &#x27;x_co_0c00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0177406  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_9230f8bf</td><td>ERROR     </td><td>172.26.215.93:275814</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_20c0</td><td>[&#x27;force&#x27;, &#x27;x_co_3740</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0174974  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_5df754b0</td><td>ERROR     </td><td>172.26.215.93:275911</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_7b00</td><td>[&#x27;force&#x27;, &#x27;x_co_3540</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0151741  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a10d27d1</td><td>ERROR     </td><td>172.26.215.93:276229</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_05c0</td><td>[&#x27;force&#x27;, &#x27;x_co_2380</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.015133   </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_5837f84a</td><td>ERROR     </td><td>172.26.215.93:276329</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_0180</td><td>[&#x27;force&#x27;, &#x27;x_co_5dc0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.012696   </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_7cd96ac9</td><td>ERROR     </td><td>172.26.215.93:276651</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6c40</td><td>[&#x27;force&#x27;, &#x27;x_co_7e80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0138236  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_ce8f2ddc</td><td>ERROR     </td><td>172.26.215.93:276747</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_6a00</td><td>[&#x27;force&#x27;, &#x27;x_co_2d00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0152374  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_ce3191bc</td><td>ERROR     </td><td>172.26.215.93:277075</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_0700</td><td>[&#x27;force&#x27;, &#x27;x_co_bc00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0183783  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_16c1edc2</td><td>ERROR     </td><td>172.26.215.93:277171</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_52c0</td><td>[&#x27;force&#x27;, &#x27;x_co_1940</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0187117  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_04c92bb8</td><td>ERROR     </td><td>172.26.215.93:277494</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_2080</td><td>[&#x27;force&#x27;, &#x27;x_co_b9c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.012859   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_fe1ae516</td><td>ERROR     </td><td>172.26.215.93:277586</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_7880</td><td>[&#x27;force&#x27;, &#x27;x_co_6ec0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0117932  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_876067fd</td><td>ERROR     </td><td>172.26.215.93:277912</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_3ec0</td><td>[&#x27;force&#x27;, &#x27;x_co_1f40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0166041  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_cd6ea670</td><td>ERROR     </td><td>172.26.215.93:277993</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_8900</td><td>[&#x27;force&#x27;, &#x27;x_co_6340</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.010765   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a67f43be</td><td>ERROR     </td><td>172.26.215.93:278334</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_0140</td><td>[&#x27;force&#x27;, &#x27;x_co_9a00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.014381   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_2acb15cf</td><td>ERROR     </td><td>172.26.215.93:278430</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1c00</td><td>[&#x27;force&#x27;, &#x27;x_co_3540</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0148303  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_32a8a03b</td><td>ERROR     </td><td>172.26.215.93:278750</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_5440</td><td>[&#x27;force&#x27;, &#x27;x_co_20c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0154438  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_e26788fe</td><td>ERROR     </td><td>172.26.215.93:278850</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_a7c0</td><td>[&#x27;force&#x27;, &#x27;x_co_8a80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0140778  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_16d165c1</td><td>ERROR     </td><td>172.26.215.93:279174</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_3200</td><td>[&#x27;force&#x27;, &#x27;x_co_ab40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.014482   </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_ae231229</td><td>ERROR     </td><td>172.26.215.93:279272</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_3280</td><td>[&#x27;force&#x27;, &#x27;x_co_3400</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0136465  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_9a435255</td><td>ERROR     </td><td>172.26.215.93:279594</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_3100</td><td>[&#x27;force&#x27;, &#x27;x_co_2c00</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0148059  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_1d6566d5</td><td>ERROR     </td><td>172.26.215.93:279689</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1e40</td><td>[&#x27;force&#x27;, &#x27;x_co_3fc0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0136281  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_479e6a56</td><td>ERROR     </td><td>172.26.215.93:280006</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_16c0</td><td>[&#x27;force&#x27;, &#x27;x_co_8080</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0129337  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_a1ef9b8b</td><td>ERROR     </td><td>172.26.215.93:280101</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_34c0</td><td>[&#x27;force&#x27;, &#x27;x_co_a940</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0101204  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_8f8427c8</td><td>ERROR     </td><td>172.26.215.93:280439</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_0140</td><td>[&#x27;force&#x27;, &#x27;x_co_21c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0140669  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_b4e7377c</td><td>ERROR     </td><td>172.26.215.93:280531</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1000</td><td>[&#x27;force&#x27;, &#x27;x_co_a7c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0237366  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_676ec781</td><td>ERROR     </td><td>172.26.215.93:280853</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_1380</td><td>[&#x27;force&#x27;, &#x27;x_co_23c0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0128806  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_67d56bc6</td><td>ERROR     </td><td>172.26.215.93:280953</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_9f40</td><td>[&#x27;force&#x27;, &#x27;x_co_1e80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0141979  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_dbe40062</td><td>ERROR     </td><td>172.26.215.93:281277</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_2700</td><td>[&#x27;force&#x27;, &#x27;x_co_5d40</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0137461  </td><td>sklearn.preproc_cf30</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_75837ea5</td><td>ERROR     </td><td>172.26.215.93:281377</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_19c0</td><td>[&#x27;force&#x27;, &#x27;x_co_1280</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0148331  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_184ab78c</td><td>ERROR     </td><td>172.26.215.93:281703</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_41c0</td><td>[&#x27;force&#x27;, &#x27;x_co_4ac0</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0129188  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_1857e24d</td><td>ERROR     </td><td>172.26.215.93:281809</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_db80</td><td>[&#x27;force&#x27;, &#x27;x_co_0840</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0155824  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "<tr><td>FSR_Trainable_17d3bd89</td><td>ERROR     </td><td>172.26.215.93:282136</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_ced0</td><td>sklearn.impute._1200</td><td>mean  </td><td>[&#x27;FSR_for_force_08c0</td><td>[&#x27;force&#x27;, &#x27;x_co_ed80</td><td>fsr_model.FSRGr_2fb0</td><td style=\"text-align: right;\">                     3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0197059  </td><td>sklearn.preproc_cb10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">              </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 12:08:41,735\tINFO wandb.py:320 -- Already logged into W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>hostname       </th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_04c92bb8</td><td>2023-08-17_12-23-10</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277494</td><td style=\"text-align: right;\"> 1692242590</td><td>04c92bb8  </td></tr>\n",
       "<tr><td>FSR_Trainable_08dd982a</td><td>2023-08-17_12-20-56</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">274144</td><td style=\"text-align: right;\"> 1692242456</td><td>08dd982a  </td></tr>\n",
       "<tr><td>FSR_Trainable_0ef02b34</td><td>2023-08-17_12-11-12</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">262818</td><td style=\"text-align: right;\"> 1692241872</td><td>0ef02b34  </td></tr>\n",
       "<tr><td>FSR_Trainable_0f6bd4bc</td><td>2023-08-17_12-12-42</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">263073</td><td style=\"text-align: right;\"> 1692241962</td><td>0f6bd4bc  </td></tr>\n",
       "<tr><td>FSR_Trainable_10ef409d</td><td>2023-08-17_12-16-38</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">266330</td><td style=\"text-align: right;\"> 1692242198</td><td>10ef409d  </td></tr>\n",
       "<tr><td>FSR_Trainable_11c78141</td><td>2023-08-17_12-16-52</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">268193</td><td style=\"text-align: right;\"> 1692242212</td><td>11c78141  </td></tr>\n",
       "<tr><td>FSR_Trainable_16c1edc2</td><td>2023-08-17_12-23-01</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277171</td><td style=\"text-align: right;\"> 1692242581</td><td>16c1edc2  </td></tr>\n",
       "<tr><td>FSR_Trainable_16d165c1</td><td>2023-08-17_12-24-20</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">279174</td><td style=\"text-align: right;\"> 1692242660</td><td>16d165c1  </td></tr>\n",
       "<tr><td>FSR_Trainable_17d3bd89</td><td>2023-08-17_12-26-33</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">282136</td><td style=\"text-align: right;\"> 1692242793</td><td>17d3bd89  </td></tr>\n",
       "<tr><td>FSR_Trainable_184ab78c</td><td>2023-08-17_12-26-11</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">281703</td><td style=\"text-align: right;\"> 1692242771</td><td>184ab78c  </td></tr>\n",
       "<tr><td>FSR_Trainable_1857e24d</td><td>2023-08-17_12-26-21</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">281809</td><td style=\"text-align: right;\"> 1692242781</td><td>1857e24d  </td></tr>\n",
       "<tr><td>FSR_Trainable_1c1b9820</td><td>2023-08-17_12-19-08</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">271308</td><td style=\"text-align: right;\"> 1692242348</td><td>1c1b9820  </td></tr>\n",
       "<tr><td>FSR_Trainable_1d6566d5</td><td>2023-08-17_12-24-43</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">279689</td><td style=\"text-align: right;\"> 1692242683</td><td>1d6566d5  </td></tr>\n",
       "<tr><td>FSR_Trainable_1fb63a46</td><td>2023-08-17_12-21-21</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">274655</td><td style=\"text-align: right;\"> 1692242481</td><td>1fb63a46  </td></tr>\n",
       "<tr><td>FSR_Trainable_21069100</td><td>2023-08-17_12-10-41</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">262131</td><td style=\"text-align: right;\"> 1692241841</td><td>21069100  </td></tr>\n",
       "<tr><td>FSR_Trainable_225e0ef4</td><td>2023-08-17_12-21-53</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">275494</td><td style=\"text-align: right;\"> 1692242513</td><td>225e0ef4  </td></tr>\n",
       "<tr><td>FSR_Trainable_26d6aa8b</td><td>2023-08-17_12-09-54</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">261372</td><td style=\"text-align: right;\"> 1692241794</td><td>26d6aa8b  </td></tr>\n",
       "<tr><td>FSR_Trainable_28d7c7bd</td><td>2023-08-17_12-10-35</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">260106</td><td style=\"text-align: right;\"> 1692241835</td><td>28d7c7bd  </td></tr>\n",
       "<tr><td>FSR_Trainable_2a10d033</td><td>2023-08-17_12-17-48</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">269511</td><td style=\"text-align: right;\"> 1692242268</td><td>2a10d033  </td></tr>\n",
       "<tr><td>FSR_Trainable_2acb15cf</td><td>2023-08-17_12-23-52</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">278430</td><td style=\"text-align: right;\"> 1692242632</td><td>2acb15cf  </td></tr>\n",
       "<tr><td>FSR_Trainable_2c66a9b4</td><td>2023-08-17_12-18-53</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">270883</td><td style=\"text-align: right;\"> 1692242333</td><td>2c66a9b4  </td></tr>\n",
       "<tr><td>FSR_Trainable_2cac426f</td><td>2023-08-17_12-10-29</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">261870</td><td style=\"text-align: right;\"> 1692241829</td><td>2cac426f  </td></tr>\n",
       "<tr><td>FSR_Trainable_2f1488dc</td><td>2023-08-17_12-17-39</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">269187</td><td style=\"text-align: right;\"> 1692242259</td><td>2f1488dc  </td></tr>\n",
       "<tr><td>FSR_Trainable_30eac9ce</td><td>2023-08-17_12-19-31</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272048</td><td style=\"text-align: right;\"> 1692242371</td><td>30eac9ce  </td></tr>\n",
       "<tr><td>FSR_Trainable_32a8a03b</td><td>2023-08-17_12-24-02</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">278750</td><td style=\"text-align: right;\"> 1692242642</td><td>32a8a03b  </td></tr>\n",
       "<tr><td>FSR_Trainable_351613df</td><td>2023-08-17_12-17-20</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">268770</td><td style=\"text-align: right;\"> 1692242240</td><td>351613df  </td></tr>\n",
       "<tr><td>FSR_Trainable_37c9b0d4</td><td>2023-08-17_12-10-35</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">260182</td><td style=\"text-align: right;\"> 1692241835</td><td>37c9b0d4  </td></tr>\n",
       "<tr><td>FSR_Trainable_3834e2c6</td><td>2023-08-17_12-21-03</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">274237</td><td style=\"text-align: right;\"> 1692242463</td><td>3834e2c6  </td></tr>\n",
       "<tr><td>FSR_Trainable_38c148a5</td><td>2023-08-17_12-19-17</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">271627</td><td style=\"text-align: right;\"> 1692242357</td><td>38c148a5  </td></tr>\n",
       "<tr><td>FSR_Trainable_417f094f</td><td>2023-08-17_12-19-23</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">271720</td><td style=\"text-align: right;\"> 1692242363</td><td>417f094f  </td></tr>\n",
       "<tr><td>FSR_Trainable_43872776</td><td>2023-08-17_12-17-57</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">269614</td><td style=\"text-align: right;\"> 1692242277</td><td>43872776  </td></tr>\n",
       "<tr><td>FSR_Trainable_43fcd44e</td><td>2023-08-17_12-09-03</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">260367</td><td style=\"text-align: right;\"> 1692241743</td><td>43fcd44e  </td></tr>\n",
       "<tr><td>FSR_Trainable_46857252</td><td>2023-08-17_12-10-53</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">260884</td><td style=\"text-align: right;\"> 1692241853</td><td>46857252  </td></tr>\n",
       "<tr><td>FSR_Trainable_46e653c7</td><td>2023-08-17_12-19-49</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272465</td><td style=\"text-align: right;\"> 1692242389</td><td>46e653c7  </td></tr>\n",
       "<tr><td>FSR_Trainable_478dea9a</td><td>2023-08-17_12-20-28</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">273397</td><td style=\"text-align: right;\"> 1692242428</td><td>478dea9a  </td></tr>\n",
       "<tr><td>FSR_Trainable_479e6a56</td><td>2023-08-17_12-24-52</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280006</td><td style=\"text-align: right;\"> 1692242692</td><td>479e6a56  </td></tr>\n",
       "<tr><td>FSR_Trainable_4d5dc9c2</td><td>2023-08-17_12-09-12</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">260528</td><td style=\"text-align: right;\"> 1692241752</td><td>4d5dc9c2  </td></tr>\n",
       "<tr><td>FSR_Trainable_52703439</td><td>2023-08-17_12-18-24</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">270361</td><td style=\"text-align: right;\"> 1692242304</td><td>52703439  </td></tr>\n",
       "<tr><td>FSR_Trainable_531ddeb1</td><td>2023-08-17_12-18-07</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">269936</td><td style=\"text-align: right;\"> 1692242287</td><td>531ddeb1  </td></tr>\n",
       "<tr><td>FSR_Trainable_5837f84a</td><td>2023-08-17_12-22-27</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">276329</td><td style=\"text-align: right;\"> 1692242547</td><td>5837f84a  </td></tr>\n",
       "<tr><td>FSR_Trainable_5cc7b50b</td><td>2023-08-17_12-10-09</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">261621</td><td style=\"text-align: right;\"> 1692241809</td><td>5cc7b50b  </td></tr>\n",
       "<tr><td>FSR_Trainable_5df754b0</td><td>2023-08-17_12-22-11</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">275911</td><td style=\"text-align: right;\"> 1692242531</td><td>5df754b0  </td></tr>\n",
       "<tr><td>FSR_Trainable_60504e3e</td><td>2023-08-17_12-11-33</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">263405</td><td style=\"text-align: right;\"> 1692241893</td><td>60504e3e  </td></tr>\n",
       "<tr><td>FSR_Trainable_60e69b40</td><td>2023-08-17_12-16-31</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">267558</td><td style=\"text-align: right;\"> 1692242191</td><td>60e69b40  </td></tr>\n",
       "<tr><td>FSR_Trainable_619004dc</td><td>2023-08-17_12-17-00</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">266603</td><td style=\"text-align: right;\"> 1692242220</td><td>619004dc  </td></tr>\n",
       "<tr><td>FSR_Trainable_6205df9b</td><td>2023-08-17_12-20-05</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272879</td><td style=\"text-align: right;\"> 1692242405</td><td>6205df9b  </td></tr>\n",
       "<tr><td>FSR_Trainable_63cd847d</td><td>2023-08-17_12-15-46</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">266822</td><td style=\"text-align: right;\"> 1692242146</td><td>63cd847d  </td></tr>\n",
       "<tr><td>FSR_Trainable_64a7a150</td><td>2023-08-17_12-17-11</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">268674</td><td style=\"text-align: right;\"> 1692242231</td><td>64a7a150  </td></tr>\n",
       "<tr><td>FSR_Trainable_676ec781</td><td>2023-08-17_12-25-29</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280853</td><td style=\"text-align: right;\"> 1692242729</td><td>676ec781  </td></tr>\n",
       "<tr><td>FSR_Trainable_67d56bc6</td><td>2023-08-17_12-25-37</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280953</td><td style=\"text-align: right;\"> 1692242737</td><td>67d56bc6  </td></tr>\n",
       "<tr><td>FSR_Trainable_6baa37a1</td><td>2023-08-17_12-20-38</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">273721</td><td style=\"text-align: right;\"> 1692242438</td><td>6baa37a1  </td></tr>\n",
       "<tr><td>FSR_Trainable_75837ea5</td><td>2023-08-17_12-26-00</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">281377</td><td style=\"text-align: right;\"> 1692242760</td><td>75837ea5  </td></tr>\n",
       "<tr><td>FSR_Trainable_7bb60977</td><td>2023-08-17_12-18-33</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">270458</td><td style=\"text-align: right;\"> 1692242313</td><td>7bb60977  </td></tr>\n",
       "<tr><td>FSR_Trainable_7c048b8f</td><td>2023-08-17_12-15-22</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">265510</td><td style=\"text-align: right;\"> 1692242122</td><td>7c048b8f  </td></tr>\n",
       "<tr><td>FSR_Trainable_7cd96ac9</td><td>2023-08-17_12-22-36</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">276651</td><td style=\"text-align: right;\"> 1692242556</td><td>7cd96ac9  </td></tr>\n",
       "<tr><td>FSR_Trainable_7ecfe12d</td><td>2023-08-17_12-17-31</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">269090</td><td style=\"text-align: right;\"> 1692242251</td><td>7ecfe12d  </td></tr>\n",
       "<tr><td>FSR_Trainable_83963611</td><td>2023-08-17_12-21-38</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">275078</td><td style=\"text-align: right;\"> 1692242498</td><td>83963611  </td></tr>\n",
       "<tr><td>FSR_Trainable_8690cda0</td><td>2023-08-17_12-16-13</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">266058</td><td style=\"text-align: right;\"> 1692242173</td><td>8690cda0  </td></tr>\n",
       "<tr><td>FSR_Trainable_876067fd</td><td>2023-08-17_12-23-27</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277912</td><td style=\"text-align: right;\"> 1692242607</td><td>876067fd  </td></tr>\n",
       "<tr><td>FSR_Trainable_887a8ade</td><td>2023-08-17_12-13-30</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">264200</td><td style=\"text-align: right;\"> 1692242010</td><td>887a8ade  </td></tr>\n",
       "<tr><td>FSR_Trainable_8ac82c65</td><td>2023-08-17_12-19-39</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272144</td><td style=\"text-align: right;\"> 1692242379</td><td>8ac82c65  </td></tr>\n",
       "<tr><td>FSR_Trainable_8f8427c8</td><td>2023-08-17_12-25-11</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280439</td><td style=\"text-align: right;\"> 1692242711</td><td>8f8427c8  </td></tr>\n",
       "<tr><td>FSR_Trainable_9230f8bf</td><td>2023-08-17_12-22-04</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">275814</td><td style=\"text-align: right;\"> 1692242524</td><td>9230f8bf  </td></tr>\n",
       "<tr><td>FSR_Trainable_952233df</td><td>2023-08-17_12-13-12</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">263964</td><td style=\"text-align: right;\"> 1692241992</td><td>952233df  </td></tr>\n",
       "<tr><td>FSR_Trainable_958c204f</td><td>2023-08-17_12-11-04</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">262598</td><td style=\"text-align: right;\"> 1692241864</td><td>958c204f  </td></tr>\n",
       "<tr><td>FSR_Trainable_95e10e0c</td><td>2023-08-17_12-21-47</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">275400</td><td style=\"text-align: right;\"> 1692242507</td><td>95e10e0c  </td></tr>\n",
       "<tr><td>FSR_Trainable_971919c0</td><td>2023-08-17_12-16-02</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">267061</td><td style=\"text-align: right;\"> 1692242162</td><td>971919c0  </td></tr>\n",
       "<tr><td>FSR_Trainable_98575263</td><td>2023-08-17_12-18-14</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">270033</td><td style=\"text-align: right;\"> 1692242294</td><td>98575263  </td></tr>\n",
       "<tr><td>FSR_Trainable_9a435255</td><td>2023-08-17_12-24-36</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">279594</td><td style=\"text-align: right;\"> 1692242676</td><td>9a435255  </td></tr>\n",
       "<tr><td>FSR_Trainable_9d1f0ebb</td><td>2023-08-17_12-17-02</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">268428</td><td style=\"text-align: right;\"> 1692242222</td><td>9d1f0ebb  </td></tr>\n",
       "<tr><td>FSR_Trainable_a10d27d1</td><td>2023-08-17_12-22-20</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">276229</td><td style=\"text-align: right;\"> 1692242540</td><td>a10d27d1  </td></tr>\n",
       "<tr><td>FSR_Trainable_a1730c8a</td><td>2023-08-17_12-19-56</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272564</td><td style=\"text-align: right;\"> 1692242396</td><td>a1730c8a  </td></tr>\n",
       "<tr><td>FSR_Trainable_a1ef9b8b</td><td>2023-08-17_12-25-00</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280101</td><td style=\"text-align: right;\"> 1692242700</td><td>a1ef9b8b  </td></tr>\n",
       "<tr><td>FSR_Trainable_a1f9db66</td><td>2023-08-17_12-11-26</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">263304</td><td style=\"text-align: right;\"> 1692241886</td><td>a1f9db66  </td></tr>\n",
       "<tr><td>FSR_Trainable_a618a14f</td><td>2023-08-17_12-19-01</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">271209</td><td style=\"text-align: right;\"> 1692242341</td><td>a618a14f  </td></tr>\n",
       "<tr><td>FSR_Trainable_a67f43be</td><td>2023-08-17_12-23-45</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">278334</td><td style=\"text-align: right;\"> 1692242625</td><td>a67f43be  </td></tr>\n",
       "<tr><td>FSR_Trainable_a729e8d5</td><td>2023-08-17_12-16-43</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">267938</td><td style=\"text-align: right;\"> 1692242203</td><td>a729e8d5  </td></tr>\n",
       "<tr><td>FSR_Trainable_ab967e63</td><td>2023-08-17_12-11-45</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">263718</td><td style=\"text-align: right;\"> 1692241905</td><td>ab967e63  </td></tr>\n",
       "<tr><td>FSR_Trainable_ae231229</td><td>2023-08-17_12-24-28</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">279272</td><td style=\"text-align: right;\"> 1692242668</td><td>ae231229  </td></tr>\n",
       "<tr><td>FSR_Trainable_b32403dc</td><td>2023-08-17_12-14-54</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">265032</td><td style=\"text-align: right;\"> 1692242094</td><td>b32403dc  </td></tr>\n",
       "<tr><td>FSR_Trainable_b4e7377c</td><td>2023-08-17_12-25-19</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">280531</td><td style=\"text-align: right;\"> 1692242719</td><td>b4e7377c  </td></tr>\n",
       "<tr><td>FSR_Trainable_bbd0c5e6</td><td>2023-08-17_12-13-39</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">264430</td><td style=\"text-align: right;\"> 1692242019</td><td>bbd0c5e6  </td></tr>\n",
       "<tr><td>FSR_Trainable_bfffe96c</td><td>2023-08-17_12-21-30</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">274979</td><td style=\"text-align: right;\"> 1692242490</td><td>bfffe96c  </td></tr>\n",
       "<tr><td>FSR_Trainable_c7777b46</td><td>2023-08-17_12-14-27</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">264752</td><td style=\"text-align: right;\"> 1692242067</td><td>c7777b46  </td></tr>\n",
       "<tr><td>FSR_Trainable_ca6ab145</td><td>2023-08-17_12-09-38</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">261124</td><td style=\"text-align: right;\"> 1692241778</td><td>ca6ab145  </td></tr>\n",
       "<tr><td>FSR_Trainable_cd6ea670</td><td>2023-08-17_12-23-35</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277993</td><td style=\"text-align: right;\"> 1692242615</td><td>cd6ea670  </td></tr>\n",
       "<tr><td>FSR_Trainable_ce3191bc</td><td>2023-08-17_12-22-54</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277075</td><td style=\"text-align: right;\"> 1692242574</td><td>ce3191bc  </td></tr>\n",
       "<tr><td>FSR_Trainable_ce8f2ddc</td><td>2023-08-17_12-22-45</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">276747</td><td style=\"text-align: right;\"> 1692242565</td><td>ce8f2ddc  </td></tr>\n",
       "<tr><td>FSR_Trainable_d0631592</td><td>2023-08-17_12-18-44</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">270784</td><td style=\"text-align: right;\"> 1692242324</td><td>d0631592  </td></tr>\n",
       "<tr><td>FSR_Trainable_d853c660</td><td>2023-08-17_12-16-19</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">267307</td><td style=\"text-align: right;\"> 1692242179</td><td>d853c660  </td></tr>\n",
       "<tr><td>FSR_Trainable_dbe40062</td><td>2023-08-17_12-25-49</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">281277</td><td style=\"text-align: right;\"> 1692242749</td><td>dbe40062  </td></tr>\n",
       "<tr><td>FSR_Trainable_e0139bc1</td><td>2023-08-17_12-10-50</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">262367</td><td style=\"text-align: right;\"> 1692241850</td><td>e0139bc1  </td></tr>\n",
       "<tr><td>FSR_Trainable_e26788fe</td><td>2023-08-17_12-24-10</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">278850</td><td style=\"text-align: right;\"> 1692242650</td><td>e26788fe  </td></tr>\n",
       "<tr><td>FSR_Trainable_edbf5674</td><td>2023-08-17_12-13-42</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">265288</td><td style=\"text-align: right;\"> 1692242022</td><td>edbf5674  </td></tr>\n",
       "<tr><td>FSR_Trainable_f7f52756</td><td>2023-08-17_12-20-20</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">273299</td><td style=\"text-align: right;\"> 1692242420</td><td>f7f52756  </td></tr>\n",
       "<tr><td>FSR_Trainable_fb5da508</td><td>2023-08-17_12-21-13</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">274559</td><td style=\"text-align: right;\"> 1692242473</td><td>fb5da508  </td></tr>\n",
       "<tr><td>FSR_Trainable_fc0be644</td><td>2023-08-17_12-20-11</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">272975</td><td style=\"text-align: right;\"> 1692242411</td><td>fc0be644  </td></tr>\n",
       "<tr><td>FSR_Trainable_fd359cb8</td><td>2023-08-17_12-15-31</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">265742</td><td style=\"text-align: right;\"> 1692242131</td><td>fd359cb8  </td></tr>\n",
       "<tr><td>FSR_Trainable_fe1ae516</td><td>2023-08-17_12-23-18</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">277586</td><td style=\"text-align: right;\"> 1692242598</td><td>fe1ae516  </td></tr>\n",
       "<tr><td>FSR_Trainable_fee9192e</td><td>2023-08-17_12-20-46</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">273818</td><td style=\"text-align: right;\"> 1692242446</td><td>fee9192e  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_28d7c7bd_1_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-08-41/wandb/run-20230817_120853-28d7c7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Syncing run FSR_Trainable_28d7c7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/28d7c7bd\n",
      "2023-08-17 12:09:04,317\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_43fcd44e\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=260367, ip=172.26.215.93, actor_id=f5ed745de32e2ab49bd996bd01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fa8d5c5f7f0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_37c9b0d4_2_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-08-47/wandb/run-20230817_120904-37c9b0d4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Syncing run FSR_Trainable_37c9b0d4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/37c9b0d4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_43fcd44e_3_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-08-55/wandb/run-20230817_120910-43fcd44e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Syncing run FSR_Trainable_43fcd44e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/43fcd44e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:09:13,823\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_4d5dc9c2\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=260528, ip=172.26.215.93, actor_id=c1ed508f00743ebe22ffbb3301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7efb29667850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: \\ 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: | 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb:  View run FSR_Trainable_43fcd44e at: https://wandb.ai/seokjin/FSR-prediction/runs/43fcd44e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260527)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_120910-43fcd44e/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_4d5dc9c2_4_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-03/wandb/run-20230817_120919-4d5dc9c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Syncing run FSR_Trainable_4d5dc9c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4d5dc9c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb:  View run FSR_Trainable_4d5dc9c2 at: https://wandb.ai/seokjin/FSR-prediction/runs/4d5dc9c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260742)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_120919-4d5dc9c2/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_46857252_5_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-12/wandb/run-20230817_120934-46857252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Syncing run FSR_Trainable_46857252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/46857252\n",
      "2023-08-17 12:09:39,643\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_ca6ab145\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=261124, ip=172.26.215.93, actor_id=85bed1d5dca1aa6be88b10d201000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f896a89f910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ca6ab145_6_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-25/wandb/run-20230817_120945-ca6ab145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Syncing run FSR_Trainable_ca6ab145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ca6ab145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:09:56,608\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.878 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:09:56,615\tWARNING util.py:315 -- The `process_trial_result` operation took 1.886 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:09:56,617\tWARNING util.py:315 -- Processing trial results took 1.888 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:09:56,619\tWARNING util.py:315 -- The `process_trial_result` operation took 1.890 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb:  View run FSR_Trainable_ca6ab145 at: https://wandb.ai/seokjin/FSR-prediction/runs/ca6ab145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261225)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_120945-ca6ab145/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_26d6aa8b_7_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-38/wandb/run-20230817_120959-26d6aa8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Syncing run FSR_Trainable_26d6aa8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/26d6aa8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: / 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)05 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                mae_coord 311.094\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                mae_force 79943.95642\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               mape_coord 66.2728\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               mape_force 6.518007983009319e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                   metric 2254.18044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               rmse_coord 900.03904\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               rmse_force 252377.63057\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:       time_since_restore 1.13524\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:         time_this_iter_s 1.13524\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:             time_total_s 1.13524\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:                timestamp 1692241794\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               tmae_coord 455.95985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:               tmae_force 439.6437\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              tmape_coord 7.85983310232401e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              tmape_force 4.6580069614662925e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              trmse_coord 1128.55853\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:              trmse_force 1125.62191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb:  View run FSR_Trainable_26d6aa8b at: https://wandb.ai/seokjin/FSR-prediction/runs/26d6aa8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261467)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_120959-26d6aa8b/logs\n",
      "2023-08-17 12:10:10,078\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_5cc7b50b\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=261621, ip=172.26.215.93, actor_id=02c9c13abdb1e217bfa0319201000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7efc7767b850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5cc7b50b_8_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-53/wandb/run-20230817_121016-5cc7b50b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Syncing run FSR_Trainable_5cc7b50b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/5cc7b50b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:10:28,563\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.887 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:10:28,566\tWARNING util.py:315 -- The `process_trial_result` operation took 1.891 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:10:28,569\tWARNING util.py:315 -- Processing trial results took 1.893 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:10:28,572\tWARNING util.py:315 -- The `process_trial_result` operation took 1.897 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb:  View run FSR_Trainable_5cc7b50b at: https://wandb.ai/seokjin/FSR-prediction/runs/5cc7b50b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261726)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121016-5cc7b50b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2cac426f_9_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-10-09/wandb/run-20230817_121031-2cac426f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Syncing run FSR_Trainable_2cac426f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2cac426f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Waiting for W&B process to finish... (success).\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                mae_coord 3.9083\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                mae_force 2567.10006\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               mape_coord 0.93269\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               mape_force 11067331250.83475\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                   metric 20.02816\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               rmse_coord 6.9161\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               rmse_force 4785.7069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:       time_since_restore 86.43222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:         time_this_iter_s 0.73098\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:             time_total_s 86.43222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:                timestamp 1692241835\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               tmae_coord 6.15119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:               tmae_force 6.6287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              tmape_coord 6729037256277347.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              tmape_force 40.94117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              trmse_coord 9.87529\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:              trmse_force 10.15287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb:  View run FSR_Trainable_28d7c7bd at: https://wandb.ai/seokjin/FSR-prediction/runs/28d7c7bd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_120853-28d7c7bd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              trmse_force \n",
      "2023-08-17 12:10:43,369\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:10:43,373\tWARNING util.py:315 -- The `process_trial_result` operation took 1.914 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:10:43,374\tWARNING util.py:315 -- Processing trial results took 1.916 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:10:43,377\tWARNING util.py:315 -- The `process_trial_result` operation took 1.919 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260181)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Run history:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260366)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Run summary:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: iterations_since_restore 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                mae_coord 59.3996\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                mae_force 36658.43491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               mape_coord 11.92158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               mape_force 77383644598.93811\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                   metric 378.03598\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               rmse_coord 106.90969\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               rmse_force 68260.84267\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:       time_since_restore 2.70467\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:         time_this_iter_s 1.2268\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:             time_total_s 2.70467\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:                timestamp 1692241829\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               tmae_coord 89.86548\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:               tmae_force 141.19569\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              tmape_coord 1.1239635214369405e+17\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              tmape_force 1036.14411\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:       training_iteration 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              trmse_coord 148.04819\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:              trmse_force 229.98779\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb:  View run FSR_Trainable_2cac426f at: https://wandb.ai/seokjin/FSR-prediction/runs/2cac426f\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=261961)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121031-2cac426f/logs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_21069100_10_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-10-25/wandb/run-20230817_121046-21069100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Syncing run FSR_Trainable_21069100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/21069100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:10:50,774\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_e0139bc1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=262367, ip=172.26.215.93, actor_id=c275b9a1bd86250c1f7d760601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f58375cf850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: / 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                mae_coord 190.0388\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                mae_force 138147.3295\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               mape_coord 51.12375\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               mape_force 9.869147872689834e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                   metric 2258.19954\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               rmse_coord 492.64168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               rmse_force 341807.34799\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:       time_since_restore 0.96887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:         time_this_iter_s 0.96887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:             time_total_s 0.96887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:                timestamp 1692241841\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               tmae_coord 359.91154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:               tmae_force 666.29115\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              tmape_coord 5.2153554377097805e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              tmape_force 6.683742569193393e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              trmse_coord 845.22346\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:              trmse_force 1412.97609\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb:  View run FSR_Trainable_21069100 at: https://wandb.ai/seokjin/FSR-prediction/runs/21069100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262233)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121046-21069100/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e0139bc1_11_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-10-40/wandb/run-20230817_121055-e0139bc1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Syncing run FSR_Trainable_e0139bc1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e0139bc1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=260992)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:11:03,370\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.921 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:03,375\tWARNING util.py:315 -- The `process_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:03,377\tWARNING util.py:315 -- Processing trial results took 1.929 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:03,379\tWARNING util.py:315 -- The `process_trial_result` operation took 1.930 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb:  View run FSR_Trainable_e0139bc1 at: https://wandb.ai/seokjin/FSR-prediction/runs/e0139bc1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262468)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121055-e0139bc1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_958c204f_12_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-10-50/wandb/run-20230817_121105-958c204f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Syncing run FSR_Trainable_958c204f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/958c204f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)08 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:11:10,450\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:10,452\tWARNING util.py:315 -- The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:10,455\tWARNING util.py:315 -- Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:10,456\tWARNING util.py:315 -- The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                mae_coord 8738549.53588\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                mae_force 1807713177.22\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               mape_coord 1990581.49282\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               mape_force 3.0558453705412995e+24\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                   metric 3882286.64437\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               rmse_coord 13890893.78485\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               rmse_force 4030243192.62652\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:       time_since_restore 2.37061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:         time_this_iter_s 0.94876\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:             time_total_s 2.37061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:                timestamp 1692241864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               tmae_coord 1669147.55208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:               tmae_force 727584.20085\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              tmape_coord 8.67303539075232e+19\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              tmape_force 1.3378853660161595e+21\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              trmse_coord 2419106.75575\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:              trmse_force 1463179.88862\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb:  View run FSR_Trainable_958c204f at: https://wandb.ai/seokjin/FSR-prediction/runs/958c204f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262709)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121105-958c204f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_0ef02b34_13_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-00/wandb/run-20230817_121112-0ef02b34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Syncing run FSR_Trainable_0ef02b34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0ef02b34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: / 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:11:18,888\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:18,889\tWARNING util.py:315 -- The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:18,893\tWARNING util.py:315 -- Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:18,897\tWARNING util.py:315 -- The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                mae_coord 66.90666\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                mae_force 46252.74014\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               mape_coord 11.15683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               mape_force 1.0577819154055248e+20\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                   metric 52.88736\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               rmse_coord 115.19075\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               rmse_force 93047.04436\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:       time_since_restore 3.24243\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:         time_this_iter_s 0.63129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:             time_total_s 3.24243\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:                timestamp 1692241872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               tmae_coord 13.76033\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:               tmae_force 18.09353\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              tmape_coord 876113759941136.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              tmape_force 4.293782834441641e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              trmse_coord 22.83631\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:              trmse_force 30.05105\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb:  View run FSR_Trainable_0ef02b34 at: https://wandb.ai/seokjin/FSR-prediction/runs/0ef02b34\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=262943)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121112-0ef02b34/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_0f6bd4bc_14_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-07/wandb/run-20230817_121121-0f6bd4bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Syncing run FSR_Trainable_0f6bd4bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0f6bd4bc\n",
      "2023-08-17 12:11:28,669\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.003 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:28,677\tWARNING util.py:315 -- The `process_trial_result` operation took 2.011 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:28,679\tWARNING util.py:315 -- Processing trial results took 2.014 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:28,681\tWARNING util.py:315 -- The `process_trial_result` operation took 2.016 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1f9db66_15_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-16/wandb/run-20230817_121131-a1f9db66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Syncing run FSR_Trainable_a1f9db66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a1f9db66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:11:35,543\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.898 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:35,548\tWARNING util.py:315 -- The `process_trial_result` operation took 1.904 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:35,550\tWARNING util.py:315 -- Processing trial results took 1.905 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:35,551\tWARNING util.py:315 -- The `process_trial_result` operation took 1.907 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: | 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                mae_coord 2226.40645\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                mae_force 1759110.35371\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               mape_coord 478.19656\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               mape_force 3.216831961753489e+21\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                   metric 2028.90483\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               rmse_coord 4120.26566\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               rmse_force 3261580.35034\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:       time_since_restore 1.36804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:         time_this_iter_s 1.36804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:             time_total_s 1.36804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:                timestamp 1692241886\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               tmae_coord 448.48528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:               tmae_force 747.43964\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              tmape_coord 2.0948440572241212e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              tmape_force 1.483044939275102e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              trmse_coord 802.99212\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:              trmse_force 1225.91271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb:  View run FSR_Trainable_a1f9db66 at: https://wandb.ai/seokjin/FSR-prediction/runs/a1f9db66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263404)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121131-a1f9db66/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121138-60504e3e/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121138-60504e3e/logs\n",
      "2023-08-17 12:11:45,067\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.008 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:45,070\tWARNING util.py:315 -- The `process_trial_result` operation took 2.011 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:45,072\tWARNING util.py:315 -- Processing trial results took 2.014 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:45,074\tWARNING util.py:315 -- The `process_trial_result` operation took 2.016 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263568)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ab967e63_17_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-32/wandb/run-20230817_121147-ab967e63\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Syncing run FSR_Trainable_ab967e63\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ab967e63\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                mae_coord 75.29763\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                mae_force 16091.83277\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               mape_coord 20.64827\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               mape_force 33944853571.98326\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                   metric 333.54553\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               rmse_coord 192.30311\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               rmse_force 25623.03667\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:       time_since_restore 1.55367\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:         time_this_iter_s 0.74856\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:             time_total_s 1.55367\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:                timestamp 1692241905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               tmae_coord 107.55275\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:               tmae_force 64.84155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              tmape_coord 9.814812619995608e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              tmape_force 435.79664\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              trmse_coord 220.79929\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:              trmse_force 112.74624\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb:  View run FSR_Trainable_ab967e63 at: https://wandb.ai/seokjin/FSR-prediction/runs/ab967e63\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121147-ab967e63/logs\n",
      "2023-08-17 12:11:55,813\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.524 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:55,816\tWARNING util.py:315 -- The `process_trial_result` operation took 2.529 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:11:55,818\tWARNING util.py:315 -- Processing trial results took 2.531 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:11:55,818\tWARNING util.py:315 -- The `process_trial_result` operation took 2.533 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263829)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_952233df_18_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-42/wandb/run-20230817_121158-952233df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Syncing run FSR_Trainable_952233df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/952233df\n",
      "2023-08-17 12:12:07,065\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.076 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:07,069\tWARNING util.py:315 -- The `process_trial_result` operation took 2.081 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:07,072\tWARNING util.py:315 -- Processing trial results took 2.084 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:12:07,073\tWARNING util.py:315 -- The `process_trial_result` operation took 2.085 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_887a8ade_19_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-11-52/wandb/run-20230817_121210-887a8ade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Syncing run FSR_Trainable_887a8ade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/887a8ade\n",
      "2023-08-17 12:12:20,323\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.731 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:20,328\tWARNING util.py:315 -- The `process_trial_result` operation took 2.736 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:20,331\tWARNING util.py:315 -- Processing trial results took 2.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:12:20,335\tWARNING util.py:315 -- The `process_trial_result` operation took 2.744 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_bbd0c5e6_20_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-12-04/wandb/run-20230817_121223-bbd0c5e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Syncing run FSR_Trainable_bbd0c5e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bbd0c5e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                mae_coord 0.37262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                mae_force 190.66062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               mape_coord 0.10289\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               mape_force 559392200.02348\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                   metric 1.86018\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               rmse_coord 0.69697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               rmse_force 346.18671\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:       time_since_restore 70.70068\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:         time_this_iter_s 0.86021\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:             time_total_s 70.70068\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:                timestamp 1692241962\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               tmae_coord 0.60652\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:               tmae_force 0.51215\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              tmape_coord 225071930370510.88\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              tmape_force 2.62194\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              trmse_coord 1.02523\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:              trmse_force 0.83495\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb:  View run FSR_Trainable_0f6bd4bc at: https://wandb.ai/seokjin/FSR-prediction/runs/0f6bd4bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=263174)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121121-0f6bd4bc/logs\n",
      "2023-08-17 12:12:58,744\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.287 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:58,752\tWARNING util.py:315 -- The `process_trial_result` operation took 2.296 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:12:58,755\tWARNING util.py:315 -- Processing trial results took 2.299 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:12:58,759\tWARNING util.py:315 -- The `process_trial_result` operation took 2.304 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_c7777b46_21_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-12-16/wandb/run-20230817_121302-c7777b46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Syncing run FSR_Trainable_c7777b46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c7777b46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                mae_coord 0.71928\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                mae_force 539.83331\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               mape_coord 0.16228\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               mape_force 2457712916.36876\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                   metric 3.8483\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               rmse_coord 1.29516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               rmse_force 1081.8979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:       time_since_restore 68.5182\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:         time_this_iter_s 0.679\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:             time_total_s 68.5182\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:                timestamp 1692241992\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               tmae_coord 1.18324\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:               tmae_force 1.27909\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              tmape_coord 13.43597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              tmape_force 6.65513\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              trmse_coord 1.94121\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:              trmse_force 1.90709\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb:  View run FSR_Trainable_952233df at: https://wandb.ai/seokjin/FSR-prediction/runs/952233df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264060)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121158-952233df/logs\n",
      "2023-08-17 12:13:27,366\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.147 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:13:27,369\tWARNING util.py:315 -- The `process_trial_result` operation took 2.151 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:13:27,374\tWARNING util.py:315 -- Processing trial results took 2.156 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:13:27,376\tWARNING util.py:315 -- The `process_trial_result` operation took 2.158 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_b32403dc_22_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-12-55/wandb/run-20230817_121330-b32403dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Syncing run FSR_Trainable_b32403dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b32403dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                mae_coord 0.58906\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                mae_force 257.77764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               mape_coord 0.16259\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               mape_force 884220308.41224\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                   metric 2.72344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               rmse_coord 1.10729\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               rmse_force 485.14552\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:       time_since_restore 73.44733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:         time_this_iter_s 0.7982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:             time_total_s 73.44733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:                timestamp 1692242010\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               tmae_coord 0.94395\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:               tmae_force 0.67226\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              tmape_coord 7.55142\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              tmape_force 2.83104\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              trmse_coord 1.57795\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:              trmse_force 1.14549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb:  View run FSR_Trainable_887a8ade at: https://wandb.ai/seokjin/FSR-prediction/runs/887a8ade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264293)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121210-887a8ade/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:13:42,789\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_edbf5674\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=265288, ip=172.26.215.93, actor_id=5892815a8174fc935c0a41cb01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f29883678b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                mae_coord 0.46409\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                mae_force 240.89831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               mape_coord 0.1154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               mape_force 919924843.22405\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                   metric 2.22178\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               rmse_coord 0.82211\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               rmse_force 447.05157\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:       time_since_restore 73.36095\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:         time_this_iter_s 0.7289\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:             time_total_s 73.36095\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:                timestamp 1692242019\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               tmae_coord 0.74493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:               tmae_force 0.61522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              tmape_coord 4.92694\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              tmape_force 1.98131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              trmse_coord 1.22881\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:              trmse_force 0.99297\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb:  View run FSR_Trainable_bbd0c5e6 at: https://wandb.ai/seokjin/FSR-prediction/runs/bbd0c5e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264527)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121223-bbd0c5e6/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_edbf5674_23_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-13-24/wandb/run-20230817_121349-edbf5674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Syncing run FSR_Trainable_edbf5674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/edbf5674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:13:57,497\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.103 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:13:57,503\tWARNING util.py:315 -- The `process_trial_result` operation took 2.110 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:13:57,505\tWARNING util.py:315 -- Processing trial results took 2.113 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:13:57,509\tWARNING util.py:315 -- The `process_trial_result` operation took 2.117 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb:  View run FSR_Trainable_edbf5674 at: https://wandb.ai/seokjin/FSR-prediction/runs/edbf5674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265366)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121349-edbf5674/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7c048b8f_24_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-13-42/wandb/run-20230817_121401-7c048b8f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Syncing run FSR_Trainable_7c048b8f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7c048b8f\n",
      "2023-08-17 12:14:11,851\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.996 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:14:11,856\tWARNING util.py:315 -- The `process_trial_result` operation took 2.003 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:14:11,858\tWARNING util.py:315 -- Processing trial results took 2.005 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:14:11,861\tWARNING util.py:315 -- The `process_trial_result` operation took 2.007 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fd359cb8_25_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-13-54/wandb/run-20230817_121415-fd359cb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Syncing run FSR_Trainable_fd359cb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fd359cb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                mae_coord 0.41595\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                mae_force 296.58811\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               mape_coord 0.1046\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               mape_force 974089379.43378\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                   metric 2.28905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               rmse_coord 0.74584\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               rmse_force 529.94026\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:       time_since_restore 77.73749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:         time_this_iter_s 0.65914\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:             time_total_s 77.73749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:                timestamp 1692242067\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               tmae_coord 0.67129\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:               tmae_force 0.77498\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              tmape_coord 3.99426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              tmape_force 2.87813\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              trmse_coord 1.09387\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:              trmse_force 1.19518\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb:  View run FSR_Trainable_c7777b46 at: https://wandb.ai/seokjin/FSR-prediction/runs/c7777b46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=264826)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121302-c7777b46/logs\n",
      "2023-08-17 12:14:42,094\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.172 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:14:42,097\tWARNING util.py:315 -- The `process_trial_result` operation took 2.177 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:14:42,098\tWARNING util.py:315 -- Processing trial results took 2.178 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:14:42,100\tWARNING util.py:315 -- The `process_trial_result` operation took 2.180 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8690cda0_26_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-14-08/wandb/run-20230817_121445-8690cda0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Syncing run FSR_Trainable_8690cda0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8690cda0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                mae_coord 0.57163\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                mae_force 190.92707\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               mape_coord 0.12749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               mape_force 591139478.9173\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                   metric 2.11907\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               rmse_coord 0.94733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               rmse_force 338.37718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:       time_since_restore 76.54287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:         time_this_iter_s 1.03145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:             time_total_s 76.54287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:                timestamp 1692242094\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               tmae_coord 0.89796\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:               tmae_force 0.48362\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              tmape_coord 6.10802\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              tmape_force 2.18819\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              trmse_coord 1.35231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:              trmse_force 0.76676\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb:  View run FSR_Trainable_b32403dc at: https://wandb.ai/seokjin/FSR-prediction/runs/b32403dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265107)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121330-b32403dc/logs\n",
      "2023-08-17 12:15:09,978\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.235 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:15:09,982\tWARNING util.py:315 -- The `process_trial_result` operation took 2.240 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:15:09,984\tWARNING util.py:315 -- Processing trial results took 2.242 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:15:09,986\tWARNING util.py:315 -- The `process_trial_result` operation took 2.244 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_10ef409d_27_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-14-38/wandb/run-20230817_121513-10ef409d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Syncing run FSR_Trainable_10ef409d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/10ef409d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                mae_coord 0.52326\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                mae_force 199.57372\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               mape_coord 0.12354\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               mape_force 497553528.79876\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                   metric 2.16538\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               rmse_coord 0.84858\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               rmse_force 350.25205\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:       time_since_restore 76.13984\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:         time_this_iter_s 0.65828\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:             time_total_s 76.13984\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:                timestamp 1692242122\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               tmae_coord 0.85151\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:               tmae_force 0.55944\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              tmape_coord 555306432118731.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              tmape_force 2.89002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              trmse_coord 1.25559\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:              trmse_force 0.90979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb:  View run FSR_Trainable_7c048b8f at: https://wandb.ai/seokjin/FSR-prediction/runs/7c048b8f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265607)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121401-7c048b8f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                mae_coord 0.5414\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                mae_force 207.18643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               mape_coord 0.12697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               mape_force 509301376.32437\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                   metric 2.23421\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               rmse_coord 0.87653\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               rmse_force 358.0187\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:       time_since_restore 74.12872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:         time_this_iter_s 0.68385\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:             time_total_s 74.12872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:                timestamp 1692242131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               tmae_coord 0.87879\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:               tmae_force 0.58696\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              tmape_coord 597087301605439.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              tmape_force 3.09283\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              trmse_coord 1.28655\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:              trmse_force 0.94766\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb:  View run FSR_Trainable_fd359cb8 at: https://wandb.ai/seokjin/FSR-prediction/runs/fd359cb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=265842)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121415-fd359cb8/logs\n",
      "2023-08-17 12:15:37,234\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.161 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:15:37,237\tWARNING util.py:315 -- The `process_trial_result` operation took 2.165 s, which may be a performance bottleneck.\n",
      "2023-08-17 12:15:37,240\tWARNING util.py:315 -- Processing trial results took 2.169 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-17 12:15:37,242\tWARNING util.py:315 -- The `process_trial_result` operation took 2.170 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_619004dc_28_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-06/wandb/run-20230817_121540-619004dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Syncing run FSR_Trainable_619004dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/619004dc\n",
      "2023-08-17 12:15:47,579\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_63cd847d\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=266822, ip=172.26.215.93, actor_id=bb5346f113925135bb82ad5f01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fc5f3a538b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_63cd847d_29_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-34/wandb/run-20230817_121553-63cd847d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Syncing run FSR_Trainable_63cd847d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/63cd847d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb:  View run FSR_Trainable_63cd847d at: https://wandb.ai/seokjin/FSR-prediction/runs/63cd847d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266917)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121553-63cd847d/logs\n",
      "2023-08-17 12:16:03,597\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_971919c0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=267061, ip=172.26.215.93, actor_id=b48e01d9c51d3bcb37a3a90301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f3eef617850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_971919c0_30_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-47/wandb/run-20230817_121610-971919c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Syncing run FSR_Trainable_971919c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/971919c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb:  View run FSR_Trainable_971919c0 at: https://wandb.ai/seokjin/FSR-prediction/runs/971919c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267166)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121610-971919c0/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                mae_coord 0.56296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                mae_force 218.52816\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               mape_coord 0.1291\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               mape_force 540178060.73467\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                   metric 2.34167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               rmse_coord 0.90503\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               rmse_force 378.92287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:       time_since_restore 80.32465\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:         time_this_iter_s 0.86985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:             time_total_s 80.32465\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:                timestamp 1692242173\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               tmae_coord 0.91686\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:               tmae_force 0.61015\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              tmape_coord 685612704370107.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              tmape_force 3.2393\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              trmse_coord 1.34387\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb:              trmse_force 0.9978\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: \n",
      "2023-08-17 12:16:19,944\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_d853c660\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=267307, ip=172.26.215.93, actor_id=a4135de148400f5d87adadd401000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fa1a03c7850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266125)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d853c660_31_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-03/wandb/run-20230817_121625-d853c660\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Syncing run FSR_Trainable_d853c660\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d853c660\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:16:32,340\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_60e69b40\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=267558, ip=172.26.215.93, actor_id=349ed1a18974f8dc35b3a06401000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f9876bdb850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb:  View run FSR_Trainable_d853c660 at: https://wandb.ai/seokjin/FSR-prediction/runs/d853c660\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267421)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121625-d853c660/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_60e69b40_32_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-19/wandb/run-20230817_121638-60e69b40\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Syncing run FSR_Trainable_60e69b40\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/60e69b40\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                mae_coord 0.554\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                mae_force 206.92411\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               mape_coord 0.1282\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               mape_force 521178673.57284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                   metric 2.26374\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               rmse_coord 0.89313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               rmse_force 363.68122\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:       time_since_restore 75.67545\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:         time_this_iter_s 0.70854\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:             time_total_s 75.67545\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:                timestamp 1692242198\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               tmae_coord 0.90097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:               tmae_force 0.57501\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              tmape_coord 639135934817686.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              tmape_force 3.0756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              trmse_coord 1.31379\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:              trmse_force 0.94995\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb:  View run FSR_Trainable_10ef409d at: https://wandb.ai/seokjin/FSR-prediction/runs/10ef409d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266404)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121513-10ef409d/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:16:43,787\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a729e8d5\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=267938, ip=172.26.215.93, actor_id=350b514c51848af889dc193f01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f1a901cf910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121638-60e69b40/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=267781)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a729e8d5_33_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-31/wandb/run-20230817_121648-a729e8d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Syncing run FSR_Trainable_a729e8d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a729e8d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:16:53,414\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_11c78141\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=268193, ip=172.26.215.93, actor_id=6417b78c693abfd26567fb1501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f58c1fcf910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb:  View run FSR_Trainable_a729e8d5 at: https://wandb.ai/seokjin/FSR-prediction/runs/a729e8d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268060)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121648-a729e8d5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_11c78141_34_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-43/wandb/run-20230817_121658-11c78141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Syncing run FSR_Trainable_11c78141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/11c78141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:17:03,119\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_9d1f0ebb\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=268428, ip=172.26.215.93, actor_id=b47a63949e0509af300287cc01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fef478bf7f0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb:  View run FSR_Trainable_11c78141 at: https://wandb.ai/seokjin/FSR-prediction/runs/11c78141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268290)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121658-11c78141/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                mae_coord 0.57083\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                mae_force 230.50244\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               mape_coord 0.12977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               mape_force 562384143.47263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                   metric 2.38562\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               rmse_coord 0.91695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               rmse_force 402.26999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:       time_since_restore 68.10907\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:         time_this_iter_s 0.55651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:             time_total_s 68.10907\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:                timestamp 1692242220\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               tmae_coord 0.92753\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:               tmae_force 0.62423\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              tmape_coord 707805861575049.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              tmape_force 3.26813\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              trmse_coord 1.35628\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:              trmse_force 1.02933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9d1f0ebb_35_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-53/wandb/run-20230817_121707-9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Syncing run FSR_Trainable_9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=266682)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:17:12,419\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_64a7a150\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=268674, ip=172.26.215.93, actor_id=d54d4af33692ee2a00d60d3301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f3f4495f8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb:  View run FSR_Trainable_9d1f0ebb at: https://wandb.ai/seokjin/FSR-prediction/runs/9d1f0ebb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268535)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121707-9d1f0ebb/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_64a7a150_36_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-02/wandb/run-20230817_121719-64a7a150\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Syncing run FSR_Trainable_64a7a150\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/64a7a150\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:17:21,158\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_351613df\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=268770, ip=172.26.215.93, actor_id=dc657d2a7023228d8f01181301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fe94729b7f0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb:  View run FSR_Trainable_64a7a150 at: https://wandb.ai/seokjin/FSR-prediction/runs/64a7a150\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268768)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121719-64a7a150/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_351613df_37_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-11/wandb/run-20230817_121726-351613df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Syncing run FSR_Trainable_351613df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/351613df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:17:32,685\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_7ecfe12d\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=269090, ip=172.26.215.93, actor_id=a3f77822510730df313d3e7701000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f73487ab940>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb:  View run FSR_Trainable_351613df at: https://wandb.ai/seokjin/FSR-prediction/runs/351613df\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=268958)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121726-351613df/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7ecfe12d_38_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-20/wandb/run-20230817_121737-7ecfe12d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Syncing run FSR_Trainable_7ecfe12d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7ecfe12d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:17:39,914\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_2f1488dc\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=269187, ip=172.26.215.93, actor_id=0b4b1dc1cec0b2ee9b55500601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fdb1c4ef850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2f1488dc_39_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-31/wandb/run-20230817_121744-2f1488dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Syncing run FSR_Trainable_2f1488dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2f1488dc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb:  View run FSR_Trainable_7ecfe12d at: https://wandb.ai/seokjin/FSR-prediction/runs/7ecfe12d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269186)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121737-7ecfe12d/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:17:49,791\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_2a10d033\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=269511, ip=172.26.215.93, actor_id=f298844f46be41a8b2a39ef301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f826f53f8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269379)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "2023-08-17 12:17:58,816\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_43872776\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=269614, ip=172.26.215.93, actor_id=83401cefc4886191f9482a2001000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f0b8e703880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2a10d033_40_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-39/wandb/run-20230817_121756-2a10d033\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Syncing run FSR_Trainable_2a10d033\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2a10d033\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb:  View run FSR_Trainable_2a10d033 at: https://wandb.ai/seokjin/FSR-prediction/runs/2a10d033\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269613)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121756-2a10d033/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121756-2a10d033/logs\n",
      "2023-08-17 12:18:07,817\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_531ddeb1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=269936, ip=172.26.215.93, actor_id=74b5a82746c57293c3087a2e01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f4171e7b880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121803-43872776/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=269786)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_531ddeb1_42_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-58/wandb/run-20230817_121812-531ddeb1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Syncing run FSR_Trainable_531ddeb1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/531ddeb1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:18:15,127\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_98575263\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=270033, ip=172.26.215.93, actor_id=48bdee0d7ed686dd30738e2001000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f803ed57910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb:  View run FSR_Trainable_531ddeb1 at: https://wandb.ai/seokjin/FSR-prediction/runs/531ddeb1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270032)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121812-531ddeb1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_98575263_43_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-07/wandb/run-20230817_121820-98575263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Syncing run FSR_Trainable_98575263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/98575263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:18:25,563\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_52703439\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=270361, ip=172.26.215.93, actor_id=f27d0d337948d1c032f1781001000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fe4fd393910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb:  View run FSR_Trainable_98575263 at: https://wandb.ai/seokjin/FSR-prediction/runs/98575263\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270222)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121820-98575263/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_52703439_44_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-14/wandb/run-20230817_121831-52703439\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Syncing run FSR_Trainable_52703439\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/52703439\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:18:34,137\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_7bb60977\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=270458, ip=172.26.215.93, actor_id=6735479428908cb510e7d34801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f4bb8deb880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb:  View run FSR_Trainable_52703439 at: https://wandb.ai/seokjin/FSR-prediction/runs/52703439\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270456)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121831-52703439/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7bb60977_45_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-24/wandb/run-20230817_121840-7bb60977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Syncing run FSR_Trainable_7bb60977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7bb60977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:18:45,526\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_d0631592\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=270784, ip=172.26.215.93, actor_id=ef844c969b43d63d6138c5d101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f97b1b93880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb:  View run FSR_Trainable_7bb60977 at: https://wandb.ai/seokjin/FSR-prediction/runs/7bb60977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270643)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121840-7bb60977/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d0631592_46_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-33/wandb/run-20230817_121851-d0631592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Syncing run FSR_Trainable_d0631592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d0631592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:18:53,783\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_2c66a9b4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=270883, ip=172.26.215.93, actor_id=b2d48e716fccfc9b73ab40bb01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f27e8bbb8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2c66a9b4_47_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-44/wandb/run-20230817_121858-2c66a9b4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Syncing run FSR_Trainable_2c66a9b4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2c66a9b4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb:  View run FSR_Trainable_d0631592 at: https://wandb.ai/seokjin/FSR-prediction/runs/d0631592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=270882)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121851-d0631592/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:19:02,259\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a618a14f\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=271209, ip=172.26.215.93, actor_id=ef4af92d8ff4171d9125d69501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7ffa10eeb8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271075)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a618a14f_48_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-53/wandb/run-20230817_121907-a618a14f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Syncing run FSR_Trainable_a618a14f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a618a14f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:19:09,517\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_1c1b9820\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=271308, ip=172.26.215.93, actor_id=5859747602b11ccb2463f13b01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fbc95df38e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb:  View run FSR_Trainable_a618a14f at: https://wandb.ai/seokjin/FSR-prediction/runs/a618a14f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271307)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121907-a618a14f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1c1b9820_49_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-01/wandb/run-20230817_121913-1c1b9820\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Syncing run FSR_Trainable_1c1b9820\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1c1b9820\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:19:17,876\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_38c148a5\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=271627, ip=172.26.215.93, actor_id=2974aba78817ee70d7798f0801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f532aca3820>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb:  View run FSR_Trainable_1c1b9820 at: https://wandb.ai/seokjin/FSR-prediction/runs/1c1b9820\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271491)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121913-1c1b9820/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_38c148a5_50_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-08/wandb/run-20230817_121922-38c148a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Syncing run FSR_Trainable_38c148a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/38c148a5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:19:24,425\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_417f094f\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=271720, ip=172.26.215.93, actor_id=76fe6a9125bd3152c260810901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f1c848af8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121922-38c148a5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121922-38c148a5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271719)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121922-38c148a5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_417f094f_51_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-17/wandb/run-20230817_121928-417f094f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Syncing run FSR_Trainable_417f094f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/417f094f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:19:32,891\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_30eac9ce\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272048, ip=172.26.215.93, actor_id=f907caec8f063247f273918a01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f940843b8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb:  View run FSR_Trainable_417f094f at: https://wandb.ai/seokjin/FSR-prediction/runs/417f094f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=271907)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121928-417f094f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_30eac9ce_52_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-23/wandb/run-20230817_121937-30eac9ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Syncing run FSR_Trainable_30eac9ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/30eac9ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:19:40,018\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_8ac82c65\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272144, ip=172.26.215.93, actor_id=5cd855b6d731ddc46ab852eb01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f85e677f8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb:  View run FSR_Trainable_30eac9ce at: https://wandb.ai/seokjin/FSR-prediction/runs/30eac9ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272143)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121937-30eac9ce/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8ac82c65_53_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-31/wandb/run-20230817_121945-8ac82c65\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Syncing run FSR_Trainable_8ac82c65\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8ac82c65\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:19:50,590\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_46e653c7\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272465, ip=172.26.215.93, actor_id=efc009364ed3312eebbad56e01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f05800438e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb:  View run FSR_Trainable_8ac82c65 at: https://wandb.ai/seokjin/FSR-prediction/runs/8ac82c65\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272328)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121945-8ac82c65/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_46e653c7_54_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-39/wandb/run-20230817_121955-46e653c7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Syncing run FSR_Trainable_46e653c7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/46e653c7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:19:57,480\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a1730c8a\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272564, ip=172.26.215.93, actor_id=66d167a06b0e60467f9c3cd901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f889843b8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb:  View run FSR_Trainable_46e653c7 at: https://wandb.ai/seokjin/FSR-prediction/runs/46e653c7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272563)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_121955-46e653c7/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1730c8a_55_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-49/wandb/run-20230817_122001-a1730c8a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Syncing run FSR_Trainable_a1730c8a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a1730c8a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:20:05,832\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_6205df9b\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272879, ip=172.26.215.93, actor_id=96fef8a5272a91d9655a84b901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fc0009b38e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb:  View run FSR_Trainable_a1730c8a at: https://wandb.ai/seokjin/FSR-prediction/runs/a1730c8a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272747)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122001-a1730c8a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6205df9b_56_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-56/wandb/run-20230817_122010-6205df9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Syncing run FSR_Trainable_6205df9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6205df9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:20:12,814\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_fc0be644\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=272975, ip=172.26.215.93, actor_id=5960f8969c767796191248eb01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f8dc39af7f0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122010-6205df9b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122010-6205df9b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=272974)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122010-6205df9b/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fc0be644_57_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-05/wandb/run-20230817_122017-fc0be644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Syncing run FSR_Trainable_fc0be644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fc0be644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:20:21,311\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_f7f52756\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=273299, ip=172.26.215.93, actor_id=5d6f77cf777e1192205dbb4101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f2976b538b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb:  View run FSR_Trainable_fc0be644 at: https://wandb.ai/seokjin/FSR-prediction/runs/fc0be644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273161)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122017-fc0be644/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_f7f52756_58_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-12/wandb/run-20230817_122027-f7f52756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Syncing run FSR_Trainable_f7f52756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f7f52756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:20:29,201\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_478dea9a\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=273397, ip=172.26.215.93, actor_id=37cd2de3a5ec57791b586b9101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f5d1a4db8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb:  View run FSR_Trainable_f7f52756 at: https://wandb.ai/seokjin/FSR-prediction/runs/f7f52756\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273396)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122027-f7f52756/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_478dea9a_59_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-20/wandb/run-20230817_122033-478dea9a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Syncing run FSR_Trainable_478dea9a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/478dea9a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:20:39,623\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_6baa37a1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=273721, ip=172.26.215.93, actor_id=beb3b603f2cbf3a10ef81ac601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fbc4373b820>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb:  View run FSR_Trainable_478dea9a at: https://wandb.ai/seokjin/FSR-prediction/runs/478dea9a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273581)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122033-478dea9a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6baa37a1_60_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-28/wandb/run-20230817_122044-6baa37a1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Syncing run FSR_Trainable_6baa37a1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6baa37a1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:20:47,603\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_fee9192e\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=273818, ip=172.26.215.93, actor_id=cc14cc3b3347545a8cfe2d3801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f553fdbf8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb:  View run FSR_Trainable_6baa37a1 at: https://wandb.ai/seokjin/FSR-prediction/runs/6baa37a1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=273817)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122044-6baa37a1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fee9192e_61_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-38/wandb/run-20230817_122052-fee9192e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Syncing run FSR_Trainable_fee9192e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fee9192e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:20:57,321\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_08dd982a\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=274144, ip=172.26.215.93, actor_id=6d6f38040151e3e2ff98ce7301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f344538f850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb:  View run FSR_Trainable_fee9192e at: https://wandb.ai/seokjin/FSR-prediction/runs/fee9192e\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274001)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122052-fee9192e/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_08dd982a_62_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-46/wandb/run-20230817_122102-08dd982a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Syncing run FSR_Trainable_08dd982a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/08dd982a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:21:04,730\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_3834e2c6\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=274237, ip=172.26.215.93, actor_id=af951186a0a2dc1aaac62ae401000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7eff942ff880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb:  View run FSR_Trainable_08dd982a at: https://wandb.ai/seokjin/FSR-prediction/runs/08dd982a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274235)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122102-08dd982a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_3834e2c6_63_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-56/wandb/run-20230817_122109-3834e2c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Syncing run FSR_Trainable_3834e2c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3834e2c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:21:14,335\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_fb5da508\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=274559, ip=172.26.215.93, actor_id=ecbd0ea82bb01093745bdc1901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7ff7e3b978b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb:  View run FSR_Trainable_3834e2c6 at: https://wandb.ai/seokjin/FSR-prediction/runs/3834e2c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274419)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122109-3834e2c6/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fb5da508_64_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-03/wandb/run-20230817_122119-fb5da508\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Syncing run FSR_Trainable_fb5da508\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fb5da508\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:21:21,895\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_1fb63a46\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=274655, ip=172.26.215.93, actor_id=651bc5f76c05842d1d17bd1101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fdd5a3ab910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb:  View run FSR_Trainable_fb5da508 at: https://wandb.ai/seokjin/FSR-prediction/runs/fb5da508\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274654)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122119-fb5da508/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1fb63a46_65_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-13/wandb/run-20230817_122126-1fb63a46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Syncing run FSR_Trainable_1fb63a46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1fb63a46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:21:31,388\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_bfffe96c\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=274979, ip=172.26.215.93, actor_id=dbf13aecccfdc08604255b8701000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fb366453910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb:  View run FSR_Trainable_1fb63a46 at: https://wandb.ai/seokjin/FSR-prediction/runs/1fb63a46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=274839)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122126-1fb63a46/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_bfffe96c_66_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-21/wandb/run-20230817_122136-bfffe96c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Syncing run FSR_Trainable_bfffe96c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bfffe96c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:21:39,422\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_83963611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=275078, ip=172.26.215.93, actor_id=a8c6bd9c7d52ea3cf0fca64f01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f521074f850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb:  View run FSR_Trainable_bfffe96c at: https://wandb.ai/seokjin/FSR-prediction/runs/bfffe96c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275077)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122136-bfffe96c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_83963611_67_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-30/wandb/run-20230817_122144-83963611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Syncing run FSR_Trainable_83963611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/83963611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:21:48,134\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_95e10e0c\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=275400, ip=172.26.215.93, actor_id=d7950acef439af273139b4d701000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7feaa03678b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb:  View run FSR_Trainable_83963611 at: https://wandb.ai/seokjin/FSR-prediction/runs/83963611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275260)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122144-83963611/logs\n",
      "2023-08-17 12:21:54,529\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_225e0ef4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=275494, ip=172.26.215.93, actor_id=8731f4a0b4b01209a0303ca401000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f90b8ca78b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_95e10e0c_68_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-38/wandb/run-20230817_122155-95e10e0c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Syncing run FSR_Trainable_95e10e0c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/95e10e0c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb:  View run FSR_Trainable_95e10e0c at: https://wandb.ai/seokjin/FSR-prediction/runs/95e10e0c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275493)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122155-95e10e0c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:22:04,789\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_9230f8bf\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=275814, ip=172.26.215.93, actor_id=ab09ae07a58dd482128b7ee101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f0a5ff138e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122159-225e0ef4/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122159-225e0ef4/logs\n",
      "2023-08-17 12:22:11,947\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_5df754b0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=275911, ip=172.26.215.93, actor_id=48db66517dc7fbb2650e7e6601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f9306adf820>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275655)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9230f8bf_70_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-53/wandb/run-20230817_122212-9230f8bf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Syncing run FSR_Trainable_9230f8bf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9230f8bf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb:  View run FSR_Trainable_9230f8bf at: https://wandb.ai/seokjin/FSR-prediction/runs/9230f8bf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=275910)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122212-9230f8bf/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:22:20,926\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a10d27d1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=276229, ip=172.26.215.93, actor_id=853aabe995a4609e4ce879b901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f1ecd2b7910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122216-5df754b0/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122216-5df754b0/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276074)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a10d27d1_72_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-11/wandb/run-20230817_122225-a10d27d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Syncing run FSR_Trainable_a10d27d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a10d27d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:22:28,009\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_5837f84a\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=276329, ip=172.26.215.93, actor_id=4ea4eab079588e2a1580aa6d01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f4c233a3910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb:  View run FSR_Trainable_a10d27d1 at: https://wandb.ai/seokjin/FSR-prediction/runs/a10d27d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276328)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122225-a10d27d1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5837f84a_73_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-20/wandb/run-20230817_122232-5837f84a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Syncing run FSR_Trainable_5837f84a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/5837f84a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:22:36,943\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_7cd96ac9\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=276651, ip=172.26.215.93, actor_id=619168f13a36882856e5c89301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f5af704b880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb:  View run FSR_Trainable_5837f84a at: https://wandb.ai/seokjin/FSR-prediction/runs/5837f84a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276513)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122232-5837f84a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7cd96ac9_74_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-27/wandb/run-20230817_122243-7cd96ac9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Syncing run FSR_Trainable_7cd96ac9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7cd96ac9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:22:45,958\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_ce8f2ddc\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=276747, ip=172.26.215.93, actor_id=65047f55c7c323eb38ef6fd801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fcdca98f8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb:  View run FSR_Trainable_7cd96ac9 at: https://wandb.ai/seokjin/FSR-prediction/runs/7cd96ac9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276746)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122243-7cd96ac9/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce8f2ddc_75_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-36/wandb/run-20230817_122250-ce8f2ddc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Syncing run FSR_Trainable_ce8f2ddc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ce8f2ddc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:22:55,390\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_ce3191bc\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277075, ip=172.26.215.93, actor_id=212b2297bcd6b54db86039b901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f603eb73850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb:  View run FSR_Trainable_ce8f2ddc at: https://wandb.ai/seokjin/FSR-prediction/runs/ce8f2ddc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=276934)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122250-ce8f2ddc/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce3191bc_76_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-45/wandb/run-20230817_122300-ce3191bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Syncing run FSR_Trainable_ce3191bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ce3191bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:02,478\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_16c1edc2\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277171, ip=172.26.215.93, actor_id=e216e7fd11c612abf671e9e701000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f21e0393850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb:  View run FSR_Trainable_ce3191bc at: https://wandb.ai/seokjin/FSR-prediction/runs/ce3191bc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277170)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122300-ce3191bc/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16c1edc2_77_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-54/wandb/run-20230817_122307-16c1edc2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Syncing run FSR_Trainable_16c1edc2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/16c1edc2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:10,844\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_04c92bb8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277494, ip=172.26.215.93, actor_id=543c020a6475b788a83cf93f01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7feeca3178b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122307-16c1edc2/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122307-16c1edc2/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277355)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122307-16c1edc2/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_04c92bb8_78_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-01/wandb/run-20230817_122316-04c92bb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Syncing run FSR_Trainable_04c92bb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/04c92bb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:19,206\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_fe1ae516\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277586, ip=172.26.215.93, actor_id=880afa609d5e0667e196e1c301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f057e35f8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb:  View run FSR_Trainable_04c92bb8 at: https://wandb.ai/seokjin/FSR-prediction/runs/04c92bb8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277585)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122316-04c92bb8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fe1ae516_79_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-10/wandb/run-20230817_122327-fe1ae516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Syncing run FSR_Trainable_fe1ae516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fe1ae516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:28,780\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_876067fd\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277912, ip=172.26.215.93, actor_id=4b5168398730fb7966c89f5901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f1131ad7820>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb:  View run FSR_Trainable_fe1ae516 at: https://wandb.ai/seokjin/FSR-prediction/runs/fe1ae516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277773)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122327-fe1ae516/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_876067fd_80_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-18/wandb/run-20230817_122334-876067fd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Syncing run FSR_Trainable_876067fd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/876067fd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:36,538\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_cd6ea670\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=277993, ip=172.26.215.93, actor_id=796bed114ed2e11d5cd858c301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fc07e86b8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122334-876067fd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122334-876067fd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=277992)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122334-876067fd/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_cd6ea670_81_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-27/wandb/run-20230817_122341-cd6ea670\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Syncing run FSR_Trainable_cd6ea670\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/cd6ea670\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:23:46,059\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a67f43be\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=278334, ip=172.26.215.93, actor_id=52dbd2927cf9f2689adb818801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f0a0063f7c0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb:  View run FSR_Trainable_cd6ea670 at: https://wandb.ai/seokjin/FSR-prediction/runs/cd6ea670\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278196)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122341-cd6ea670/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a67f43be_82_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-35/wandb/run-20230817_122351-a67f43be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Syncing run FSR_Trainable_a67f43be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a67f43be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:23:53,648\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_2acb15cf\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=278430, ip=172.26.215.93, actor_id=3c0bf1e7974a39f0772ec21201000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fbc51ff7910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: - 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: \\ 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb:  View run FSR_Trainable_a67f43be at: https://wandb.ai/seokjin/FSR-prediction/runs/a67f43be\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278429)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122351-a67f43be/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2acb15cf_83_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-45/wandb/run-20230817_122358-2acb15cf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Syncing run FSR_Trainable_2acb15cf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2acb15cf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:24:03,064\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_32a8a03b\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=278750, ip=172.26.215.93, actor_id=8688e911631d858e417530c501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f3133fc7880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb:  View run FSR_Trainable_2acb15cf at: https://wandb.ai/seokjin/FSR-prediction/runs/2acb15cf\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278618)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122358-2acb15cf/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_32a8a03b_84_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-52/wandb/run-20230817_122409-32a8a03b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Syncing run FSR_Trainable_32a8a03b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/32a8a03b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:24:11,957\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_e26788fe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=278850, ip=172.26.215.93, actor_id=f0773be8bc5a29d01ad8114a01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fa73774b8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)02 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=278849)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e26788fe_85_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-02/wandb/run-20230817_122416-e26788fe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Syncing run FSR_Trainable_e26788fe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e26788fe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:24:21,877\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_16d165c1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=279174, ip=172.26.215.93, actor_id=30ba2b896407e84e6f83c8f101000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fc41a1bf880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb:  View run FSR_Trainable_e26788fe at: https://wandb.ai/seokjin/FSR-prediction/runs/e26788fe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279036)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122416-e26788fe/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16d165c1_86_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-11/wandb/run-20230817_122426-16d165c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Syncing run FSR_Trainable_16d165c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/16d165c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:24:29,065\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_ae231229\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=279272, ip=172.26.215.93, actor_id=a934b06c00839b05bbf8f6fa01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fa87b793880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)04 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb:  View run FSR_Trainable_16d165c1 at: https://wandb.ai/seokjin/FSR-prediction/runs/16d165c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279271)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122426-16d165c1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ae231229_87_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-20/wandb/run-20230817_122433-ae231229\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Syncing run FSR_Trainable_ae231229\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ae231229\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:24:37,479\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_9a435255\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=279594, ip=172.26.215.93, actor_id=f90a1cd2cc1b960fa27273f901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f0c6ef038b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122433-ae231229/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122433-ae231229/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279455)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122433-ae231229/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9a435255_88_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-28/wandb/run-20230817_122442-9a435255\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Syncing run FSR_Trainable_9a435255\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9a435255\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:24:44,211\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_1d6566d5\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=279689, ip=172.26.215.93, actor_id=d070637fa6a464ee87c09c7501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f069bec38b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: / 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb:  View run FSR_Trainable_9a435255 at: https://wandb.ai/seokjin/FSR-prediction/runs/9a435255\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279685)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122442-9a435255/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1d6566d5_89_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-36/wandb/run-20230817_122448-1d6566d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Syncing run FSR_Trainable_1d6566d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1d6566d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:24:53,330\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_479e6a56\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280006, ip=172.26.215.93, actor_id=47a567a6a648676981baa69501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f396b347910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_479e6a56_90_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-43/wandb/run-20230817_122458-479e6a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Syncing run FSR_Trainable_479e6a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/479e6a56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb:  View run FSR_Trainable_1d6566d5 at: https://wandb.ai/seokjin/FSR-prediction/runs/1d6566d5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=279872)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122448-1d6566d5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:25:01,716\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_a1ef9b8b\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280101, ip=172.26.215.93, actor_id=349300b7bbf22a259b9e714d01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f17f01fb7f0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: \\ 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: | 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280090)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1ef9b8b_91_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-52/wandb/run-20230817_122506-a1ef9b8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Syncing run FSR_Trainable_a1ef9b8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a1ef9b8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb:  View run FSR_Trainable_a1ef9b8b at: https://wandb.ai/seokjin/FSR-prediction/runs/a1ef9b8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280299)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122506-a1ef9b8b/logs\n",
      "2023-08-17 12:25:12,087\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_8f8427c8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280439, ip=172.26.215.93, actor_id=cbf649ea60846170efc54a9601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fb5afb978b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8f8427c8_92_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-00/wandb/run-20230817_122517-8f8427c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Syncing run FSR_Trainable_8f8427c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8f8427c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:25:20,294\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_b4e7377c\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280531, ip=172.26.215.93, actor_id=0858339da21881cc7bb84b4901000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f368276b910>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb:  View run FSR_Trainable_8f8427c8 at: https://wandb.ai/seokjin/FSR-prediction/runs/8f8427c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280530)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122517-8f8427c8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_b4e7377c_93_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-11/wandb/run-20230817_122528-b4e7377c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Syncing run FSR_Trainable_b4e7377c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b4e7377c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:25:30,585\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_676ec781\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280853, ip=172.26.215.93, actor_id=dc40a7910ac9637249de240501000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f5ce840f850>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb:  View run FSR_Trainable_b4e7377c at: https://wandb.ai/seokjin/FSR-prediction/runs/b4e7377c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280719)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122528-b4e7377c/logs\n",
      "2023-08-17 12:25:38,740\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_67d56bc6\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=280953, ip=172.26.215.93, actor_id=07d9ef65b1167f6bbcc3449301000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f123b2ff8b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_676ec781_94_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-19/wandb/run-20230817_122539-676ec781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Syncing run FSR_Trainable_676ec781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/676ec781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb:  View run FSR_Trainable_676ec781 at: https://wandb.ai/seokjin/FSR-prediction/runs/676ec781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=280951)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122539-676ec781/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122539-676ec781/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_67d56bc6_95_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-29/wandb/run-20230817_122544-67d56bc6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Syncing run FSR_Trainable_67d56bc6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/67d56bc6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:25:49,932\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_dbe40062\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=281277, ip=172.26.215.93, actor_id=8ad8d0a3f62211fb3068454d01000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7ff09d32b8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb:  View run FSR_Trainable_67d56bc6 at: https://wandb.ai/seokjin/FSR-prediction/runs/67d56bc6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281115)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122544-67d56bc6/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "2023-08-17 12:26:01,178\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_75837ea5\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=281377, ip=172.26.215.93, actor_id=8623a51952dab1bb57d88a5201000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7f6b451e38b0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_dbe40062_96_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-37/wandb/run-20230817_122557-dbe40062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Syncing run FSR_Trainable_dbe40062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/dbe40062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: \\ 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: | 0.006 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb:  View run FSR_Trainable_dbe40062 at: https://wandb.ai/seokjin/FSR-prediction/runs/dbe40062\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281376)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122557-dbe40062/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_75837ea5_97_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-49/wandb/run-20230817_122606-75837ea5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Syncing run FSR_Trainable_75837ea5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/75837ea5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-08-17 12:26:12,979\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_184ab78c\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=281703, ip=172.26.215.93, actor_id=d92cfb6d0f4325c8fc4044f201000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fb963aef880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122606-75837ea5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122606-75837ea5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281553)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122606-75837ea5/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_184ab78c_98_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-00/wandb/run-20230817_122619-184ab78c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Syncing run FSR_Trainable_184ab78c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/184ab78c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "2023-08-17 12:26:22,418\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_1857e24d\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=281809, ip=172.26.215.93, actor_id=fee42f8768e17432cf994b7801000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7ff8ca22b8e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb:  View run FSR_Trainable_184ab78c at: https://wandb.ai/seokjin/FSR-prediction/runs/184ab78c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281808)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122619-184ab78c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1857e24d_99_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-12/wandb/run-20230817_122628-1857e24d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Syncing run FSR_Trainable_1857e24d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1857e24d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: \\ 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: | 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb:  View run FSR_Trainable_1857e24d at: https://wandb.ai/seokjin/FSR-prediction/runs/1857e24d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=281994)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122628-1857e24d/logs\n",
      "2023-08-17 12:26:34,787\tERROR tune_controller.py:873 -- Trial task failed for trial FSR_Trainable_17d3bd89\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ResourceTrainable.train()\u001b[39m (pid=282136, ip=172.26.215.93, actor_id=fe5344a3b6cb4a08930a914601000000, repr=<ray.tune.trainable.util.FSR_Trainable object at 0x7fbc45e8f880>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/home/seokj/workspace/FSR-prediction/fsr_trainable.py\", line 72, in step\n",
      "    tmae.append(sklearn.metrics.mean_absolute_error(y, pred, multioutput='raw_values'))\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 196, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_17d3bd89_100_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_Simple_2023-08-17_12-26-21/wandb/run-20230817_122640-17d3bd89\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Syncing run FSR_Trainable_17d3bd89\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/17d3bd89\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: \\ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb:  View run FSR_Trainable_17d3bd89 at: https://wandb.ai/seokjin/FSR-prediction/runs/17d3bd89\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=282237)\u001b[0m wandb: Find logs at: ./wandb/run-20230817_122640-17d3bd89/logs\n",
      "2023-08-17 12:26:45,318\tERROR tune.py:1107 -- Trials did not complete: [FSR_Trainable_43fcd44e, FSR_Trainable_4d5dc9c2, FSR_Trainable_ca6ab145, FSR_Trainable_5cc7b50b, FSR_Trainable_e0139bc1, FSR_Trainable_edbf5674, FSR_Trainable_63cd847d, FSR_Trainable_971919c0, FSR_Trainable_d853c660, FSR_Trainable_60e69b40, FSR_Trainable_a729e8d5, FSR_Trainable_11c78141, FSR_Trainable_9d1f0ebb, FSR_Trainable_64a7a150, FSR_Trainable_351613df, FSR_Trainable_7ecfe12d, FSR_Trainable_2f1488dc, FSR_Trainable_2a10d033, FSR_Trainable_43872776, FSR_Trainable_531ddeb1, FSR_Trainable_98575263, FSR_Trainable_52703439, FSR_Trainable_7bb60977, FSR_Trainable_d0631592, FSR_Trainable_2c66a9b4, FSR_Trainable_a618a14f, FSR_Trainable_1c1b9820, FSR_Trainable_38c148a5, FSR_Trainable_417f094f, FSR_Trainable_30eac9ce, FSR_Trainable_8ac82c65, FSR_Trainable_46e653c7, FSR_Trainable_a1730c8a, FSR_Trainable_6205df9b, FSR_Trainable_fc0be644, FSR_Trainable_f7f52756, FSR_Trainable_478dea9a, FSR_Trainable_6baa37a1, FSR_Trainable_fee9192e, FSR_Trainable_08dd982a, FSR_Trainable_3834e2c6, FSR_Trainable_fb5da508, FSR_Trainable_1fb63a46, FSR_Trainable_bfffe96c, FSR_Trainable_83963611, FSR_Trainable_95e10e0c, FSR_Trainable_225e0ef4, FSR_Trainable_9230f8bf, FSR_Trainable_5df754b0, FSR_Trainable_a10d27d1, FSR_Trainable_5837f84a, FSR_Trainable_7cd96ac9, FSR_Trainable_ce8f2ddc, FSR_Trainable_ce3191bc, FSR_Trainable_16c1edc2, FSR_Trainable_04c92bb8, FSR_Trainable_fe1ae516, FSR_Trainable_876067fd, FSR_Trainable_cd6ea670, FSR_Trainable_a67f43be, FSR_Trainable_2acb15cf, FSR_Trainable_32a8a03b, FSR_Trainable_e26788fe, FSR_Trainable_16d165c1, FSR_Trainable_ae231229, FSR_Trainable_9a435255, FSR_Trainable_1d6566d5, FSR_Trainable_479e6a56, FSR_Trainable_a1ef9b8b, FSR_Trainable_8f8427c8, FSR_Trainable_b4e7377c, FSR_Trainable_676ec781, FSR_Trainable_67d56bc6, FSR_Trainable_dbe40062, FSR_Trainable_75837ea5, FSR_Trainable_184ab78c, FSR_Trainable_1857e24d, FSR_Trainable_17d3bd89]\n",
      "2023-08-17 12:26:45,321\tINFO tune.py:1111 -- Total run time: 1083.73 seconds (1075.71 seconds for the tuning loop).\n",
      "2023-08-17 12:26:45,445\tWARNING experiment_analysis.py:910 -- Failed to read the results for 78 trials:\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_43fcd44e_3_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-08-55\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_4d5dc9c2_4_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-03\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ca6ab145_6_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-25\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5cc7b50b_8_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleIm_2023-08-17_12-09-53\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e0139bc1_11_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-10-40\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_edbf5674_23_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-13-24\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_63cd847d_29_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-34\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_971919c0_30_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-15-47\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d853c660_31_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-03\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_60e69b40_32_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-19\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a729e8d5_33_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-31\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_11c78141_34_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-43\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9d1f0ebb_35_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-16-53\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_64a7a150_36_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-02\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_351613df_37_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-11\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7ecfe12d_38_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-20\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2f1488dc_39_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-31\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2a10d033_40_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-39\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_43872776_41_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-48\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_531ddeb1_42_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-17-58\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_98575263_43_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-07\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_52703439_44_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-14\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7bb60977_45_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-24\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_d0631592_46_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-33\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2c66a9b4_47_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-44\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a618a14f_48_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-18-53\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1c1b9820_49_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-01\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_38c148a5_50_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-08\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_417f094f_51_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-17\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_30eac9ce_52_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-23\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8ac82c65_53_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-31\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_46e653c7_54_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-39\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1730c8a_55_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-49\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6205df9b_56_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-19-56\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fc0be644_57_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-05\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_f7f52756_58_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-12\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_478dea9a_59_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-20\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_6baa37a1_60_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-28\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fee9192e_61_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-38\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_08dd982a_62_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-46\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_3834e2c6_63_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-20-56\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fb5da508_64_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-03\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1fb63a46_65_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-13\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_bfffe96c_66_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-21\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_83963611_67_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-30\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_95e10e0c_68_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-38\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_225e0ef4_69_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-47\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9230f8bf_70_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-21-53\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5df754b0_71_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-04\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a10d27d1_72_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-11\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_5837f84a_73_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-20\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_7cd96ac9_74_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-27\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce8f2ddc_75_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-36\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ce3191bc_76_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-45\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16c1edc2_77_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-22-54\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_04c92bb8_78_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-01\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_fe1ae516_79_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-10\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_876067fd_80_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-18\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_cd6ea670_81_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-27\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a67f43be_82_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-35\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_2acb15cf_83_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-45\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_32a8a03b_84_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-23-52\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_e26788fe_85_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-02\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_16d165c1_86_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-11\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_ae231229_87_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-20\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_9a435255_88_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-28\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1d6566d5_89_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-36\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_479e6a56_90_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-43\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_a1ef9b8b_91_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-24-52\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_8f8427c8_92_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-00\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_b4e7377c_93_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-11\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_676ec781_94_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-19\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_67d56bc6_95_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-29\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_dbe40062_96_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-37\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_75837ea5_97_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-25-49\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_184ab78c_98_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-00\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_1857e24d_99_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_SimpleI_2023-08-17_12-26-12\n",
      "- /home/seokj/ray_results/FSR_Trainable_2023-08-17_12-08-36/FSR_Trainable_17d3bd89_100_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_time,imputer=sklearn_impute_Simple_2023-08-17_12-26-21\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
