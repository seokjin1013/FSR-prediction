{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasource\n",
    "import torch\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    def _import_class(name:str):\n",
    "        import importlib\n",
    "        index = name.rfind('.')\n",
    "        module_name = name[:index] if index != -1 else '__main__'\n",
    "        class_name = name[index + 1:]\n",
    "        return getattr(importlib.import_module(module_name), class_name)\n",
    "    \n",
    "    model = config['model']\n",
    "    criterion = config['criterion']\n",
    "    optimizer = config['optimizer']\n",
    "    \n",
    "    train_data = session.get_dataset_shard('train_ds')\n",
    "    test_data = session.get_dataset_shard('test_ds')\n",
    "\n",
    "    index_X = 'FSR_for_force'\n",
    "    index_y = 'force'\n",
    "\n",
    "    model = _import_class(model)(input_size=len(data.loc[:, index_X].columns), output_size=len(data.loc[:, index_y].columns), **config['model_args'])\n",
    "    criterion = _import_class(criterion)()\n",
    "    optimizer = _import_class(optimizer)(model.parameters(), **config['optimizer_args'])\n",
    "\n",
    "    while True:\n",
    "        model.train()\n",
    "        for X, y in train_data:\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            mae, mse, mape, num = [], [], [], []\n",
    "            for X, y in test_data:\n",
    "                pred = model(X)\n",
    "                mae.append(sklearn.metrics.mean_absolute_error(y, pred))\n",
    "                mse.append(sklearn.metrics.mean_squared_error(y, pred))\n",
    "                mape.append(sklearn.metrics.mean_absolute_percentage_error(y, pred))\n",
    "                num.append(len(y))\n",
    "            mae = np.average(mae, weights=num)\n",
    "            mse = np.average(mse, weights=num)\n",
    "            mape = np.average(mape, weights=num)\n",
    "            rmse = mse ** 0.5\n",
    "        session.report(\n",
    "            dict(rmse=rmse, mae=mae, mape=mape),\n",
    "            checkpoint=Checkpoint.from_dict(\n",
    "                dict(model=model.state_dict(), optimizer=optimizer.state_dict()),\n",
    "            ),\n",
    "        ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 16:07:41,617\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-07-04 16:07:45,571\tWARNING dataset.py:253 -- \u001b[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\n",
      "\n",
      "Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ray.data\n",
    "import datasource\n",
    "import numpy as np\n",
    "data = datasource.get_data()\n",
    "train_indexes, test_indexes = datasource.get_index_splited_by_time(data)\n",
    "for i, train_index in enumerate(train_indexes):\n",
    "    data.loc[train_index, 'group'] = i\n",
    "train_ds = ray.data.from_items(np.concatenate([data.loc[train_index, ['FSR_for_force', 'force', 'group']].to_numpy() for train_index in train_indexes]))\n",
    "for i, test_index in enumerate(test_indexes):\n",
    "    data.loc[test_index, 'group'] = i\n",
    "test_ds = ray.data.from_items(np.concatenate([data.loc[test_index, ['FSR_for_force', 'force', 'group']].to_numpy() for test_index in test_indexes]))\n",
    "def split_column(batch):\n",
    "    for i in range(13):\n",
    "        batch[str(i)] = batch['item'][..., i]\n",
    "        batch[str(i)] = batch['item'][..., i]\n",
    "    batch.pop('item')\n",
    "    return batch\n",
    "def combine_column(batch):\n",
    "    batch['X'] = np.hstack([np.expand_dims(batch[str(i)], 1) for i in range(6)])\n",
    "    batch['y'] = np.hstack([np.expand_dims(batch[str(i)], 1) for i in range(6, 12)])\n",
    "    batch['group'] = batch[str(12)]\n",
    "    for i in range(13):\n",
    "        batch.pop(str(i))\n",
    "    return batch\n",
    "def group_row(group):\n",
    "    return {'X': [np.vstack(group['X'])], 'y': [np.vstack(group['y'])]}\n",
    "from ray.data.preprocessors import SimpleImputer, StandardScaler, BatchMapper, Chain\n",
    "split_mapper = BatchMapper(split_column, batch_format='numpy')\n",
    "imputer = SimpleImputer(map(str, range(12)))\n",
    "scaler = StandardScaler(map(str, range(12)))\n",
    "combine_mapper = BatchMapper(combine_column, batch_format='numpy')\n",
    "preprocessor = Chain(split_mapper, imputer, scaler, combine_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-04 16:08:13</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:25.31        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.9/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_7b2f6_00000</td><td style=\"text-align: right;\">           1</td><td>/home/seokj/ray_results/TorchTrainer_2023-07-04_16-07-47/TorchTrainer_7b2f6_00000_0_2023-07-04_16-07-47/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_7b2f6_00000</td><td>ERROR   </td><td>172.26.215.93:1063285</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e11c4c01e641af955d95367af84287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) - RandomizeBlockOrder 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fa6fa2a72d41ac81cee027f1d853f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) - Aggregate 2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e790f8a28294e51b080620d4c4a7059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) SortSample 3:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da9a9933f744bf7b8bae4c2cd0b85d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) ShuffleMap 4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc77394d8144250badcf1515a9d1a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) ShuffleReduce 5:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273afd0ac6a64a7596aa88191b61b17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:52,164\tWARNING dataset.py:253 -- \u001b[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode\u001b[0m\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:52,165\tINFO dataset.py:2087 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:52,169\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper] -> AllToAllOperator[RandomizeBlockOrder] -> AllToAllOperator[Aggregate]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:52,169\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:52,169\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e161e7118e40b09b30a056ae98bb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) - RandomizeBlockOrder 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c2aba55a53454db0b6b53db629d199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:57,492\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper] -> AllToAllOperator[RandomizeBlockOrder]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:57,492\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:57,492\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:58,433\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-5, stopped daemon 139818340173376)>.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:59,878\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-4, stopped daemon 139818348566080)>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32136aef2c394098ab39cc4a8bc45478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) - Aggregate 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61286d27014403dab14f8716bde78d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) SortSample 2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e5d3d39a644aba89884517223924aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) ShuffleMap 3:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b786de7ab4ef2b7e802d8148dcb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) ShuffleReduce 4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27a943e7efa464fbc9da99bb2c0fa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:59,888\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[SimpleImputer] -> AllToAllOperator[Aggregate]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:59,888\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:07:59,888\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0250914d3db04fe39cffe0a26d551fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:01,111\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[SimpleImputer]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:01,111\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:01,112\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:02,243\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-8, stopped daemon 139818348566080)>.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:03,877\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-7, stopped daemon 139818340173376)>.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:06,087\tINFO backend_executor.py:137 -- Starting distributed worker processes: ['1063647 (172.26.215.93)', '1063648 (172.26.215.93)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1063647)\u001b[0m 2023-07-04 16:08:07,812\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263665ba011a458e904e460dc6c1e552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) - RandomizeBlockOrder 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e0410f34b345e5a5fe671963ad3887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=1063285) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:08,855\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper->SimpleImputer->StandardScaler->BatchMapper] -> AllToAllOperator[RandomizeBlockOrder]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:08,855\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:08,856\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=1063285)\u001b[0m 2023-07-04 16:08:11,591\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-10, stopped daemon 139818340173376)>.\n",
      "2023-07-04 16:08:13,052\tERROR tune_controller.py:873 -- Trial task failed for trial TorchTrainer_7b2f6_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=1063285, ip=172.26.215.93, actor_id=beea7af000834f3faebfd79c01000000, repr=TorchTrainer)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n",
      "    ray.get(object_ref)\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=1063647, ip=172.26.215.93, actor_id=9807ed4808854fa1f396f3fa01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7f640ec242e0>)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 32, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n",
      "    train_func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1062758/782900269.py\", line 34, in train_loop_per_worker\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>hostname       </th><th>node_ip      </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_7b2f6_00000</td><td>2023-07-04_16-07-52</td><td>DESKTOP-0P789CI</td><td>172.26.215.93</td><td style=\"text-align: right;\">1063285</td><td style=\"text-align: right;\"> 1688454472</td><td>7b2f6_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 16:08:13,076\tERROR tune.py:1107 -- Trials did not complete: [TorchTrainer_7b2f6_00000]\n",
      "2023-07-04 16:08:13,078\tINFO tune.py:1111 -- Total run time: 25.37 seconds (25.30 seconds for the tuning loop).\n",
      "2023-07-04 16:08:13,087\tWARNING experiment_analysis.py:910 -- Failed to read the results for 1 trials:\n",
      "- /home/seokj/ray_results/TorchTrainer_2023-07-04_16-07-47/TorchTrainer_7b2f6_00000_0_2023-07-04_16-07-47\n"
     ]
    },
    {
     "ename": "TrainingFailedError",
     "evalue": "The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"/home/seokj/ray_results/TorchTrainer_2023-07-04_16-07-47\")`.\nTo start a new run that will retry on training failures, set `air.RunConfig(failure_config=air.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=1063285, ip=172.26.215.93, actor_id=beea7af000834f3faebfd79c01000000, repr=TorchTrainer)\n  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayTaskError(TypeError): \u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=1063647, ip=172.26.215.93, actor_id=9807ed4808854fa1f396f3fa01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7f640ec242e0>)\n  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 32, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"/home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n    train_func(*args, **kwargs)\n  File \"/tmp/ipykernel_1062758/782900269.py\", line 34, in train_loop_per_worker\nTypeError: 'NoneType' object is not iterable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTrainingFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 46\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m Chain, SimpleImputer, MaxAbsScaler, MinMaxScaler, PowerTransformer, RobustScaler, StandardScaler\n\u001b[1;32m      7\u001b[0m trainer \u001b[39m=\u001b[39m TorchTrainer(\n\u001b[1;32m      8\u001b[0m     train_loop_per_worker\u001b[39m=\u001b[39mtrain_loop_per_worker, \n\u001b[1;32m      9\u001b[0m     train_loop_config\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     preprocessor\u001b[39m=\u001b[39mpreprocessor,\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLast result: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mmetrics\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.10/site-packages/ray/train/base_trainer.py:616\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m result \u001b[39m=\u001b[39m result_grid[\u001b[39m0\u001b[39m]\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39merror:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Raise trainable errors to the user with a message to restore\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39m# or configure `FailureConfig` in a new run.\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[39mraise\u001b[39;00m TrainingFailedError(\n\u001b[1;32m    617\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([restore_msg, TrainingFailedError\u001b[39m.\u001b[39m_FAILURE_CONFIG_MSG])\n\u001b[1;32m    618\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mresult\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39merror\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTrainingFailedError\u001b[0m: The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"/home/seokj/ray_results/TorchTrainer_2023-07-04_16-07-47\")`.\nTo start a new run that will retry on training failures, set `air.RunConfig(failure_config=air.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries."
     ]
    }
   ],
   "source": [
    "from ray.air.config import ScalingConfig, RunConfig, CheckpointConfig\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.tune.stopper import TrialPlateauStopper, ExperimentPlateauStopper, CombinedStopper\n",
    "from ray.data.preprocessors import Chain, SimpleImputer, MaxAbsScaler, MinMaxScaler, PowerTransformer, RobustScaler, StandardScaler\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker, \n",
    "    train_loop_config={\n",
    "        'model':'fsr_model.LSTM',\n",
    "        'model_args':{\n",
    "            'hidden_size':8,\n",
    "            'num_layer':1,\n",
    "        },\n",
    "        'criterion':'torch.nn.MSELoss',\n",
    "        'optimizer':'torch.optim.Adam',\n",
    "        'optimizer_args':{\n",
    "            'lr': 1e-3,\n",
    "        },\n",
    "        'scaler':'sklearn.preprocessing.StandardScaler',\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2,\n",
    "        use_gpu=False,\n",
    "    ),\n",
    "    run_config=RunConfig(\n",
    "        # callbacks=[\n",
    "        #     WandbLoggerCallback(project='FSR-prediction'),\n",
    "        # ],\n",
    "        stop=CombinedStopper(\n",
    "            TrialPlateauStopper(metric='rmse'),\n",
    "            ExperimentPlateauStopper(metric='rmse'),\n",
    "        ),\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=3,\n",
    "            checkpoint_score_attribute='rmse',\n",
    "            checkpoint_score_order='min',\n",
    "        ),\n",
    "    ),\n",
    "    datasets={\n",
    "        'train':train_ds,\n",
    "        'test':test_ds,\n",
    "    },\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
