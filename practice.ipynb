{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.295725  [    0/60000]\n",
      "loss: 2.288331  [ 6400/60000]\n",
      "loss: 2.269881  [12800/60000]\n",
      "loss: 2.267963  [19200/60000]\n",
      "loss: 2.246048  [25600/60000]\n",
      "loss: 2.210479  [32000/60000]\n",
      "loss: 2.222671  [38400/60000]\n",
      "loss: 2.175079  [44800/60000]\n",
      "loss: 2.179878  [51200/60000]\n",
      "loss: 2.139994  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 2.138721 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.147133  [    0/60000]\n",
      "loss: 2.136176  [ 6400/60000]\n",
      "loss: 2.081316  [12800/60000]\n",
      "loss: 2.098356  [19200/60000]\n",
      "loss: 2.039676  [25600/60000]\n",
      "loss: 1.977533  [32000/60000]\n",
      "loss: 2.004722  [38400/60000]\n",
      "loss: 1.917204  [44800/60000]\n",
      "loss: 1.934661  [51200/60000]\n",
      "loss: 1.839513  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.847508 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.884295  [    0/60000]\n",
      "loss: 1.844624  [ 6400/60000]\n",
      "loss: 1.736727  [12800/60000]\n",
      "loss: 1.773564  [19200/60000]\n",
      "loss: 1.658612  [25600/60000]\n",
      "loss: 1.621730  [32000/60000]\n",
      "loss: 1.634687  [38400/60000]\n",
      "loss: 1.542075  [44800/60000]\n",
      "loss: 1.574895  [51200/60000]\n",
      "loss: 1.454008  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.481025 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.546907  [    0/60000]\n",
      "loss: 1.507822  [ 6400/60000]\n",
      "loss: 1.373632  [12800/60000]\n",
      "loss: 1.440276  [19200/60000]\n",
      "loss: 1.322248  [25600/60000]\n",
      "loss: 1.326777  [32000/60000]\n",
      "loss: 1.335736  [38400/60000]\n",
      "loss: 1.264882  [44800/60000]\n",
      "loss: 1.306755  [51200/60000]\n",
      "loss: 1.197755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.226468 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.295339  [    0/60000]\n",
      "loss: 1.277842  [ 6400/60000]\n",
      "loss: 1.126734  [12800/60000]\n",
      "loss: 1.229979  [19200/60000]\n",
      "loss: 1.105348  [25600/60000]\n",
      "loss: 1.133698  [32000/60000]\n",
      "loss: 1.153043  [38400/60000]\n",
      "loss: 1.091334  [44800/60000]\n",
      "loss: 1.139907  [51200/60000]\n",
      "loss: 1.045722  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.068517 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_epoch(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    batch_size = 64\n",
    "    lr = 1e-3\n",
    "    epochs = 5\n",
    "    \n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    # Get cpu or gpu device for training.\n",
    "    device = \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    \n",
    "    model = NeuralNetwork().to(device)\n",
    "    print(model)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_epoch(test_dataloader, model, loss_fn)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.304617  [    0/60000]\n",
      "loss: 2.285371  [ 6400/60000]\n",
      "loss: 2.271165  [12800/60000]\n",
      "loss: 2.259961  [19200/60000]\n",
      "loss: 2.240443  [25600/60000]\n",
      "loss: 2.215926  [32000/60000]\n",
      "loss: 2.221008  [38400/60000]\n",
      "loss: 2.191331  [44800/60000]\n",
      "loss: 2.185502  [51200/60000]\n",
      "loss: 2.148566  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.147187 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.163097  [    0/60000]\n",
      "loss: 2.146952  [ 6400/60000]\n",
      "loss: 2.094553  [12800/60000]\n",
      "loss: 2.103191  [19200/60000]\n",
      "loss: 2.054648  [25600/60000]\n",
      "loss: 1.997787  [32000/60000]\n",
      "loss: 2.013405  [38400/60000]\n",
      "loss: 1.942909  [44800/60000]\n",
      "loss: 1.943117  [51200/60000]\n",
      "loss: 1.865383  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 1.867540 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.909571  [    0/60000]\n",
      "loss: 1.868183  [ 6400/60000]\n",
      "loss: 1.755521  [12800/60000]\n",
      "loss: 1.786567  [19200/60000]\n",
      "loss: 1.682479  [25600/60000]\n",
      "loss: 1.642840  [32000/60000]\n",
      "loss: 1.648873  [38400/60000]\n",
      "loss: 1.565118  [44800/60000]\n",
      "loss: 1.584990  [51200/60000]\n",
      "loss: 1.479309  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.499026 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.576882  [    0/60000]\n",
      "loss: 1.528863  [ 6400/60000]\n",
      "loss: 1.385050  [12800/60000]\n",
      "loss: 1.446660  [19200/60000]\n",
      "loss: 1.342283  [25600/60000]\n",
      "loss: 1.340553  [32000/60000]\n",
      "loss: 1.346086  [38400/60000]\n",
      "loss: 1.283069  [44800/60000]\n",
      "loss: 1.314038  [51200/60000]\n",
      "loss: 1.216123  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.241329 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.327827  [    0/60000]\n",
      "loss: 1.296433  [ 6400/60000]\n",
      "loss: 1.135706  [12800/60000]\n",
      "loss: 1.229513  [19200/60000]\n",
      "loss: 1.122516  [25600/60000]\n",
      "loss: 1.142933  [32000/60000]\n",
      "loss: 1.160400  [38400/60000]\n",
      "loss: 1.106946  [44800/60000]\n",
      "loss: 1.142818  [51200/60000]\n",
      "loss: 1.059758  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.079579 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.air import session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()  # Divide by word size\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()  # Divide by word size\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.air import session\n",
    "\n",
    "def train_func(config: dict):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    \n",
    "    batch_size_per_worker = batch_size // session.get_world_size()\n",
    "    \n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size_per_worker)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size_per_worker)\n",
    "    \n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "    \n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss = test_epoch(test_dataloader, model, loss_fn)\n",
    "        from ray.air import Checkpoint\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            dict(epoch=t, model=model.state_dict())\n",
    "        )\n",
    "        session.report(dict(loss=test_loss), checkpoint=checkpoint)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:27:46,045\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-07-03 19:27:48,703\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Trainer(...)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-03 19:29:02</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:14.19        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.6/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_41ed3_00000</td><td>TERMINATED</td><td>172.26.215.93:882230</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         66.8926</td><td style=\"text-align: right;\">1.20098</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=882230)\u001b[0m 2023-07-03 19:27:56,665\tINFO backend_executor.py:137 -- Starting distributed worker processes: ['882300 (172.26.215.93)', '882301 (172.26.215.93)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882300)\u001b[0m 2023-07-03 19:27:58,741\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882300)\u001b[0m 2023-07-03 19:27:59,299\tINFO train_loop_utils.py:286 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882300)\u001b[0m 2023-07-03 19:27:59,300\tINFO train_loop_utils.py:346 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_41ed3_00000</td><td>2023-07-03_19-29-00</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">1.20098</td><td>172.26.215.93</td><td style=\"text-align: right;\">882230</td><td style=\"text-align: right;\">             66.8926</td><td style=\"text-align: right;\">           15.2581</td><td style=\"text-align: right;\">       66.8926</td><td style=\"text-align: right;\"> 1688380140</td><td style=\"text-align: right;\">                   4</td><td>41ed3_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882301)\u001b[0m Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:29:02,969\tINFO tune.py:1111 -- Total run time: 74.26 seconds (74.18 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last result: {'loss': 1.2009836940249061, 'timestamp': 1688380140, 'time_this_iter_s': 15.25805377960205, 'done': True, 'training_iteration': 4, 'trial_id': '41ed3_00000', 'date': '2023-07-03_19-29-00', 'time_total_s': 66.8925530910492, 'pid': 882230, 'hostname': 'DESKTOP-0P789CI', 'node_ip': '172.26.215.93', 'config': {'train_loop_config': {'lr': 0.001, 'batch_size': 64, 'epochs': 4}}, 'time_since_restore': 66.8925530910492, 'iterations_since_restore': 4, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4},\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import Checkpoint\n",
    "\n",
    "def load_data():\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return training_data, test_data\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    \n",
    "    batch_size_per_worker = batch_size // session.get_world_size()\n",
    "    \n",
    "    training_data, test_data = load_data()  # <- this is new!\n",
    "    \n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size_per_worker)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size_per_worker)\n",
    "    \n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "    \n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss = test_epoch(test_dataloader, model, loss_fn)\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            dict(epoch=t, model=model.state_dict())\n",
    "        )\n",
    "        session.report(dict(loss=test_loss), checkpoint=checkpoint)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-03 19:39:05</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:37.70        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.6/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_9b5e4_00000</td><td>TERMINATED</td><td>172.26.215.93:882712</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         92.1065</td><td style=\"text-align: right;\">1.25864</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=882712)\u001b[0m 2023-07-03 19:37:33,985\tINFO backend_executor.py:137 -- Starting distributed worker processes: ['882758 (172.26.215.93)', '882759 (172.26.215.93)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m 2023-07-03 19:37:35,431\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882300)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26421880 [00:00<?, ?it/s]\n",
      "  0%|          | 32768/26421880 [00:00<03:20, 131516.75it/s]\n",
      "  0%|          | 65536/26421880 [00:00<03:14, 135401.48it/s]\n",
      "  2%|▏         | 425984/26421880 [00:05<03:35, 120786.28it/s]\n",
      " 62%|██████▏   | 16252928/26421880 [00:05<00:03, 3136056.27it/s]\u001b[32m [repeated 41x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      " 91%|█████████▏| 24150016/26421880 [00:07<00:00, 3161171.50it/s]\n",
      " 93%|█████████▎| 24576000/26421880 [00:07<00:00, 3422442.83it/s]\n",
      " 94%|█████████▍| 24936448/26421880 [00:08<00:00, 3194646.45it/s]\n",
      " 96%|█████████▌| 25329664/26421880 [00:08<00:00, 3354793.09it/s]\n",
      " 97%|█████████▋| 25722880/26421880 [00:08<00:00, 3167942.36it/s]\n",
      "100%|██████████| 26421880/26421880 [00:08<00:00, 3130820.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29515 [00:00<?, ?it/s]\n",
      "  5%|▍         | 1277952/26421880 [00:10<01:49, 230057.44it/s]\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "100%|██████████| 29515/29515 [00:00<00:00, 59517.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\n",
      " 21%|██        | 5537792/26421880 [00:15<00:12, 1713041.40it/s]\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      " 54%|█████▍    | 14286848/26421880 [00:20<00:06, 1961187.41it/s]\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      " 92%|█████████▏| 4063232/4422102 [00:09<00:00, 1338036.13it/s]\n",
      " 99%|█████████▊| 4358144/4422102 [00:09<00:00, 1627569.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:09<00:00, 464521.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 12096513.72it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m 2023-07-03 19:37:58,896\tINFO train_loop_utils.py:286 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882758)\u001b[0m 2023-07-03 19:37:58,897\tINFO train_loop_utils.py:346 -- Wrapping provided model in DistributedDataParallel.\n",
      " 84%|████████▍ | 22282240/26421880 [00:25<00:02, 1594864.60it/s]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      " 92%|█████████▏| 24182784/26421880 [00:26<00:01, 1368264.77it/s]\n",
      " 92%|█████████▏| 24412160/26421880 [00:27<00:01, 1473449.02it/s]\n",
      " 93%|█████████▎| 24576000/26421880 [00:27<00:01, 1439784.03it/s]\n",
      " 94%|█████████▍| 24805376/26421880 [00:27<00:01, 1552220.03it/s]\n",
      " 95%|█████████▍| 24969216/26421880 [00:27<00:00, 1478060.73it/s]\n",
      " 95%|█████████▌| 25165824/26421880 [00:27<00:00, 1558619.38it/s]\n",
      " 96%|█████████▌| 25329664/26421880 [00:27<00:00, 1475959.70it/s]\n",
      " 97%|█████████▋| 25559040/26421880 [00:27<00:00, 1591292.05it/s]\n",
      " 97%|█████████▋| 25722880/26421880 [00:27<00:00, 1497252.97it/s]\n",
      " 98%|█████████▊| 25952256/26421880 [00:28<00:00, 1633757.67it/s]\n",
      " 99%|█████████▉| 26148864/26421880 [00:28<00:00, 1568351.98it/s]\n",
      "100%|██████████| 26421880/26421880 [00:28<00:00, 933037.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29515 [00:00<?, ?it/s]\n",
      "100%|██████████| 29515/29515 [00:00<00:00, 114225.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\n",
      " 91%|█████████ | 24018944/26421880 [00:26<00:01, 1486832.38it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1984761.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 19522854.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_9b5e4_00000</td><td>2023-07-03_19-39-03</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">1.25864</td><td>172.26.215.93</td><td style=\"text-align: right;\">882712</td><td>True               </td><td style=\"text-align: right;\">             92.1065</td><td style=\"text-align: right;\">           14.8636</td><td style=\"text-align: right;\">       92.1065</td><td style=\"text-align: right;\"> 1688380743</td><td style=\"text-align: right;\">                   4</td><td>9b5e4_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=882759)\u001b[0m Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:39:05,998\tINFO tune.py:1111 -- Total run time: 97.73 seconds (97.70 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4},\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last result: {'loss': 1.258639681491123, 'timestamp': 1688380743, 'time_this_iter_s': 14.863616228103638, 'should_checkpoint': True, 'done': True, 'training_iteration': 4, 'trial_id': '9b5e4_00000', 'date': '2023-07-03_19-39-03', 'time_total_s': 92.10650444030762, 'pid': 882712, 'hostname': 'DESKTOP-0P789CI', 'node_ip': '172.26.215.93', 'config': {'train_loop_config': {'lr': 0.001, 'batch_size': 64, 'epochs': 4}}, 'time_since_restore': 92.10650444030762, 'iterations_since_restore': 4, 'experiment_tag': '0'}\n",
      "Checkpoint: TorchCheckpoint(local_path=/home/seokj/ray_results/TorchTrainer_2023-07-03_19-37-28/TorchTrainer_9b5e4_00000_0_2023-07-03_19-37-28/checkpoint_000003)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Last result: {result.metrics}\")\n",
    "print(f\"Checkpoint: {result.checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_model(model):\n",
    "    classes = [\n",
    "        \"T-shirt/top\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ]\n",
    "\n",
    "    model.eval()\n",
    "    x, y = test_data[0][0], test_data[0][1]\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "model = TorchCheckpoint.from_checkpoint(result.checkpoint).get_model(NeuralNetwork())\n",
    "\n",
    "predict_from_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "def predict_from_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            pred = model(x)\n",
    "            predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "            print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n",
      "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Pullover\", Actual: \"Shirt\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Pullover\", Actual: \"Coat\"\n",
      "Predicted: \"Coat\", Actual: \"Shirt\"\n",
      "Predicted: \"Sneaker\", Actual: \"Sandal\"\n",
      "Predicted: \"Sneaker\", Actual: \"Sneaker\"\n"
     ]
    }
   ],
   "source": [
    "predict_from_model(model, [test_data[i] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.torch import TorchPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(result.checkpoint, TorchPredictor, model=NeuralNetwork())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:39:07,764\tWARNING dataset.py:253 -- \u001b[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\n",
      "\n",
      "Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ray.data\n",
    "\n",
    "ds = ray.data.from_items([x.numpy() for x, y in test_data], parallelism=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = batch_predictor.predict(ds, batch_size=32, min_scoring_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:39:07,804\tINFO dataset.py:2087 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2023-07-03 19:39:07,812\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(ScoringWrapper)]\n",
      "2023-07-03 19:39:07,813\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-07-03 19:39:07,816\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-07-03 19:39:07,888\tINFO actor_pool_map_operator.py:114 -- MapBatches(ScoringWrapper): Waiting for 2 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4393d85750ef4bd5801f669ebfa53923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:39:11,979\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-472, started daemon 140284872603200)>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': array([-1.4564618 , -1.6455319 , -0.5546917 , -1.4862297 , -0.67328656,\n",
      "        1.3009992 , -0.76655257,  1.6294042 ,  1.2306256 ,  2.0893838 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.529662  , -2.3841782 ,  2.6290684 , -1.1644136 ,  2.4346154 ,\n",
      "       -1.7986703 ,  1.8237766 , -2.2549539 ,  0.91606885, -1.2686421 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 1.6924237 ,  3.7445989 , -0.16596645,  2.7232094 ,  0.37961888,\n",
      "       -1.8623419 ,  0.5047344 , -2.215086  , -1.457871  , -2.498712  ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 1.1999766 ,  2.8721836 , -0.22619268,  2.152885  ,  0.2031754 ,\n",
      "       -1.3261802 ,  0.32827246, -1.6174845 , -1.1585081 , -1.8407434 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.70811534, -0.9485282 ,  1.0355327 , -0.23830125,  0.9868727 ,\n",
      "       -0.96967053,  0.9683471 , -1.3278077 ,  0.3286457 , -0.7888265 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 1.6928362 ,  2.575294  ,  0.2620929 ,  2.0942364 ,  0.6812103 ,\n",
      "       -1.7834175 ,  0.79562175, -2.2057254 , -1.1609243 , -2.3397624 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.5601998 , -0.35490978,  0.6695457 , -0.01298608,  0.6683689 ,\n",
      "       -0.61404246,  0.62692416, -0.9017134 ,  0.0351227 , -0.82279027],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.23845842, -0.8815688 ,  1.1300596 , -0.33205688,  1.1372564 ,\n",
      "       -0.8410609 ,  0.8761482 , -1.1075454 ,  0.35668567, -0.7667322 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([-0.32073838, -0.24435075, -0.04473148, -0.22722204, -0.15160197,\n",
      "        0.31093344, -0.12921765,  0.4461954 ,  0.21030326,  0.03350915],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([-0.97831   , -0.9269584 , -0.37714827, -0.8839232 , -0.51406074,\n",
      "        0.9227356 , -0.55104923,  1.5308083 ,  0.7879804 ,  0.8517095 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.34909698, -0.86658144,  1.7399684 , -0.35212326,  1.7181234 ,\n",
      "       -1.3036585 ,  1.2191234 , -1.5380269 ,  0.1721949 , -1.2545886 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([-1.0893592 , -1.3560253 , -0.2708218 , -1.1749182 , -0.35132578,\n",
      "        0.92335296, -0.4940641 ,  1.2433867 ,  0.96907437,  1.347156  ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([-0.97065574, -1.001185  , -0.29807162, -0.9381075 , -0.40417254,\n",
      "        0.9206278 , -0.5110151 ,  1.3693798 ,  0.98599714,  0.7001909 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 1.0610889 ,  2.089599  , -0.49105272,  2.2480106 ,  0.0221239 ,\n",
      "       -1.2449741 ,  0.15745018, -1.4443867 , -0.8937597 , -1.387398  ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.8747498 , -1.4542739 ,  2.02591   , -0.21470112,  2.4118679 ,\n",
      "       -2.129375  ,  1.7537359 , -2.5631166 ,  0.7021716 , -1.670532  ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 1.2917049 ,  2.7139015 , -0.14598417,  2.2077205 ,  0.27096152,\n",
      "       -1.4249895 ,  0.43262994, -1.7319114 , -1.2228148 , -1.8889227 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.70444196, -0.70666116,  1.154929  , -0.271767  ,  0.96564186,\n",
      "       -0.9265362 ,  0.9769671 , -1.2894387 ,  0.21986076, -0.98011696],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 0.6411483 , -1.3178942 ,  1.4451219 , -0.51881504,  1.4368525 ,\n",
      "       -1.2330294 ,  1.1989272 , -1.6208997 ,  0.61184275, -1.001287  ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([-1.4022675 , -2.389628  ,  0.01796474, -1.9659618 , -0.14002182,\n",
      "        0.9351756 , -0.46297616,  1.2646779 ,  2.0324376 ,  1.6286999 ],\n",
      "      dtype=float32)}\n",
      "{'predictions': array([ 2.8590374 ,  0.99693763,  1.0499637 ,  1.748455  ,  1.3579652 ,\n",
      "       -2.5708385 ,  1.685844  , -3.2667556 , -0.7993251 , -2.7723997 ],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = results.map_batches(\n",
    "    lambda batch: {\"pred\": [classes[pred.argmax(0)] for pred in batch[\"predictions\"]]}, \n",
    "    batch_size=32,\n",
    "    batch_format=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:43:26,920\tINFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(ScoringWrapper)] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "2023-07-03 19:43:26,921\tINFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-07-03 19:43:26,922\tINFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-07-03 19:43:26,970\tINFO actor_pool_map_operator.py:114 -- MapBatches(ScoringWrapper): Waiting for 2 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42967660870d4948aec2e99babdef441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:43:32,080\tINFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-528, started daemon 140284855817792)>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ankle boot', 'Ankle boot')\n",
      "('Pullover', 'Pullover')\n",
      "('Trouser', 'Trouser')\n",
      "('Trouser', 'Trouser')\n",
      "('Pullover', 'Shirt')\n",
      "('Trouser', 'Trouser')\n",
      "('Pullover', 'Coat')\n",
      "('Coat', 'Shirt')\n",
      "('Sneaker', 'Sandal')\n",
      "('Sneaker', 'Sneaker')\n",
      "('Pullover', 'Coat')\n",
      "('Ankle boot', 'Sandal')\n",
      "('Sneaker', 'Sneaker')\n",
      "('Dress', 'Dress')\n",
      "('Coat', 'Coat')\n",
      "('Trouser', 'Trouser')\n",
      "('Pullover', 'Pullover')\n",
      "('Pullover', 'Coat')\n",
      "('Bag', 'Bag')\n",
      "('T-shirt/top', 'T-shirt/top')\n"
     ]
    }
   ],
   "source": [
    "real_classes = [classes[y] for x, y in test_data]\n",
    "for predicted, real in zip(predicted_classes.take_batch()[\"pred\"], real_classes):\n",
    "    print((predicted, real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
