{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4\n",
    "\n",
    "Index_X = FSR_for_force, FSR_for_coord\n",
    "\n",
    "Index_y = force, x_coord, y_coord\n",
    "\n",
    "Data = Splited by Subject\n",
    "\n",
    "## Run result\n",
    "\n",
    "https://wandb.ai/seokjin/FSR-prediction/groups/FSR_Trainable_2023-08-10_23-25-39/workspace?workspace=user-seokjin\n",
    "\n",
    "## Experiment id\n",
    "\n",
    "FSR_Trainable_2023-08-10_23-25-39\n",
    "\n",
    "## Best metric (RMSE)\n",
    "\n",
    "171.708\n",
    "\n",
    "1.022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_searchspace(trial):\n",
    "    model = trial.suggest_categorical('model', ['fsr_model.CNN_LSTM'])\n",
    "    if model == 'fsr_model.LSTM':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.CNN_LSTM':\n",
    "        trial.suggest_categorical('model_args/cnn_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_categorical('model_args/lstm_hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/cnn_num_layer', 1, 8)\n",
    "        trial.suggest_int('model_args/lstm_num_layer', 1, 8)\n",
    "    elif model == 'fsr_model.ANN':\n",
    "        trial.suggest_categorical('model_args/hidden_size', [8, 16, 32, 64, 128])\n",
    "        trial.suggest_int('model_args/num_layer', 1, 8)\n",
    "    trial.suggest_categorical('criterion', ['torch.nn.MSELoss'])\n",
    "    trial.suggest_categorical('optimizer', [\n",
    "        'torch.optim.Adam',\n",
    "        'torch.optim.NAdam',\n",
    "        'torch.optim.Adagrad',\n",
    "        'torch.optim.RAdam',\n",
    "        'torch.optim.SGD',\n",
    "    ])\n",
    "    trial.suggest_float('optimizer_args/lr', 1e-5, 1e-1, log=True)\n",
    "    imputer = trial.suggest_categorical('imputer', ['sklearn.impute.SimpleImputer'])\n",
    "    if imputer == 'sklearn.impute.SimpleImputer':\n",
    "        trial.suggest_categorical('imputer_args/strategy', [\n",
    "            'mean',\n",
    "            'median',\n",
    "        ])\n",
    "    trial.suggest_categorical('scaler', [ \n",
    "        'sklearn.preprocessing.StandardScaler',\n",
    "        'sklearn.preprocessing.MinMaxScaler',\n",
    "        'sklearn.preprocessing.RobustScaler',\n",
    "    ])\n",
    "    return {\n",
    "        'index_X': ['FSR_for_force', 'FSR_for_coord'],\n",
    "        'index_y': ['force', 'x_coord', 'y_coord'],\n",
    "        'data_loader': 'fsr_data.get_index_splited_by_subject'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-10 23:25:39,751] A new study created in memory with name: optuna\n"
     ]
    }
   ],
   "source": [
    "import ray.tune\n",
    "import ray.air\n",
    "import ray.air.integrations.wandb\n",
    "import ray.tune.schedulers\n",
    "from fsr_trainable import FSR_Trainable\n",
    "import ray.tune.search\n",
    "import ray.tune.search.optuna\n",
    "\n",
    "tuner = ray.tune.Tuner(\n",
    "    trainable=ray.tune.with_resources(\n",
    "        FSR_Trainable, {'cpu':2},\n",
    "    ),\n",
    "    tune_config=ray.tune.TuneConfig(\n",
    "        num_samples=100,\n",
    "        scheduler=ray.tune.schedulers.ASHAScheduler(\n",
    "            max_t=100,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2,\n",
    "            brackets=1,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "        search_alg=ray.tune.search.optuna.OptunaSearch(\n",
    "            space=define_searchspace,\n",
    "            metric='metric',\n",
    "            mode='min',\n",
    "        ),\n",
    "    ), \n",
    "    run_config=ray.air.RunConfig(\n",
    "        callbacks=[\n",
    "            ray.air.integrations.wandb.WandbLoggerCallback(project='FSR-prediction'),\n",
    "        ],\n",
    "        checkpoint_config=ray.air.CheckpointConfig(\n",
    "            num_to_keep=3,\n",
    "            checkpoint_score_attribute='metric',\n",
    "            checkpoint_score_order='min',\n",
    "            checkpoint_frequency=5,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 23:25:41,910\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2023-08-10 23:25:43,812\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-11 00:27:38</td></tr>\n",
       "<tr><td>Running for: </td><td>01:01:54.51        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.3/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=100<br>Bracket: Iter 64.000: -0.66961899688884 | Iter 32.000: -0.6839074846876434 | Iter 16.000: -0.7039353711411123 | Iter 8.000: -0.7213298673014691 | Iter 4.000: -0.7473924234625903 | Iter 2.000: -0.8228812820498248 | Iter 1.000: -0.8813348194009702<br>Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc                 </th><th>criterion       </th><th>data_loader         </th><th>imputer             </th><th>imputer_args/strateg\n",
       "y       </th><th>index_X             </th><th>index_y             </th><th>model             </th><th style=\"text-align: right;\">    model_args/cnn_hidde\n",
       "n_size</th><th style=\"text-align: right;\">  model_args/cnn_num_l\n",
       "ayer</th><th style=\"text-align: right;\">    model_args/lstm_hidd\n",
       "en_size</th><th style=\"text-align: right;\">  model_args/lstm_num_\n",
       "layer</th><th>optimizer          </th><th style=\"text-align: right;\">  optimizer_args/lr</th><th>scaler              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  tmae_force</th><th style=\"text-align: right;\">  trmse_force</th><th style=\"text-align: right;\">  tmape_force</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_102a7f72</td><td>TERMINATED</td><td>172.26.215.93:156286</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_c2c0</td><td>[&#x27;force&#x27;, &#x27;x_co_7d80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.0608935  </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">        93.1655 </td><td style=\"text-align: right;\">    3.48836 </td><td style=\"text-align: right;\">     2.00933 </td><td style=\"text-align: right;\"> 19.578      </td></tr>\n",
       "<tr><td>FSR_Trainable_b15e6191</td><td>TERMINATED</td><td>172.26.215.93:156357</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_9e80</td><td>[&#x27;force&#x27;, &#x27;x_co_4880</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">4</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0227349  </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.8108 </td><td style=\"text-align: right;\">    7.05835 </td><td style=\"text-align: right;\">     6.31898 </td><td style=\"text-align: right;\">  7.88817e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_306a3737</td><td>TERMINATED</td><td>172.26.215.93:156530</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_9a00</td><td>[&#x27;force&#x27;, &#x27;x_co_0d80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.0501648  </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.47301</td><td style=\"text-align: right;\">    4.00419 </td><td style=\"text-align: right;\">     2.24537 </td><td style=\"text-align: right;\">255.578      </td></tr>\n",
       "<tr><td>FSR_Trainable_6872dd1b</td><td>TERMINATED</td><td>172.26.215.93:156704</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_d300</td><td>[&#x27;force&#x27;, &#x27;x_co_d8c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">3</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00142678 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       200.64   </td><td style=\"text-align: right;\">    0.537145</td><td style=\"text-align: right;\">     0.30678 </td><td style=\"text-align: right;\">  1.1893e+15 </td></tr>\n",
       "<tr><td>FSR_Trainable_10656ea1</td><td>TERMINATED</td><td>172.26.215.93:157005</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_7640</td><td>[&#x27;force&#x27;, &#x27;x_co_6d00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">8</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        2.66882e-05</td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.97302</td><td style=\"text-align: right;\">    6.08244 </td><td style=\"text-align: right;\">     7.06589 </td><td style=\"text-align: right;\">  1.92657e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_f4bdfb81</td><td>TERMINATED</td><td>172.26.215.93:157231</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_5ac0</td><td>[&#x27;force&#x27;, &#x27;x_co_edc0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00245838 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       644.835  </td><td style=\"text-align: right;\">    0.520412</td><td style=\"text-align: right;\">     0.306155</td><td style=\"text-align: right;\">  1.11128e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_60a52149</td><td>TERMINATED</td><td>172.26.215.93:157451</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_1f40</td><td>[&#x27;force&#x27;, &#x27;x_co_9e80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        3.72954e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       270.942  </td><td style=\"text-align: right;\">    0.39834 </td><td style=\"text-align: right;\">     0.250568</td><td style=\"text-align: right;\">  7.5052e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_331fad73</td><td>TERMINATED</td><td>172.26.215.93:157754</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_e3c0</td><td>[&#x27;force&#x27;, &#x27;x_co_f240</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">8</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.00855669 </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.95958</td><td style=\"text-align: right;\">    3.4862  </td><td style=\"text-align: right;\">     2.00961 </td><td style=\"text-align: right;\"> 37.7965     </td></tr>\n",
       "<tr><td>FSR_Trainable_408c68c9</td><td>TERMINATED</td><td>172.26.215.93:157990</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_2200</td><td>[&#x27;force&#x27;, &#x27;x_co_2680</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">5</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        2.6376e-05 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.85516</td><td style=\"text-align: right;\">    6.15426 </td><td style=\"text-align: right;\">     7.13933 </td><td style=\"text-align: right;\">  1.73708e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_7c0b9ad8</td><td>TERMINATED</td><td>172.26.215.93:158193</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_2f40</td><td>[&#x27;force&#x27;, &#x27;x_co_9040</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">4</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.000181869</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         9.21296</td><td style=\"text-align: right;\">    1.2837  </td><td style=\"text-align: right;\">     0.63897 </td><td style=\"text-align: right;\">  2.97005e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_bbab0ac2</td><td>TERMINATED</td><td>172.26.215.93:158456</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_8f80</td><td>[&#x27;force&#x27;, &#x27;x_co_f880</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">7</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.0441138  </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        14.7077 </td><td style=\"text-align: right;\">    0.556037</td><td style=\"text-align: right;\">     0.31391 </td><td style=\"text-align: right;\">  1.19966e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_841d9a78</td><td>TERMINATED</td><td>172.26.215.93:158696</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_92c0</td><td>[&#x27;force&#x27;, &#x27;x_co_96c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">3</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.026825   </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        10.1129 </td><td style=\"text-align: right;\">    0.607449</td><td style=\"text-align: right;\">     0.33175 </td><td style=\"text-align: right;\">  1.42194e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_dd2298d1</td><td>TERMINATED</td><td>172.26.215.93:158930</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_2f40</td><td>[&#x27;force&#x27;, &#x27;x_co_f080</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">3</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        7.30309e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        10.0603 </td><td style=\"text-align: right;\">    0.623371</td><td style=\"text-align: right;\">     0.348452</td><td style=\"text-align: right;\">  1.26238e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_698f5feb</td><td>TERMINATED</td><td>172.26.215.93:159115</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_3f00</td><td>[&#x27;force&#x27;, &#x27;x_co_be80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00171115 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       132.539  </td><td style=\"text-align: right;\">    0.241186</td><td style=\"text-align: right;\">     0.157922</td><td style=\"text-align: right;\">  3.5446e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_a6c859de</td><td>TERMINATED</td><td>172.26.215.93:159359</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_afc0</td><td>[&#x27;force&#x27;, &#x27;x_co_3040</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">6</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00241839 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        44.6325 </td><td style=\"text-align: right;\">    0.474715</td><td style=\"text-align: right;\">     0.306622</td><td style=\"text-align: right;\">  9.17048e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_9cb367ce</td><td>TERMINATED</td><td>172.26.215.93:159650</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3e80</td><td>[&#x27;force&#x27;, &#x27;x_co_2bc0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">6</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00253775 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      1320.8    </td><td style=\"text-align: right;\">    0.270587</td><td style=\"text-align: right;\">     0.186238</td><td style=\"text-align: right;\">  3.47387e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_d77a286d</td><td>TERMINATED</td><td>172.26.215.93:159886</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3840</td><td>[&#x27;force&#x27;, &#x27;x_co_31c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00324431 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">       134.37   </td><td style=\"text-align: right;\">    0.414143</td><td style=\"text-align: right;\">     0.316001</td><td style=\"text-align: right;\">  5.43593e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_fec4be7a</td><td>TERMINATED</td><td>172.26.215.93:160138</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_0ec0</td><td>[&#x27;force&#x27;, &#x27;x_co_d8c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000611723</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       141.883  </td><td style=\"text-align: right;\">    0.509197</td><td style=\"text-align: right;\">     0.302818</td><td style=\"text-align: right;\">  1.06173e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_d1e87242</td><td>TERMINATED</td><td>172.26.215.93:160416</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_3600</td><td>[&#x27;force&#x27;, &#x27;x_co_8e80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00038198 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        18.7492 </td><td style=\"text-align: right;\">    0.529195</td><td style=\"text-align: right;\">     0.308462</td><td style=\"text-align: right;\">  1.11724e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_28642b0a</td><td>TERMINATED</td><td>172.26.215.93:160652</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_eb40</td><td>[&#x27;force&#x27;, &#x27;x_co_7a40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000343839</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        39.6005 </td><td style=\"text-align: right;\">    0.51655 </td><td style=\"text-align: right;\">     0.304539</td><td style=\"text-align: right;\">  1.08122e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_0daa8344</td><td>TERMINATED</td><td>172.26.215.93:160885</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_2f00</td><td>[&#x27;force&#x27;, &#x27;x_co_9100</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000509269</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       474.341  </td><td style=\"text-align: right;\">    0.289985</td><td style=\"text-align: right;\">     0.195866</td><td style=\"text-align: right;\">  3.7867e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_96f85d46</td><td>TERMINATED</td><td>172.26.215.93:161128</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_a8c0</td><td>[&#x27;force&#x27;, &#x27;x_co_b500</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000119134</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.83159</td><td style=\"text-align: right;\">    0.647845</td><td style=\"text-align: right;\">     0.395438</td><td style=\"text-align: right;\">  9.39295e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e3da12c6</td><td>TERMINATED</td><td>172.26.215.93:161327</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_ef80</td><td>[&#x27;force&#x27;, &#x27;x_co_8e40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        1.42011e-05</td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.83805</td><td style=\"text-align: right;\">    3.4364  </td><td style=\"text-align: right;\">     2.01338 </td><td style=\"text-align: right;\"> 27.417      </td></tr>\n",
       "<tr><td>FSR_Trainable_517ec18a</td><td>TERMINATED</td><td>172.26.215.93:161557</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_b280</td><td>[&#x27;force&#x27;, &#x27;x_co_c480</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.00110562 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.56528</td><td style=\"text-align: right;\">    6.21475 </td><td style=\"text-align: right;\">     6.07428 </td><td style=\"text-align: right;\">  6.75712e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_bad38ad8</td><td>TERMINATED</td><td>172.26.215.93:161778</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_8200</td><td>[&#x27;force&#x27;, &#x27;x_co_ed40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.00111841 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.08934</td><td style=\"text-align: right;\">    5.93441 </td><td style=\"text-align: right;\">     5.97072 </td><td style=\"text-align: right;\">  6.52012e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_93fa7cd9</td><td>TERMINATED</td><td>172.26.215.93:162011</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_9940</td><td>[&#x27;force&#x27;, &#x27;x_co_a840</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000502175</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        38.9784 </td><td style=\"text-align: right;\">    0.513915</td><td style=\"text-align: right;\">     0.302369</td><td style=\"text-align: right;\">  1.07544e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_c9d4e9c0</td><td>TERMINATED</td><td>172.26.215.93:162274</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_b9c0</td><td>[&#x27;force&#x27;, &#x27;x_co_9f00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000477958</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        10.3587 </td><td style=\"text-align: right;\">    0.508201</td><td style=\"text-align: right;\">     0.305094</td><td style=\"text-align: right;\">  1.0383e+15 </td></tr>\n",
       "<tr><td>FSR_Trainable_c3538732</td><td>TERMINATED</td><td>172.26.215.93:162516</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_1480</td><td>[&#x27;force&#x27;, &#x27;x_co_ba00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">6</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.004928   </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        59.2204 </td><td style=\"text-align: right;\">    0.512834</td><td style=\"text-align: right;\">     0.304988</td><td style=\"text-align: right;\">  1.09081e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_6adba9f2</td><td>TERMINATED</td><td>172.26.215.93:162694</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_2cc0</td><td>[&#x27;force&#x27;, &#x27;x_co_a5c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">6</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00465535 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        25.6715 </td><td style=\"text-align: right;\">    0.399102</td><td style=\"text-align: right;\">     0.314379</td><td style=\"text-align: right;\">  4.18389e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_3318cfcb</td><td>TERMINATED</td><td>172.26.215.93:162978</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_c840</td><td>[&#x27;force&#x27;, &#x27;x_co_15c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">6</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00473996 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">       119.158  </td><td style=\"text-align: right;\">    0.410897</td><td style=\"text-align: right;\">     0.321172</td><td style=\"text-align: right;\">  4.13275e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_27422225</td><td>TERMINATED</td><td>172.26.215.93:163201</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_eb40</td><td>[&#x27;force&#x27;, &#x27;x_co_8e40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">5</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.0056427  </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        17.3004 </td><td style=\"text-align: right;\">    0.39266 </td><td style=\"text-align: right;\">     0.317999</td><td style=\"text-align: right;\">  3.45392e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e7543495</td><td>TERMINATED</td><td>172.26.215.93:163446</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_0200</td><td>[&#x27;force&#x27;, &#x27;x_co_6040</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00175035 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        23.1881 </td><td style=\"text-align: right;\">    0.455591</td><td style=\"text-align: right;\">     0.302393</td><td style=\"text-align: right;\">  8.35788e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_3e3ca0ec</td><td>TERMINATED</td><td>172.26.215.93:163686</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_3a80</td><td>[&#x27;force&#x27;, &#x27;x_co_3700</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00238889 </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.5942 </td><td style=\"text-align: right;\">    3.1346  </td><td style=\"text-align: right;\">     2.10467 </td><td style=\"text-align: right;\">275.505      </td></tr>\n",
       "<tr><td>FSR_Trainable_7d0169a8</td><td>TERMINATED</td><td>172.26.215.93:163924</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_a640</td><td>[&#x27;force&#x27;, &#x27;x_co_8f80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.0104205  </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.62426</td><td style=\"text-align: right;\">    2.77399 </td><td style=\"text-align: right;\">     2.05068 </td><td style=\"text-align: right;\"> 78.7029     </td></tr>\n",
       "<tr><td>FSR_Trainable_cd75fee7</td><td>TERMINATED</td><td>172.26.215.93:164112</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_bec0</td><td>[&#x27;force&#x27;, &#x27;x_co_2400</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00090957 </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.64496</td><td style=\"text-align: right;\">    3.37317 </td><td style=\"text-align: right;\">     1.99853 </td><td style=\"text-align: right;\">  9.16208    </td></tr>\n",
       "<tr><td>FSR_Trainable_ed1df145</td><td>TERMINATED</td><td>172.26.215.93:164340</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_e1c0</td><td>[&#x27;force&#x27;, &#x27;x_co_e140</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000583022</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        21.0966 </td><td style=\"text-align: right;\">    0.51493 </td><td style=\"text-align: right;\">     0.304311</td><td style=\"text-align: right;\">  1.0782e+15 </td></tr>\n",
       "<tr><td>FSR_Trainable_6078457f</td><td>TERMINATED</td><td>172.26.215.93:164558</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_4540</td><td>[&#x27;force&#x27;, &#x27;x_co_fd00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000223534</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.97755</td><td style=\"text-align: right;\">    0.500235</td><td style=\"text-align: right;\">     0.382507</td><td style=\"text-align: right;\">  4.50804e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_5be7df8b</td><td>TERMINATED</td><td>172.26.215.93:164807</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_f800</td><td>[&#x27;force&#x27;, &#x27;x_co_3940</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000766716</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        26.8893 </td><td style=\"text-align: right;\">    0.512069</td><td style=\"text-align: right;\">     0.302433</td><td style=\"text-align: right;\">  1.08594e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_1c248ea4</td><td>TERMINATED</td><td>172.26.215.93:165023</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_99c0</td><td>[&#x27;force&#x27;, &#x27;x_co_8380</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">3</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        8.32638e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.69863</td><td style=\"text-align: right;\">    0.632761</td><td style=\"text-align: right;\">     0.366074</td><td style=\"text-align: right;\">  1.1283e+15 </td></tr>\n",
       "<tr><td>FSR_Trainable_591ef7b6</td><td>TERMINATED</td><td>172.26.215.93:165265</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_5e40</td><td>[&#x27;force&#x27;, &#x27;x_co_a5c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">3</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000819763</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.95831</td><td style=\"text-align: right;\">    0.635326</td><td style=\"text-align: right;\">     0.336404</td><td style=\"text-align: right;\">  1.44579e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_e4521cca</td><td>TERMINATED</td><td>172.26.215.93:165503</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_4e80</td><td>[&#x27;force&#x27;, &#x27;x_co_1040</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">2</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00144767 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.35977</td><td style=\"text-align: right;\">    6.09389 </td><td style=\"text-align: right;\">     7.03528 </td><td style=\"text-align: right;\">  1.32387e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_3743b7d6</td><td>TERMINATED</td><td>172.26.215.93:165733</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_9b40</td><td>[&#x27;force&#x27;, &#x27;x_co_9040</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">2</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00166127 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.94978</td><td style=\"text-align: right;\">    6.17826 </td><td style=\"text-align: right;\">     7.19803 </td><td style=\"text-align: right;\">  8.18479e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_585cd643</td><td>TERMINATED</td><td>172.26.215.93:165948</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_a380</td><td>[&#x27;force&#x27;, &#x27;x_co_9e40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">8</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        4.1973e-05 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.95117</td><td style=\"text-align: right;\">    5.98329 </td><td style=\"text-align: right;\">     7.04    </td><td style=\"text-align: right;\">  1.64155e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_31e77bab</td><td>TERMINATED</td><td>172.26.215.93:166179</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_d7c0</td><td>[&#x27;force&#x27;, &#x27;x_co_db40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">4</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        4.32284e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.7364 </td><td style=\"text-align: right;\">    1.18656 </td><td style=\"text-align: right;\">     0.57549 </td><td style=\"text-align: right;\">  2.81648e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_7674b648</td><td>TERMINATED</td><td>172.26.215.93:166425</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_1580</td><td>[&#x27;force&#x27;, &#x27;x_co_a140</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">3</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000226331</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.58814</td><td style=\"text-align: right;\">    1.00837 </td><td style=\"text-align: right;\">     0.521598</td><td style=\"text-align: right;\">  2.0623e+15 </td></tr>\n",
       "<tr><td>FSR_Trainable_27be0a03</td><td>TERMINATED</td><td>172.26.215.93:166648</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_9dc0</td><td>[&#x27;force&#x27;, &#x27;x_co_84c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">5</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00031008 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.32211</td><td style=\"text-align: right;\">    1.05988 </td><td style=\"text-align: right;\">     0.582305</td><td style=\"text-align: right;\">  1.85392e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_6c66e650</td><td>TERMINATED</td><td>172.26.215.93:166877</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_5040</td><td>[&#x27;force&#x27;, &#x27;x_co_c280</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">5</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000146349</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        46.4506 </td><td style=\"text-align: right;\">    0.531245</td><td style=\"text-align: right;\">     0.310967</td><td style=\"text-align: right;\">  1.16738e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_096272f9</td><td>TERMINATED</td><td>172.26.215.93:167108</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_bdc0</td><td>[&#x27;force&#x27;, &#x27;x_co_b840</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.000645673</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         5.28859</td><td style=\"text-align: right;\">    0.562338</td><td style=\"text-align: right;\">     0.312748</td><td style=\"text-align: right;\">  1.26079e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_2ede7356</td><td>TERMINATED</td><td>172.26.215.93:167323</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_e940</td><td>[&#x27;force&#x27;, &#x27;x_co_e9c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adam   </td><td style=\"text-align: right;\">        0.000620764</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         5.73593</td><td style=\"text-align: right;\">    0.531115</td><td style=\"text-align: right;\">     0.312309</td><td style=\"text-align: right;\">  1.11686e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_6dc65d0f</td><td>TERMINATED</td><td>172.26.215.93:167548</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_f140</td><td>[&#x27;force&#x27;, &#x27;x_co_3780</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000144191</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       487.447  </td><td style=\"text-align: right;\">    0.300023</td><td style=\"text-align: right;\">     0.206259</td><td style=\"text-align: right;\">  3.86573e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e3d65c71</td><td>TERMINATED</td><td>172.26.215.93:167774</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_52c0</td><td>[&#x27;force&#x27;, &#x27;x_co_4b00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000145761</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        42.268  </td><td style=\"text-align: right;\">    0.529472</td><td style=\"text-align: right;\">     0.305107</td><td style=\"text-align: right;\">  1.16434e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_64cfa6a4</td><td>TERMINATED</td><td>172.26.215.93:168002</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_6080</td><td>[&#x27;force&#x27;, &#x27;x_co_cb80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00257313 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.8141 </td><td style=\"text-align: right;\">    0.384397</td><td style=\"text-align: right;\">     0.316687</td><td style=\"text-align: right;\">  2.86508e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_fcd00d9b</td><td>TERMINATED</td><td>172.26.215.93:168283</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_5f40</td><td>[&#x27;force&#x27;, &#x27;x_co_4500</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00237217 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        11.3221 </td><td style=\"text-align: right;\">    0.387207</td><td style=\"text-align: right;\">     0.311903</td><td style=\"text-align: right;\">  3.94989e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_85129490</td><td>TERMINATED</td><td>172.26.215.93:168468</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6f00</td><td>[&#x27;force&#x27;, &#x27;x_co_7a80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        1.08364e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.14952</td><td style=\"text-align: right;\">    0.574607</td><td style=\"text-align: right;\">     0.354529</td><td style=\"text-align: right;\">  1.03907e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_cf3dcb02</td><td>TERMINATED</td><td>172.26.215.93:168709</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_5ac0</td><td>[&#x27;force&#x27;, &#x27;x_co_7500</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.0012568  </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       108.932  </td><td style=\"text-align: right;\">    0.328374</td><td style=\"text-align: right;\">     0.21013 </td><td style=\"text-align: right;\">  6.43191e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e93ab1cc</td><td>TERMINATED</td><td>172.26.215.93:168941</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_dd00</td><td>[&#x27;force&#x27;, &#x27;x_co_d5c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">3</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00126558 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         4.01892</td><td style=\"text-align: right;\">    0.550209</td><td style=\"text-align: right;\">     0.31416 </td><td style=\"text-align: right;\">  1.23946e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_a76f516b</td><td>TERMINATED</td><td>172.26.215.93:169182</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_ee80</td><td>[&#x27;force&#x27;, &#x27;x_co_9a00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">3</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.0003497  </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.50164</td><td style=\"text-align: right;\">    0.865041</td><td style=\"text-align: right;\">     0.517493</td><td style=\"text-align: right;\">  1.60672e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_a86dc0e6</td><td>TERMINATED</td><td>172.26.215.93:169398</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_8780</td><td>[&#x27;force&#x27;, &#x27;x_co_b800</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.000354281</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.25728</td><td style=\"text-align: right;\">    1.16172 </td><td style=\"text-align: right;\">     0.623851</td><td style=\"text-align: right;\">  2.254e+15  </td></tr>\n",
       "<tr><td>FSR_Trainable_54d09832</td><td>TERMINATED</td><td>172.26.215.93:169628</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_36c0</td><td>[&#x27;force&#x27;, &#x27;x_co_0640</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">4</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.000954818</td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.23724</td><td style=\"text-align: right;\">    3.21462 </td><td style=\"text-align: right;\">     1.99633 </td><td style=\"text-align: right;\"> 76.4583     </td></tr>\n",
       "<tr><td>FSR_Trainable_c3d55401</td><td>TERMINATED</td><td>172.26.215.93:169861</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_c3c0</td><td>[&#x27;force&#x27;, &#x27;x_co_1180</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 16</td><td style=\"text-align: right;\">2</td><td>torch.optim.SGD    </td><td style=\"text-align: right;\">        0.00101683 </td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.75447</td><td style=\"text-align: right;\">    3.33447 </td><td style=\"text-align: right;\">     2.02869 </td><td style=\"text-align: right;\"> 57.2239     </td></tr>\n",
       "<tr><td>FSR_Trainable_8269d25a</td><td>TERMINATED</td><td>172.26.215.93:170092</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_9c00</td><td>[&#x27;force&#x27;, &#x27;x_co_af80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00172433 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       409.341  </td><td style=\"text-align: right;\">    0.265562</td><td style=\"text-align: right;\">     0.176278</td><td style=\"text-align: right;\">  3.45867e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_50d0539b</td><td>TERMINATED</td><td>172.26.215.93:170363</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_0f40</td><td>[&#x27;force&#x27;, &#x27;x_co_2240</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00167222 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       242.148  </td><td style=\"text-align: right;\">    0.240902</td><td style=\"text-align: right;\">     0.154997</td><td style=\"text-align: right;\">  3.51248e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_a2c73c61</td><td>TERMINATED</td><td>172.26.215.93:170747</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_0d40</td><td>[&#x27;force&#x27;, &#x27;x_co_9580</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00156066 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       241.787  </td><td style=\"text-align: right;\">    0.242501</td><td style=\"text-align: right;\">     0.15544 </td><td style=\"text-align: right;\">  3.8003e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_07df2b2d</td><td>TERMINATED</td><td>172.26.215.93:170984</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_fa40</td><td>[&#x27;force&#x27;, &#x27;x_co_5280</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00178778 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       237.421  </td><td style=\"text-align: right;\">    0.24402 </td><td style=\"text-align: right;\">     0.160239</td><td style=\"text-align: right;\">  3.47883e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e1cb6d85</td><td>TERMINATED</td><td>172.26.215.93:171215</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>mean  </td><td>[&#x27;FSR_for_force_86c0</td><td>[&#x27;force&#x27;, &#x27;x_co_a300</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        9.83346e-05</td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       244.771  </td><td style=\"text-align: right;\">    0.245927</td><td style=\"text-align: right;\">     0.158031</td><td style=\"text-align: right;\">  3.64109e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_56b1e2c2</td><td>TERMINATED</td><td>172.26.215.93:171497</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_e8c0</td><td>[&#x27;force&#x27;, &#x27;x_co_fb00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td>torch.optim.NAdam  </td><td style=\"text-align: right;\">        0.00190865 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">       322.008  </td><td style=\"text-align: right;\">    0.363163</td><td style=\"text-align: right;\">     0.236688</td><td style=\"text-align: right;\">  5.39167e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_f73cb3c8</td><td>TERMINATED</td><td>172.26.215.93:171806</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_b980</td><td>[&#x27;force&#x27;, &#x27;x_co_b780</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00186752 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       299.854  </td><td style=\"text-align: right;\">    0.259048</td><td style=\"text-align: right;\">     0.1685  </td><td style=\"text-align: right;\">  3.65596e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_22748d08</td><td>TERMINATED</td><td>172.26.215.93:172041</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_e880</td><td>[&#x27;force&#x27;, &#x27;x_co_f140</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00177078 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       307.559  </td><td style=\"text-align: right;\">    0.242283</td><td style=\"text-align: right;\">     0.158894</td><td style=\"text-align: right;\">  3.3736e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_a92c1ed3</td><td>TERMINATED</td><td>172.26.215.93:172278</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_a500</td><td>[&#x27;force&#x27;, &#x27;x_co_ba00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00353261 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       231.388  </td><td style=\"text-align: right;\">    0.25544 </td><td style=\"text-align: right;\">     0.168766</td><td style=\"text-align: right;\">  3.58888e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_73b6e975</td><td>TERMINATED</td><td>172.26.215.93:172682</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_db80</td><td>[&#x27;force&#x27;, &#x27;x_co_8480</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00349711 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       197.969  </td><td style=\"text-align: right;\">    0.242702</td><td style=\"text-align: right;\">     0.15576 </td><td style=\"text-align: right;\">  3.5863e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_736b439f</td><td>TERMINATED</td><td>172.26.215.93:172969</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_a440</td><td>[&#x27;force&#x27;, &#x27;x_co_0600</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00303121 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       204.575  </td><td style=\"text-align: right;\">    0.278062</td><td style=\"text-align: right;\">     0.163354</td><td style=\"text-align: right;\">  5.20005e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_4bf5a3a3</td><td>TERMINATED</td><td>172.26.215.93:173167</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_9240</td><td>[&#x27;force&#x27;, &#x27;x_co_af80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00300267 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       254.823  </td><td style=\"text-align: right;\">    0.263599</td><td style=\"text-align: right;\">     0.160939</td><td style=\"text-align: right;\">  4.56724e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_bf244b87</td><td>TERMINATED</td><td>172.26.215.93:173444</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_b180</td><td>[&#x27;force&#x27;, &#x27;x_co_5f40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00318661 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">        75.5416 </td><td style=\"text-align: right;\">    0.32926 </td><td style=\"text-align: right;\">     0.184998</td><td style=\"text-align: right;\">  6.94395e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_754a29b9</td><td>TERMINATED</td><td>172.26.215.93:173730</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_b900</td><td>[&#x27;force&#x27;, &#x27;x_co_a740</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00351245 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       266.416  </td><td style=\"text-align: right;\">    0.257181</td><td style=\"text-align: right;\">     0.157077</td><td style=\"text-align: right;\">  4.26839e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_0d612610</td><td>TERMINATED</td><td>172.26.215.93:173912</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3b80</td><td>[&#x27;force&#x27;, &#x27;x_co_3180</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00328828 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       266.735  </td><td style=\"text-align: right;\">    0.255646</td><td style=\"text-align: right;\">     0.169149</td><td style=\"text-align: right;\">  3.68537e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_29c08e0a</td><td>TERMINATED</td><td>172.26.215.93:174239</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_8240</td><td>[&#x27;force&#x27;, &#x27;x_co_1bc0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00330439 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       265.116  </td><td style=\"text-align: right;\">    0.234703</td><td style=\"text-align: right;\">     0.158547</td><td style=\"text-align: right;\">  3.15284e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_596c93b0</td><td>TERMINATED</td><td>172.26.215.93:174505</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6a80</td><td>[&#x27;force&#x27;, &#x27;x_co_45c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00139181 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       209.907  </td><td style=\"text-align: right;\">    0.254582</td><td style=\"text-align: right;\">     0.159398</td><td style=\"text-align: right;\">  3.76872e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_1636580a</td><td>TERMINATED</td><td>172.26.215.93:174813</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_38c0</td><td>[&#x27;force&#x27;, &#x27;x_co_1900</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00746345 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       207.322  </td><td style=\"text-align: right;\">    0.23984 </td><td style=\"text-align: right;\">     0.16214 </td><td style=\"text-align: right;\">  3.1293e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_36c37afe</td><td>TERMINATED</td><td>172.26.215.93:175019</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6880</td><td>[&#x27;force&#x27;, &#x27;x_co_cec0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.0071241  </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       130.424  </td><td style=\"text-align: right;\">    0.265331</td><td style=\"text-align: right;\">     0.168861</td><td style=\"text-align: right;\">  4.02287e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_757aa8c1</td><td>TERMINATED</td><td>172.26.215.93:175329</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_b200</td><td>[&#x27;force&#x27;, &#x27;x_co_8900</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00678321 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       133.848  </td><td style=\"text-align: right;\">    0.258774</td><td style=\"text-align: right;\">     0.163622</td><td style=\"text-align: right;\">  4.03876e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_dc87d342</td><td>TERMINATED</td><td>172.26.215.93:175533</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_1900</td><td>[&#x27;force&#x27;, &#x27;x_co_3d00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00741017 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.69606</td><td style=\"text-align: right;\">    5.28168 </td><td style=\"text-align: right;\">     5.86798 </td><td style=\"text-align: right;\">  4.43004e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_bec324cd</td><td>TERMINATED</td><td>172.26.215.93:175760</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_b080</td><td>[&#x27;force&#x27;, &#x27;x_co_9e00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00676759 </td><td>sklearn.preproc_8b10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.39563</td><td style=\"text-align: right;\">    5.9235  </td><td style=\"text-align: right;\">     6.37353 </td><td style=\"text-align: right;\">  4.17242e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_6c3cd3ce</td><td>TERMINATED</td><td>172.26.215.93:175993</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_5080</td><td>[&#x27;force&#x27;, &#x27;x_co_7140</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00126411 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       209.845  </td><td style=\"text-align: right;\">    0.246869</td><td style=\"text-align: right;\">     0.158518</td><td style=\"text-align: right;\">  3.57334e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_45da30e1</td><td>TERMINATED</td><td>172.26.215.93:176250</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_a680</td><td>[&#x27;force&#x27;, &#x27;x_co_bb00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00423113 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       215.541  </td><td style=\"text-align: right;\">    0.265998</td><td style=\"text-align: right;\">     0.165731</td><td style=\"text-align: right;\">  4.23422e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_f43b6b94</td><td>TERMINATED</td><td>172.26.215.93:176525</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_be80</td><td>[&#x27;force&#x27;, &#x27;x_co_8f00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00140287 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       317.369  </td><td style=\"text-align: right;\">    0.24329 </td><td style=\"text-align: right;\">     0.160977</td><td style=\"text-align: right;\">  3.36313e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_d54316cd</td><td>TERMINATED</td><td>172.26.215.93:176761</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_9500</td><td>[&#x27;force&#x27;, &#x27;x_co_fa40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00414195 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       173.852  </td><td style=\"text-align: right;\">    0.260698</td><td style=\"text-align: right;\">     0.168531</td><td style=\"text-align: right;\">  3.7615e+14 </td></tr>\n",
       "<tr><td>FSR_Trainable_bf07bd58</td><td>TERMINATED</td><td>172.26.215.93:177078</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_a600</td><td>[&#x27;force&#x27;, &#x27;x_co_3480</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00459733 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        47.5248 </td><td style=\"text-align: right;\">    0.343551</td><td style=\"text-align: right;\">     0.193439</td><td style=\"text-align: right;\">  6.98457e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_e8d5cf7d</td><td>TERMINATED</td><td>172.26.215.93:177295</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_5040</td><td>[&#x27;force&#x27;, &#x27;x_co_8ec0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00144178 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       314.132  </td><td style=\"text-align: right;\">    0.283626</td><td style=\"text-align: right;\">     0.166628</td><td style=\"text-align: right;\">  5.22406e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_a5c83218</td><td>TERMINATED</td><td>172.26.215.93:177565</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_4580</td><td>[&#x27;force&#x27;, &#x27;x_co_9c40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00145209 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       257.122  </td><td style=\"text-align: right;\">    0.250711</td><td style=\"text-align: right;\">     0.15804 </td><td style=\"text-align: right;\">  3.933e+14  </td></tr>\n",
       "<tr><td>FSR_Trainable_7d289c93</td><td>TERMINATED</td><td>172.26.215.93:177749</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6f00</td><td>[&#x27;force&#x27;, &#x27;x_co_5f80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00137173 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       311.048  </td><td style=\"text-align: right;\">    0.248798</td><td style=\"text-align: right;\">     0.158094</td><td style=\"text-align: right;\">  3.95381e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_be58cc31</td><td>TERMINATED</td><td>172.26.215.93:178087</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_bf00</td><td>[&#x27;force&#x27;, &#x27;x_co_ae80</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00135409 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       310.361  </td><td style=\"text-align: right;\">    0.270041</td><td style=\"text-align: right;\">     0.166444</td><td style=\"text-align: right;\">  4.30277e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_072f68bb</td><td>TERMINATED</td><td>172.26.215.93:178417</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6f40</td><td>[&#x27;force&#x27;, &#x27;x_co_6200</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00130362 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        53.3443 </td><td style=\"text-align: right;\">    0.330567</td><td style=\"text-align: right;\">     0.191538</td><td style=\"text-align: right;\">  6.42107e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_310307c2</td><td>TERMINATED</td><td>172.26.215.93:178598</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_4580</td><td>[&#x27;force&#x27;, &#x27;x_co_43c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000775011</td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.64235</td><td style=\"text-align: right;\">    2.84977 </td><td style=\"text-align: right;\">     1.68868 </td><td style=\"text-align: right;\"> 92.5043     </td></tr>\n",
       "<tr><td>FSR_Trainable_454e8493</td><td>TERMINATED</td><td>172.26.215.93:178866</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3540</td><td>[&#x27;force&#x27;, &#x27;x_co_1880</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">2</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.000752356</td><td>sklearn.preproc_89f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.50131</td><td style=\"text-align: right;\">    2.69459 </td><td style=\"text-align: right;\">     1.66979 </td><td style=\"text-align: right;\"> 56.8384     </td></tr>\n",
       "<tr><td>FSR_Trainable_cb03759c</td><td>TERMINATED</td><td>172.26.215.93:179096</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3480</td><td>[&#x27;force&#x27;, &#x27;x_co_04c0</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00111818 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       143.249  </td><td style=\"text-align: right;\">    0.240635</td><td style=\"text-align: right;\">     0.156029</td><td style=\"text-align: right;\">  3.36901e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_aa13815a</td><td>TERMINATED</td><td>172.26.215.93:179320</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_cbc0</td><td>[&#x27;force&#x27;, &#x27;x_co_db00</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00119413 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       223.221  </td><td style=\"text-align: right;\">    0.247034</td><td style=\"text-align: right;\">     0.154865</td><td style=\"text-align: right;\">  3.78946e+14</td></tr>\n",
       "<tr><td>FSR_Trainable_f1fd40db</td><td>TERMINATED</td><td>172.26.215.93:179529</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6840</td><td>[&#x27;force&#x27;, &#x27;x_co_5240</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00219855 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         3.08215</td><td style=\"text-align: right;\">    0.503107</td><td style=\"text-align: right;\">     0.296678</td><td style=\"text-align: right;\">  1.07353e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_bcae2507</td><td>TERMINATED</td><td>172.26.215.93:179776</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_1d00</td><td>[&#x27;force&#x27;, &#x27;x_co_6e40</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">  8</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.Adagrad</td><td style=\"text-align: right;\">        0.00105376 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.46933</td><td style=\"text-align: right;\">    0.75476 </td><td style=\"text-align: right;\">     0.401855</td><td style=\"text-align: right;\">  1.75986e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_4e53941a</td><td>TERMINATED</td><td>172.26.215.93:180006</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_6300</td><td>[&#x27;force&#x27;, &#x27;x_co_4440</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00117892 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.09515</td><td style=\"text-align: right;\">    0.668645</td><td style=\"text-align: right;\">     0.356113</td><td style=\"text-align: right;\">  1.64768e+15</td></tr>\n",
       "<tr><td>FSR_Trainable_c3c06fa4</td><td>TERMINATED</td><td>172.26.215.93:180263</td><td>torch.nn.MSELoss</td><td>fsr_data.get_in_8db0</td><td>sklearn.impute._7cd0</td><td>median</td><td>[&#x27;FSR_for_force_3080</td><td>[&#x27;force&#x27;, &#x27;x_co_2800</td><td>fsr_model.CNN_LSTM</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">1</td><td>torch.optim.RAdam  </td><td style=\"text-align: right;\">        0.00146738 </td><td>sklearn.preproc_8ed0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.69088</td><td style=\"text-align: right;\">    0.64178 </td><td style=\"text-align: right;\">     0.351875</td><td style=\"text-align: right;\">  1.59581e+15</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 23:25:43,873\tINFO wandb.py:320 -- Already logged into W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mae_coord</th><th style=\"text-align: right;\">  mae_force</th><th style=\"text-align: right;\">  mape_coord</th><th style=\"text-align: right;\">  mape_force</th><th style=\"text-align: right;\">   metric</th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  rmse_coord</th><th style=\"text-align: right;\">  rmse_force</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  tmae_coord</th><th style=\"text-align: right;\">  tmae_force</th><th style=\"text-align: right;\">  tmape_coord</th><th style=\"text-align: right;\">  tmape_force</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  trmse_coord</th><th style=\"text-align: right;\">  trmse_force</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FSR_Trainable_072f68bb</td><td>2023-08-11_00-23-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.36296</td><td style=\"text-align: right;\">    777.872</td><td style=\"text-align: right;\">     1.21745</td><td style=\"text-align: right;\"> 1.28426e+18</td><td style=\"text-align: right;\"> 0.705655</td><td>172.26.215.93</td><td style=\"text-align: right;\">178417</td><td style=\"text-align: right;\">     2.60789</td><td style=\"text-align: right;\">     499.047</td><td style=\"text-align: right;\">            53.3443 </td><td style=\"text-align: right;\">          3.33996 </td><td style=\"text-align: right;\">      53.3443 </td><td style=\"text-align: right;\"> 1691681008</td><td style=\"text-align: right;\">    1.13725 </td><td style=\"text-align: right;\">    0.330567</td><td style=\"text-align: right;\">  6.38619e+13</td><td style=\"text-align: right;\">  6.42107e+14</td><td style=\"text-align: right;\">                  16</td><td>072f68bb  </td><td style=\"text-align: right;\">     0.514117</td><td style=\"text-align: right;\">     0.191538</td></tr>\n",
       "<tr><td>FSR_Trainable_07df2b2d</td><td>2023-08-10_23-57-42</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.91688</td><td style=\"text-align: right;\">    603.15 </td><td style=\"text-align: right;\">     1.15364</td><td style=\"text-align: right;\"> 6.93051e+17</td><td style=\"text-align: right;\"> 0.654152</td><td>172.26.215.93</td><td style=\"text-align: right;\">170984</td><td style=\"text-align: right;\">     2.50696</td><td style=\"text-align: right;\">     436.274</td><td style=\"text-align: right;\">           237.421  </td><td style=\"text-align: right;\">          2.13235 </td><td style=\"text-align: right;\">     237.421  </td><td style=\"text-align: right;\"> 1691679462</td><td style=\"text-align: right;\">    1.04289 </td><td style=\"text-align: right;\">    0.24402 </td><td style=\"text-align: right;\">  7.61953e+13</td><td style=\"text-align: right;\">  3.47883e+14</td><td style=\"text-align: right;\">                 100</td><td>07df2b2d  </td><td style=\"text-align: right;\">     0.493914</td><td style=\"text-align: right;\">     0.160239</td></tr>\n",
       "<tr><td>FSR_Trainable_096272f9</td><td>2023-08-10_23-44-31</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    8.63391</td><td style=\"text-align: right;\">   1498.85 </td><td style=\"text-align: right;\">     1.49474</td><td style=\"text-align: right;\"> 3.00411e+18</td><td style=\"text-align: right;\"> 0.977853</td><td>172.26.215.93</td><td style=\"text-align: right;\">167108</td><td style=\"text-align: right;\">     3.34404</td><td style=\"text-align: right;\">     949.741</td><td style=\"text-align: right;\">             5.28859</td><td style=\"text-align: right;\">          2.40362 </td><td style=\"text-align: right;\">       5.28859</td><td style=\"text-align: right;\"> 1691678671</td><td style=\"text-align: right;\">    1.82469 </td><td style=\"text-align: right;\">    0.562338</td><td style=\"text-align: right;\">  7.2004e+13 </td><td style=\"text-align: right;\">  1.26079e+15</td><td style=\"text-align: right;\">                   2</td><td>096272f9  </td><td style=\"text-align: right;\">     0.665104</td><td style=\"text-align: right;\">     0.312748</td></tr>\n",
       "<tr><td>FSR_Trainable_0d612610</td><td>2023-08-11_00-09-52</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.12986</td><td style=\"text-align: right;\">    612.802</td><td style=\"text-align: right;\">     1.12797</td><td style=\"text-align: right;\"> 6.95111e+17</td><td style=\"text-align: right;\"> 0.673926</td><td>172.26.215.93</td><td style=\"text-align: right;\">173912</td><td style=\"text-align: right;\">     2.60204</td><td style=\"text-align: right;\">     440.069</td><td style=\"text-align: right;\">           266.735  </td><td style=\"text-align: right;\">          2.75075 </td><td style=\"text-align: right;\">     266.735  </td><td style=\"text-align: right;\"> 1691680192</td><td style=\"text-align: right;\">    1.08718 </td><td style=\"text-align: right;\">    0.255646</td><td style=\"text-align: right;\">  6.44009e+13</td><td style=\"text-align: right;\">  3.68537e+14</td><td style=\"text-align: right;\">                 100</td><td>0d612610  </td><td style=\"text-align: right;\">     0.504777</td><td style=\"text-align: right;\">     0.169149</td></tr>\n",
       "<tr><td>FSR_Trainable_0daa8344</td><td>2023-08-10_23-43-52</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.85389</td><td style=\"text-align: right;\">    771.655</td><td style=\"text-align: right;\">     1.25699</td><td style=\"text-align: right;\"> 8.61844e+17</td><td style=\"text-align: right;\"> 0.728705</td><td>172.26.215.93</td><td style=\"text-align: right;\">160885</td><td style=\"text-align: right;\">     2.7996 </td><td style=\"text-align: right;\">     581.253</td><td style=\"text-align: right;\">           474.341  </td><td style=\"text-align: right;\">          5.00901 </td><td style=\"text-align: right;\">     474.341  </td><td style=\"text-align: right;\"> 1691678632</td><td style=\"text-align: right;\">    1.21466 </td><td style=\"text-align: right;\">    0.289985</td><td style=\"text-align: right;\">  7.17541e+13</td><td style=\"text-align: right;\">  3.7867e+14 </td><td style=\"text-align: right;\">                 100</td><td>0daa8344  </td><td style=\"text-align: right;\">     0.532839</td><td style=\"text-align: right;\">     0.195866</td></tr>\n",
       "<tr><td>FSR_Trainable_102a7f72</td><td>2023-08-10_23-27-33</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    3.78615</td><td style=\"text-align: right;\">   1443.46 </td><td style=\"text-align: right;\">     1.10471</td><td style=\"text-align: right;\"> 9.08805e+08</td><td style=\"text-align: right;\"> 6.49708 </td><td>172.26.215.93</td><td style=\"text-align: right;\">156286</td><td style=\"text-align: right;\">     2.36548</td><td style=\"text-align: right;\">     947.571</td><td style=\"text-align: right;\">            93.1655 </td><td style=\"text-align: right;\">          2.80451 </td><td style=\"text-align: right;\">      93.1655 </td><td style=\"text-align: right;\"> 1691677653</td><td style=\"text-align: right;\">    7.22777 </td><td style=\"text-align: right;\">    3.48836 </td><td style=\"text-align: right;\">  5.49108e+14</td><td style=\"text-align: right;\"> 19.578      </td><td style=\"text-align: right;\">                  32</td><td>102a7f72  </td><td style=\"text-align: right;\">     4.48776 </td><td style=\"text-align: right;\">     2.00933 </td></tr>\n",
       "<tr><td>FSR_Trainable_10656ea1</td><td>2023-08-10_23-26-31</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.9502 </td><td style=\"text-align: right;\">   1172.18 </td><td style=\"text-align: right;\">     1.12039</td><td style=\"text-align: right;\"> 3.83478e+16</td><td style=\"text-align: right;\">55.1395  </td><td>172.26.215.93</td><td style=\"text-align: right;\">157005</td><td style=\"text-align: right;\">     2.62324</td><td style=\"text-align: right;\">     966.018</td><td style=\"text-align: right;\">             4.97302</td><td style=\"text-align: right;\">          4.97302 </td><td style=\"text-align: right;\">       4.97302</td><td style=\"text-align: right;\"> 1691677591</td><td style=\"text-align: right;\">   45.3279  </td><td style=\"text-align: right;\">    6.08244 </td><td style=\"text-align: right;\">  7.08617e+15</td><td style=\"text-align: right;\">  1.92657e+15</td><td style=\"text-align: right;\">                   1</td><td>10656ea1  </td><td style=\"text-align: right;\">    48.0736  </td><td style=\"text-align: right;\">     7.06589 </td></tr>\n",
       "<tr><td>FSR_Trainable_1636580a</td><td>2023-08-11_00-13-40</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.12711</td><td style=\"text-align: right;\">    605.255</td><td style=\"text-align: right;\">     1.10189</td><td style=\"text-align: right;\"> 6.48555e+17</td><td style=\"text-align: right;\"> 0.66712 </td><td>172.26.215.93</td><td style=\"text-align: right;\">174813</td><td style=\"text-align: right;\">     2.61539</td><td style=\"text-align: right;\">     445.241</td><td style=\"text-align: right;\">           207.322  </td><td style=\"text-align: right;\">          2.99687 </td><td style=\"text-align: right;\">     207.322  </td><td style=\"text-align: right;\"> 1691680420</td><td style=\"text-align: right;\">    1.08282 </td><td style=\"text-align: right;\">    0.23984 </td><td style=\"text-align: right;\">  6.37851e+13</td><td style=\"text-align: right;\">  3.1293e+14 </td><td style=\"text-align: right;\">                 100</td><td>1636580a  </td><td style=\"text-align: right;\">     0.50498 </td><td style=\"text-align: right;\">     0.16214 </td></tr>\n",
       "<tr><td>FSR_Trainable_1c248ea4</td><td>2023-08-10_23-42-20</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   27.8712 </td><td style=\"text-align: right;\">   1508.88 </td><td style=\"text-align: right;\">     4.40688</td><td style=\"text-align: right;\"> 2.2017e+18 </td><td style=\"text-align: right;\"> 2.35812 </td><td>172.26.215.93</td><td style=\"text-align: right;\">165023</td><td style=\"text-align: right;\">     8.97485</td><td style=\"text-align: right;\">    1007.52 </td><td style=\"text-align: right;\">             2.69863</td><td style=\"text-align: right;\">          2.69863 </td><td style=\"text-align: right;\">       2.69863</td><td style=\"text-align: right;\"> 1691678540</td><td style=\"text-align: right;\">    6.26571 </td><td style=\"text-align: right;\">    0.632761</td><td style=\"text-align: right;\">  2.4314e+13 </td><td style=\"text-align: right;\">  1.1283e+15 </td><td style=\"text-align: right;\">                   1</td><td>1c248ea4  </td><td style=\"text-align: right;\">     1.99205 </td><td style=\"text-align: right;\">     0.366074</td></tr>\n",
       "<tr><td>FSR_Trainable_22748d08</td><td>2023-08-11_00-03-15</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.09703</td><td style=\"text-align: right;\">    582.822</td><td style=\"text-align: right;\">     1.17097</td><td style=\"text-align: right;\"> 6.13392e+17</td><td style=\"text-align: right;\"> 0.667245</td><td>172.26.215.93</td><td style=\"text-align: right;\">172041</td><td style=\"text-align: right;\">     2.59882</td><td style=\"text-align: right;\">     424.775</td><td style=\"text-align: right;\">           307.559  </td><td style=\"text-align: right;\">          2.83908 </td><td style=\"text-align: right;\">     307.559  </td><td style=\"text-align: right;\"> 1691679795</td><td style=\"text-align: right;\">    1.07997 </td><td style=\"text-align: right;\">    0.242283</td><td style=\"text-align: right;\">  6.64261e+13</td><td style=\"text-align: right;\">  3.3736e+14 </td><td style=\"text-align: right;\">                 100</td><td>22748d08  </td><td style=\"text-align: right;\">     0.508351</td><td style=\"text-align: right;\">     0.158894</td></tr>\n",
       "<tr><td>FSR_Trainable_27422225</td><td>2023-08-10_23-39-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.8053 </td><td style=\"text-align: right;\">   1164.27 </td><td style=\"text-align: right;\">     1.55026</td><td style=\"text-align: right;\"> 1.27309e+18</td><td style=\"text-align: right;\"> 0.875216</td><td>172.26.215.93</td><td style=\"text-align: right;\">163201</td><td style=\"text-align: right;\">     2.7432 </td><td style=\"text-align: right;\">     962.782</td><td style=\"text-align: right;\">            17.3004 </td><td style=\"text-align: right;\">          7.83127 </td><td style=\"text-align: right;\">      17.3004 </td><td style=\"text-align: right;\"> 1691678386</td><td style=\"text-align: right;\">    1.23365 </td><td style=\"text-align: right;\">    0.39266 </td><td style=\"text-align: right;\">  9.02471e+13</td><td style=\"text-align: right;\">  3.45392e+14</td><td style=\"text-align: right;\">                   2</td><td>27422225  </td><td style=\"text-align: right;\">     0.557216</td><td style=\"text-align: right;\">     0.317999</td></tr>\n",
       "<tr><td>FSR_Trainable_27be0a03</td><td>2023-08-10_23-44-02</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   26.9699 </td><td style=\"text-align: right;\">   3176.17 </td><td style=\"text-align: right;\">     4.11658</td><td style=\"text-align: right;\"> 4.9198e+18 </td><td style=\"text-align: right;\"> 2.54253 </td><td>172.26.215.93</td><td style=\"text-align: right;\">166648</td><td style=\"text-align: right;\">     8.60395</td><td style=\"text-align: right;\">    2034.62 </td><td style=\"text-align: right;\">             2.32211</td><td style=\"text-align: right;\">          2.32211 </td><td style=\"text-align: right;\">       2.32211</td><td style=\"text-align: right;\"> 1691678642</td><td style=\"text-align: right;\">    6.12897 </td><td style=\"text-align: right;\">    1.05988 </td><td style=\"text-align: right;\">  4.77332e+13</td><td style=\"text-align: right;\">  1.85392e+15</td><td style=\"text-align: right;\">                   1</td><td>27be0a03  </td><td style=\"text-align: right;\">     1.96022 </td><td style=\"text-align: right;\">     0.582305</td></tr>\n",
       "<tr><td>FSR_Trainable_28642b0a</td><td>2023-08-10_23-35-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    4.97571</td><td style=\"text-align: right;\">   1429.93 </td><td style=\"text-align: right;\">     1.24618</td><td style=\"text-align: right;\"> 2.77805e+18</td><td style=\"text-align: right;\"> 0.833939</td><td>172.26.215.93</td><td style=\"text-align: right;\">160652</td><td style=\"text-align: right;\">     2.57443</td><td style=\"text-align: right;\">     949.133</td><td style=\"text-align: right;\">            39.6005 </td><td style=\"text-align: right;\">          5.35054 </td><td style=\"text-align: right;\">      39.6005 </td><td style=\"text-align: right;\"> 1691678146</td><td style=\"text-align: right;\">    1.08903 </td><td style=\"text-align: right;\">    0.51655 </td><td style=\"text-align: right;\">  8.25085e+13</td><td style=\"text-align: right;\">  1.08122e+15</td><td style=\"text-align: right;\">                   8</td><td>28642b0a  </td><td style=\"text-align: right;\">     0.529401</td><td style=\"text-align: right;\">     0.304539</td></tr>\n",
       "<tr><td>FSR_Trainable_29c08e0a</td><td>2023-08-11_00-11-19</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.05953</td><td style=\"text-align: right;\">    586.904</td><td style=\"text-align: right;\">     1.13316</td><td style=\"text-align: right;\"> 6.11887e+17</td><td style=\"text-align: right;\"> 0.660481</td><td>172.26.215.93</td><td style=\"text-align: right;\">174239</td><td style=\"text-align: right;\">     2.59115</td><td style=\"text-align: right;\">     438.32 </td><td style=\"text-align: right;\">           265.116  </td><td style=\"text-align: right;\">          3.24051 </td><td style=\"text-align: right;\">     265.116  </td><td style=\"text-align: right;\"> 1691680279</td><td style=\"text-align: right;\">    1.07259 </td><td style=\"text-align: right;\">    0.234703</td><td style=\"text-align: right;\">  6.45032e+13</td><td style=\"text-align: right;\">  3.15284e+14</td><td style=\"text-align: right;\">                 100</td><td>29c08e0a  </td><td style=\"text-align: right;\">     0.501934</td><td style=\"text-align: right;\">     0.158547</td></tr>\n",
       "<tr><td>FSR_Trainable_2ede7356</td><td>2023-08-10_23-44-43</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    8.26093</td><td style=\"text-align: right;\">   1434.79 </td><td style=\"text-align: right;\">     1.53348</td><td style=\"text-align: right;\"> 2.72936e+18</td><td style=\"text-align: right;\"> 0.965019</td><td>172.26.215.93</td><td style=\"text-align: right;\">167323</td><td style=\"text-align: right;\">     3.23655</td><td style=\"text-align: right;\">     943.362</td><td style=\"text-align: right;\">             5.73593</td><td style=\"text-align: right;\">          2.71496 </td><td style=\"text-align: right;\">       5.73593</td><td style=\"text-align: right;\"> 1691678683</td><td style=\"text-align: right;\">    1.74711 </td><td style=\"text-align: right;\">    0.531115</td><td style=\"text-align: right;\">  7.85302e+13</td><td style=\"text-align: right;\">  1.11686e+15</td><td style=\"text-align: right;\">                   2</td><td>2ede7356  </td><td style=\"text-align: right;\">     0.65271 </td><td style=\"text-align: right;\">     0.312309</td></tr>\n",
       "<tr><td>FSR_Trainable_306a3737</td><td>2023-08-10_23-26-10</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.33431</td><td style=\"text-align: right;\">   1472.14 </td><td style=\"text-align: right;\">     1.38568</td><td style=\"text-align: right;\"> 1.06287e+09</td><td style=\"text-align: right;\"> 7.12616 </td><td>172.26.215.93</td><td style=\"text-align: right;\">156530</td><td style=\"text-align: right;\">     2.51624</td><td style=\"text-align: right;\">     945.339</td><td style=\"text-align: right;\">             2.47301</td><td style=\"text-align: right;\">          1.04157 </td><td style=\"text-align: right;\">       2.47301</td><td style=\"text-align: right;\"> 1691677570</td><td style=\"text-align: right;\">    9.75127 </td><td style=\"text-align: right;\">    4.00419 </td><td style=\"text-align: right;\">  4.2244e+15 </td><td style=\"text-align: right;\">255.578      </td><td style=\"text-align: right;\">                   2</td><td>306a3737  </td><td style=\"text-align: right;\">     4.88079 </td><td style=\"text-align: right;\">     2.24537 </td></tr>\n",
       "<tr><td>FSR_Trainable_310307c2</td><td>2023-08-11_00-22-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.20653</td><td style=\"text-align: right;\">   1141.6  </td><td style=\"text-align: right;\">     1.10089</td><td style=\"text-align: right;\"> 6.1447e+08 </td><td style=\"text-align: right;\"> 6.15373 </td><td>172.26.215.93</td><td style=\"text-align: right;\">178598</td><td style=\"text-align: right;\">     2.42268</td><td style=\"text-align: right;\">     739.056</td><td style=\"text-align: right;\">             4.64235</td><td style=\"text-align: right;\">          4.64235 </td><td style=\"text-align: right;\">       4.64235</td><td style=\"text-align: right;\"> 1691680966</td><td style=\"text-align: right;\">    7.7325  </td><td style=\"text-align: right;\">    2.84977 </td><td style=\"text-align: right;\"> 72.8021     </td><td style=\"text-align: right;\"> 92.5043     </td><td style=\"text-align: right;\">                   1</td><td>310307c2  </td><td style=\"text-align: right;\">     4.46506 </td><td style=\"text-align: right;\">     1.68868 </td></tr>\n",
       "<tr><td>FSR_Trainable_31e77bab</td><td>2023-08-10_23-43-41</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   26.2779 </td><td style=\"text-align: right;\">   2792.03 </td><td style=\"text-align: right;\">     4.53116</td><td style=\"text-align: right;\"> 6.14138e+18</td><td style=\"text-align: right;\"> 2.47475 </td><td>172.26.215.93</td><td style=\"text-align: right;\">166179</td><td style=\"text-align: right;\">     8.89721</td><td style=\"text-align: right;\">    1446.18 </td><td style=\"text-align: right;\">             3.7364 </td><td style=\"text-align: right;\">          3.7364  </td><td style=\"text-align: right;\">       3.7364 </td><td style=\"text-align: right;\"> 1691678621</td><td style=\"text-align: right;\">    5.77772 </td><td style=\"text-align: right;\">    1.18656 </td><td style=\"text-align: right;\">  5.78437e+13</td><td style=\"text-align: right;\">  2.81648e+15</td><td style=\"text-align: right;\">                   1</td><td>31e77bab  </td><td style=\"text-align: right;\">     1.89926 </td><td style=\"text-align: right;\">     0.57549 </td></tr>\n",
       "<tr><td>FSR_Trainable_3318cfcb</td><td>2023-08-10_23-41-05</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.62804</td><td style=\"text-align: right;\">   1216.32 </td><td style=\"text-align: right;\">     1.51554</td><td style=\"text-align: right;\"> 1.46595e+18</td><td style=\"text-align: right;\"> 0.870895</td><td>172.26.215.93</td><td style=\"text-align: right;\">162978</td><td style=\"text-align: right;\">     2.69271</td><td style=\"text-align: right;\">     968.081</td><td style=\"text-align: right;\">           119.158  </td><td style=\"text-align: right;\">         80.285   </td><td style=\"text-align: right;\">     119.158  </td><td style=\"text-align: right;\"> 1691678465</td><td style=\"text-align: right;\">    1.20799 </td><td style=\"text-align: right;\">    0.410897</td><td style=\"text-align: right;\">  8.99782e+13</td><td style=\"text-align: right;\">  4.13275e+14</td><td style=\"text-align: right;\">                   2</td><td>3318cfcb  </td><td style=\"text-align: right;\">     0.549723</td><td style=\"text-align: right;\">     0.321172</td></tr>\n",
       "<tr><td>FSR_Trainable_331fad73</td><td>2023-08-10_23-27-56</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    3.9289 </td><td style=\"text-align: right;\">   1435.46 </td><td style=\"text-align: right;\">     1.11988</td><td style=\"text-align: right;\"> 7.77431e+08</td><td style=\"text-align: right;\"> 6.48703 </td><td>172.26.215.93</td><td style=\"text-align: right;\">157754</td><td style=\"text-align: right;\">     2.35913</td><td style=\"text-align: right;\">     942.364</td><td style=\"text-align: right;\">             7.95958</td><td style=\"text-align: right;\">          3.83683 </td><td style=\"text-align: right;\">       7.95958</td><td style=\"text-align: right;\"> 1691677676</td><td style=\"text-align: right;\">    7.49904 </td><td style=\"text-align: right;\">    3.4862  </td><td style=\"text-align: right;\">  1.11499e+15</td><td style=\"text-align: right;\"> 37.7965     </td><td style=\"text-align: right;\">                   2</td><td>331fad73  </td><td style=\"text-align: right;\">     4.47741 </td><td style=\"text-align: right;\">     2.00961 </td></tr>\n",
       "<tr><td>FSR_Trainable_36c37afe</td><td>2023-08-11_00-12-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    5.24446</td><td style=\"text-align: right;\">    635.452</td><td style=\"text-align: right;\">     1.16404</td><td style=\"text-align: right;\"> 7.44564e+17</td><td style=\"text-align: right;\"> 0.676347</td><td>172.26.215.93</td><td style=\"text-align: right;\">175019</td><td style=\"text-align: right;\">     2.6034 </td><td style=\"text-align: right;\">     451.801</td><td style=\"text-align: right;\">           130.424  </td><td style=\"text-align: right;\">          2.06758 </td><td style=\"text-align: right;\">     130.424  </td><td style=\"text-align: right;\"> 1691680354</td><td style=\"text-align: right;\">    1.1147  </td><td style=\"text-align: right;\">    0.265331</td><td style=\"text-align: right;\">  6.44711e+13</td><td style=\"text-align: right;\">  4.02287e+14</td><td style=\"text-align: right;\">                  64</td><td>36c37afe  </td><td style=\"text-align: right;\">     0.507486</td><td style=\"text-align: right;\">     0.168861</td></tr>\n",
       "<tr><td>FSR_Trainable_3743b7d6</td><td>2023-08-10_23-43-13</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.16215</td><td style=\"text-align: right;\">   1246.66 </td><td style=\"text-align: right;\">     1.14113</td><td style=\"text-align: right;\"> 2.07538e+16</td><td style=\"text-align: right;\">40.3968  </td><td>172.26.215.93</td><td style=\"text-align: right;\">165733</td><td style=\"text-align: right;\">     2.38845</td><td style=\"text-align: right;\">    1143.17 </td><td style=\"text-align: right;\">             2.94978</td><td style=\"text-align: right;\">          2.94978 </td><td style=\"text-align: right;\">       2.94978</td><td style=\"text-align: right;\"> 1691678593</td><td style=\"text-align: right;\">   28.0876  </td><td style=\"text-align: right;\">    6.17826 </td><td style=\"text-align: right;\">  3.17521e+15</td><td style=\"text-align: right;\">  8.18479e+14</td><td style=\"text-align: right;\">                   1</td><td>3743b7d6  </td><td style=\"text-align: right;\">    33.1987  </td><td style=\"text-align: right;\">     7.19803 </td></tr>\n",
       "<tr><td>FSR_Trainable_3e3ca0ec</td><td>2023-08-10_23-40-47</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    5.39546</td><td style=\"text-align: right;\">   1171.89 </td><td style=\"text-align: right;\">     1.31081</td><td style=\"text-align: right;\"> 7.44812e+08</td><td style=\"text-align: right;\"> 7.04069 </td><td>172.26.215.93</td><td style=\"text-align: right;\">163686</td><td style=\"text-align: right;\">     2.63208</td><td style=\"text-align: right;\">     839.991</td><td style=\"text-align: right;\">            10.5942 </td><td style=\"text-align: right;\">         10.5942  </td><td style=\"text-align: right;\">      10.5942 </td><td style=\"text-align: right;\"> 1691678447</td><td style=\"text-align: right;\">    9.92972 </td><td style=\"text-align: right;\">    3.1346  </td><td style=\"text-align: right;\">  3.57802e+15</td><td style=\"text-align: right;\">275.505      </td><td style=\"text-align: right;\">                   1</td><td>3e3ca0ec  </td><td style=\"text-align: right;\">     4.93602 </td><td style=\"text-align: right;\">     2.10467 </td></tr>\n",
       "<tr><td>FSR_Trainable_408c68c9</td><td>2023-08-10_23-28-17</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.66863</td><td style=\"text-align: right;\">   1193.13 </td><td style=\"text-align: right;\">     1.28356</td><td style=\"text-align: right;\"> 3.04003e+16</td><td style=\"text-align: right;\">40.3809  </td><td>172.26.215.93</td><td style=\"text-align: right;\">157990</td><td style=\"text-align: right;\">     2.43723</td><td style=\"text-align: right;\">     976.675</td><td style=\"text-align: right;\">             3.85516</td><td style=\"text-align: right;\">          3.85516 </td><td style=\"text-align: right;\">       3.85516</td><td style=\"text-align: right;\"> 1691677697</td><td style=\"text-align: right;\">   28.8892  </td><td style=\"text-align: right;\">    6.15426 </td><td style=\"text-align: right;\">  5.30015e+15</td><td style=\"text-align: right;\">  1.73708e+15</td><td style=\"text-align: right;\">                   1</td><td>408c68c9  </td><td style=\"text-align: right;\">    33.2416  </td><td style=\"text-align: right;\">     7.13933 </td></tr>\n",
       "<tr><td>FSR_Trainable_454e8493</td><td>2023-08-11_00-23-10</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.36361</td><td style=\"text-align: right;\">   1134.85 </td><td style=\"text-align: right;\">     1.13134</td><td style=\"text-align: right;\"> 6.2272e+08 </td><td style=\"text-align: right;\"> 6.1296  </td><td>172.26.215.93</td><td style=\"text-align: right;\">178866</td><td style=\"text-align: right;\">     2.42731</td><td style=\"text-align: right;\">     780.212</td><td style=\"text-align: right;\">             5.50131</td><td style=\"text-align: right;\">          5.50131 </td><td style=\"text-align: right;\">       5.50131</td><td style=\"text-align: right;\"> 1691680990</td><td style=\"text-align: right;\">    7.93311 </td><td style=\"text-align: right;\">    2.69459 </td><td style=\"text-align: right;\">193.71       </td><td style=\"text-align: right;\"> 56.8384     </td><td style=\"text-align: right;\">                   1</td><td>454e8493  </td><td style=\"text-align: right;\">     4.45982 </td><td style=\"text-align: right;\">     1.66979 </td></tr>\n",
       "<tr><td>FSR_Trainable_45da30e1</td><td>2023-08-11_00-16-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.24342</td><td style=\"text-align: right;\">    631.472</td><td style=\"text-align: right;\">     1.17056</td><td style=\"text-align: right;\"> 7.91538e+17</td><td style=\"text-align: right;\"> 0.669464</td><td>172.26.215.93</td><td style=\"text-align: right;\">176250</td><td style=\"text-align: right;\">     2.6168 </td><td style=\"text-align: right;\">     434.631</td><td style=\"text-align: right;\">           215.541  </td><td style=\"text-align: right;\">          2.27965 </td><td style=\"text-align: right;\">     215.541  </td><td style=\"text-align: right;\"> 1691680598</td><td style=\"text-align: right;\">    1.10404 </td><td style=\"text-align: right;\">    0.265998</td><td style=\"text-align: right;\">  6.60637e+13</td><td style=\"text-align: right;\">  4.23422e+14</td><td style=\"text-align: right;\">                 100</td><td>45da30e1  </td><td style=\"text-align: right;\">     0.503733</td><td style=\"text-align: right;\">     0.165731</td></tr>\n",
       "<tr><td>FSR_Trainable_4bf5a3a3</td><td>2023-08-11_00-07-33</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.99187</td><td style=\"text-align: right;\">    636.213</td><td style=\"text-align: right;\">     1.18266</td><td style=\"text-align: right;\"> 8.71109e+17</td><td style=\"text-align: right;\"> 0.659759</td><td>172.26.215.93</td><td style=\"text-align: right;\">173167</td><td style=\"text-align: right;\">     2.57585</td><td style=\"text-align: right;\">     435.447</td><td style=\"text-align: right;\">           254.823  </td><td style=\"text-align: right;\">          2.81081 </td><td style=\"text-align: right;\">     254.823  </td><td style=\"text-align: right;\"> 1691680053</td><td style=\"text-align: right;\">    1.05981 </td><td style=\"text-align: right;\">    0.263599</td><td style=\"text-align: right;\">  6.74727e+13</td><td style=\"text-align: right;\">  4.56724e+14</td><td style=\"text-align: right;\">                 100</td><td>4bf5a3a3  </td><td style=\"text-align: right;\">     0.49882 </td><td style=\"text-align: right;\">     0.160939</td></tr>\n",
       "<tr><td>FSR_Trainable_4e53941a</td><td>2023-08-11_00-24-39</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    6.44075</td><td style=\"text-align: right;\">   1709.56 </td><td style=\"text-align: right;\">     1.36151</td><td style=\"text-align: right;\"> 3.79332e+18</td><td style=\"text-align: right;\"> 0.908875</td><td>172.26.215.93</td><td style=\"text-align: right;\">180006</td><td style=\"text-align: right;\">     2.81318</td><td style=\"text-align: right;\">    1029.53 </td><td style=\"text-align: right;\">             4.09515</td><td style=\"text-align: right;\">          4.09515 </td><td style=\"text-align: right;\">       4.09515</td><td style=\"text-align: right;\"> 1691681079</td><td style=\"text-align: right;\">    1.35185 </td><td style=\"text-align: right;\">    0.668645</td><td style=\"text-align: right;\">  7.44716e+13</td><td style=\"text-align: right;\">  1.64768e+15</td><td style=\"text-align: right;\">                   1</td><td>4e53941a  </td><td style=\"text-align: right;\">     0.552761</td><td style=\"text-align: right;\">     0.356113</td></tr>\n",
       "<tr><td>FSR_Trainable_50d0539b</td><td>2023-08-10_23-52-50</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.89638</td><td style=\"text-align: right;\">    593.612</td><td style=\"text-align: right;\">     1.15408</td><td style=\"text-align: right;\"> 6.82203e+17</td><td style=\"text-align: right;\"> 0.646463</td><td>172.26.215.93</td><td style=\"text-align: right;\">170363</td><td style=\"text-align: right;\">     2.50369</td><td style=\"text-align: right;\">     420.599</td><td style=\"text-align: right;\">           242.148  </td><td style=\"text-align: right;\">          2.41695 </td><td style=\"text-align: right;\">     242.148  </td><td style=\"text-align: right;\"> 1691679170</td><td style=\"text-align: right;\">    1.0379  </td><td style=\"text-align: right;\">    0.240902</td><td style=\"text-align: right;\">  7.60387e+13</td><td style=\"text-align: right;\">  3.51248e+14</td><td style=\"text-align: right;\">                 100</td><td>50d0539b  </td><td style=\"text-align: right;\">     0.491465</td><td style=\"text-align: right;\">     0.154997</td></tr>\n",
       "<tr><td>FSR_Trainable_517ec18a</td><td>2023-08-10_23-36-42</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.20545</td><td style=\"text-align: right;\">   1002.07 </td><td style=\"text-align: right;\">     1.11562</td><td style=\"text-align: right;\"> 1.75725e+17</td><td style=\"text-align: right;\">39.4496  </td><td>172.26.215.93</td><td style=\"text-align: right;\">161557</td><td style=\"text-align: right;\">     2.39518</td><td style=\"text-align: right;\">     785.132</td><td style=\"text-align: right;\">             2.56528</td><td style=\"text-align: right;\">          2.56528 </td><td style=\"text-align: right;\">       2.56528</td><td style=\"text-align: right;\"> 1691678202</td><td style=\"text-align: right;\">   28.5383  </td><td style=\"text-align: right;\">    6.21475 </td><td style=\"text-align: right;\">  3.9167e+15 </td><td style=\"text-align: right;\">  6.75712e+15</td><td style=\"text-align: right;\">                   1</td><td>517ec18a  </td><td style=\"text-align: right;\">    33.3753  </td><td style=\"text-align: right;\">     6.07428 </td></tr>\n",
       "<tr><td>FSR_Trainable_54d09832</td><td>2023-08-10_23-47-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.09872</td><td style=\"text-align: right;\">   1408.07 </td><td style=\"text-align: right;\">     1.14061</td><td style=\"text-align: right;\"> 7.54101e+08</td><td style=\"text-align: right;\"> 6.50713 </td><td>172.26.215.93</td><td style=\"text-align: right;\">169628</td><td style=\"text-align: right;\">     2.39572</td><td style=\"text-align: right;\">     972.604</td><td style=\"text-align: right;\">             2.23724</td><td style=\"text-align: right;\">          2.23724 </td><td style=\"text-align: right;\">       2.23724</td><td style=\"text-align: right;\"> 1691678848</td><td style=\"text-align: right;\">    7.79294 </td><td style=\"text-align: right;\">    3.21462 </td><td style=\"text-align: right;\">  1.29816e+15</td><td style=\"text-align: right;\"> 76.4583     </td><td style=\"text-align: right;\">                   1</td><td>54d09832  </td><td style=\"text-align: right;\">     4.5108  </td><td style=\"text-align: right;\">     1.99633 </td></tr>\n",
       "<tr><td>FSR_Trainable_56b1e2c2</td><td>2023-08-11_00-00-51</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    6.40807</td><td style=\"text-align: right;\">    917.102</td><td style=\"text-align: right;\">     1.65733</td><td style=\"text-align: right;\"> 1.09432e+18</td><td style=\"text-align: right;\"> 0.802322</td><td>172.26.215.93</td><td style=\"text-align: right;\">171497</td><td style=\"text-align: right;\">     2.79796</td><td style=\"text-align: right;\">     661.133</td><td style=\"text-align: right;\">           322.008  </td><td style=\"text-align: right;\">         14.1433  </td><td style=\"text-align: right;\">     322.008  </td><td style=\"text-align: right;\"> 1691679651</td><td style=\"text-align: right;\">    1.35313 </td><td style=\"text-align: right;\">    0.363163</td><td style=\"text-align: right;\">  7.06961e+13</td><td style=\"text-align: right;\">  5.39167e+14</td><td style=\"text-align: right;\">                  32</td><td>56b1e2c2  </td><td style=\"text-align: right;\">     0.565633</td><td style=\"text-align: right;\">     0.236688</td></tr>\n",
       "<tr><td>FSR_Trainable_585cd643</td><td>2023-08-10_23-43-27</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.23701</td><td style=\"text-align: right;\">   1145.33 </td><td style=\"text-align: right;\">     1.14484</td><td style=\"text-align: right;\"> 5.93016e+16</td><td style=\"text-align: right;\">40.1271  </td><td>172.26.215.93</td><td style=\"text-align: right;\">165948</td><td style=\"text-align: right;\">     2.42826</td><td style=\"text-align: right;\">     958.626</td><td style=\"text-align: right;\">             3.95117</td><td style=\"text-align: right;\">          3.95117 </td><td style=\"text-align: right;\">       3.95117</td><td style=\"text-align: right;\"> 1691678607</td><td style=\"text-align: right;\">   28.554   </td><td style=\"text-align: right;\">    5.98329 </td><td style=\"text-align: right;\">  4.45842e+15</td><td style=\"text-align: right;\">  1.64155e+15</td><td style=\"text-align: right;\">                   1</td><td>585cd643  </td><td style=\"text-align: right;\">    33.0872  </td><td style=\"text-align: right;\">     7.04    </td></tr>\n",
       "<tr><td>FSR_Trainable_591ef7b6</td><td>2023-08-10_23-42-46</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   21.9822 </td><td style=\"text-align: right;\">   1629.43 </td><td style=\"text-align: right;\">     3.68064</td><td style=\"text-align: right;\"> 3.13897e+18</td><td style=\"text-align: right;\"> 1.86966 </td><td>172.26.215.93</td><td style=\"text-align: right;\">165265</td><td style=\"text-align: right;\">     7.29082</td><td style=\"text-align: right;\">    1004.6  </td><td style=\"text-align: right;\">             2.95831</td><td style=\"text-align: right;\">          2.95831 </td><td style=\"text-align: right;\">       2.95831</td><td style=\"text-align: right;\"> 1691678566</td><td style=\"text-align: right;\">    4.85151 </td><td style=\"text-align: right;\">    0.635326</td><td style=\"text-align: right;\">  1.72131e+13</td><td style=\"text-align: right;\">  1.44579e+15</td><td style=\"text-align: right;\">                   1</td><td>591ef7b6  </td><td style=\"text-align: right;\">     1.53325 </td><td style=\"text-align: right;\">     0.336404</td></tr>\n",
       "<tr><td>FSR_Trainable_596c93b0</td><td>2023-08-11_00-11-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.88913</td><td style=\"text-align: right;\">    626.012</td><td style=\"text-align: right;\">     1.08639</td><td style=\"text-align: right;\"> 7.48523e+17</td><td style=\"text-align: right;\"> 0.649148</td><td>172.26.215.93</td><td style=\"text-align: right;\">174505</td><td style=\"text-align: right;\">     2.52522</td><td style=\"text-align: right;\">     429.614</td><td style=\"text-align: right;\">           209.907  </td><td style=\"text-align: right;\">          1.95934 </td><td style=\"text-align: right;\">     209.907  </td><td style=\"text-align: right;\"> 1691680294</td><td style=\"text-align: right;\">    1.03227 </td><td style=\"text-align: right;\">    0.254582</td><td style=\"text-align: right;\">  6.58371e+13</td><td style=\"text-align: right;\">  3.76872e+14</td><td style=\"text-align: right;\">                 100</td><td>596c93b0  </td><td style=\"text-align: right;\">     0.48975 </td><td style=\"text-align: right;\">     0.159398</td></tr>\n",
       "<tr><td>FSR_Trainable_5be7df8b</td><td>2023-08-10_23-42-35</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    4.83041</td><td style=\"text-align: right;\">   1409.8  </td><td style=\"text-align: right;\">     1.20049</td><td style=\"text-align: right;\"> 2.79239e+18</td><td style=\"text-align: right;\"> 0.824602</td><td>172.26.215.93</td><td style=\"text-align: right;\">164807</td><td style=\"text-align: right;\">     2.52293</td><td style=\"text-align: right;\">     933.728</td><td style=\"text-align: right;\">            26.8893 </td><td style=\"text-align: right;\">          4.33722 </td><td style=\"text-align: right;\">      26.8893 </td><td style=\"text-align: right;\"> 1691678555</td><td style=\"text-align: right;\">    1.05564 </td><td style=\"text-align: right;\">    0.512069</td><td style=\"text-align: right;\">  8.28551e+13</td><td style=\"text-align: right;\">  1.08594e+15</td><td style=\"text-align: right;\">                   8</td><td>5be7df8b  </td><td style=\"text-align: right;\">     0.522169</td><td style=\"text-align: right;\">     0.302433</td></tr>\n",
       "<tr><td>FSR_Trainable_6078457f</td><td>2023-08-10_23-41-47</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   25.5418 </td><td style=\"text-align: right;\">   1584.77 </td><td style=\"text-align: right;\">     4.0478 </td><td style=\"text-align: right;\"> 1.23292e+18</td><td style=\"text-align: right;\"> 2.13754 </td><td>172.26.215.93</td><td style=\"text-align: right;\">164558</td><td style=\"text-align: right;\">     8.28123</td><td style=\"text-align: right;\">    1373.49 </td><td style=\"text-align: right;\">             2.97755</td><td style=\"text-align: right;\">          2.97755 </td><td style=\"text-align: right;\">       2.97755</td><td style=\"text-align: right;\"> 1691678507</td><td style=\"text-align: right;\">    5.59152 </td><td style=\"text-align: right;\">    0.500235</td><td style=\"text-align: right;\">  1.26192e+13</td><td style=\"text-align: right;\">  4.50804e+14</td><td style=\"text-align: right;\">                   1</td><td>6078457f  </td><td style=\"text-align: right;\">     1.75503 </td><td style=\"text-align: right;\">     0.382507</td></tr>\n",
       "<tr><td>FSR_Trainable_60a52149</td><td>2023-08-10_23-31-43</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.55035</td><td style=\"text-align: right;\">   1056.74 </td><td style=\"text-align: right;\">     1.20262</td><td style=\"text-align: right;\"> 1.86058e+18</td><td style=\"text-align: right;\"> 0.746274</td><td>172.26.215.93</td><td style=\"text-align: right;\">157451</td><td style=\"text-align: right;\">     2.44309</td><td style=\"text-align: right;\">     719.549</td><td style=\"text-align: right;\">           270.942  </td><td style=\"text-align: right;\">          1.95343 </td><td style=\"text-align: right;\">     270.942  </td><td style=\"text-align: right;\"> 1691677903</td><td style=\"text-align: right;\">    0.977151</td><td style=\"text-align: right;\">    0.39834 </td><td style=\"text-align: right;\">  8.03733e+13</td><td style=\"text-align: right;\">  7.5052e+14 </td><td style=\"text-align: right;\">                 100</td><td>60a52149  </td><td style=\"text-align: right;\">     0.495706</td><td style=\"text-align: right;\">     0.250568</td></tr>\n",
       "<tr><td>FSR_Trainable_64cfa6a4</td><td>2023-08-10_23-45-32</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.92604</td><td style=\"text-align: right;\">   1151.1  </td><td style=\"text-align: right;\">     1.61944</td><td style=\"text-align: right;\"> 1.10096e+18</td><td style=\"text-align: right;\"> 0.879702</td><td>172.26.215.93</td><td style=\"text-align: right;\">168002</td><td style=\"text-align: right;\">     2.7736 </td><td style=\"text-align: right;\">     957.473</td><td style=\"text-align: right;\">            10.8141 </td><td style=\"text-align: right;\">          4.84724 </td><td style=\"text-align: right;\">      10.8141 </td><td style=\"text-align: right;\"> 1691678732</td><td style=\"text-align: right;\">    1.25945 </td><td style=\"text-align: right;\">    0.384397</td><td style=\"text-align: right;\">  9.05918e+13</td><td style=\"text-align: right;\">  2.86508e+14</td><td style=\"text-align: right;\">                   2</td><td>64cfa6a4  </td><td style=\"text-align: right;\">     0.563015</td><td style=\"text-align: right;\">     0.316687</td></tr>\n",
       "<tr><td>FSR_Trainable_6872dd1b</td><td>2023-08-10_23-29-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.81683</td><td style=\"text-align: right;\">   1454.91 </td><td style=\"text-align: right;\">     1.198  </td><td style=\"text-align: right;\"> 2.95881e+18</td><td style=\"text-align: right;\"> 0.808318</td><td>172.26.215.93</td><td style=\"text-align: right;\">156704</td><td style=\"text-align: right;\">     2.45688</td><td style=\"text-align: right;\">     943.69 </td><td style=\"text-align: right;\">           200.64   </td><td style=\"text-align: right;\">          2.08851 </td><td style=\"text-align: right;\">     200.64   </td><td style=\"text-align: right;\"> 1691677793</td><td style=\"text-align: right;\">    1.04233 </td><td style=\"text-align: right;\">    0.537145</td><td style=\"text-align: right;\">  8.67456e+13</td><td style=\"text-align: right;\">  1.1893e+15 </td><td style=\"text-align: right;\">                 100</td><td>6872dd1b  </td><td style=\"text-align: right;\">     0.501537</td><td style=\"text-align: right;\">     0.30678 </td></tr>\n",
       "<tr><td>FSR_Trainable_698f5feb</td><td>2023-08-10_23-32-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.87438</td><td style=\"text-align: right;\">    606.67 </td><td style=\"text-align: right;\">     1.32919</td><td style=\"text-align: right;\"> 7.01231e+17</td><td style=\"text-align: right;\"> 0.708937</td><td>172.26.215.93</td><td style=\"text-align: right;\">159115</td><td style=\"text-align: right;\">     2.83091</td><td style=\"text-align: right;\">     451.134</td><td style=\"text-align: right;\">           132.539  </td><td style=\"text-align: right;\">          1.072   </td><td style=\"text-align: right;\">     132.539  </td><td style=\"text-align: right;\"> 1691677954</td><td style=\"text-align: right;\">    1.24222 </td><td style=\"text-align: right;\">    0.241186</td><td style=\"text-align: right;\">  8.14694e+13</td><td style=\"text-align: right;\">  3.5446e+14 </td><td style=\"text-align: right;\">                 100</td><td>698f5feb  </td><td style=\"text-align: right;\">     0.551016</td><td style=\"text-align: right;\">     0.157922</td></tr>\n",
       "<tr><td>FSR_Trainable_6adba9f2</td><td>2023-08-10_23-38-51</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.94905</td><td style=\"text-align: right;\">   1174.38 </td><td style=\"text-align: right;\">     1.59666</td><td style=\"text-align: right;\"> 1.40857e+18</td><td style=\"text-align: right;\"> 0.879597</td><td>172.26.215.93</td><td style=\"text-align: right;\">162694</td><td style=\"text-align: right;\">     2.76479</td><td style=\"text-align: right;\">     955.644</td><td style=\"text-align: right;\">            25.6715 </td><td style=\"text-align: right;\">         12.4203  </td><td style=\"text-align: right;\">      25.6715 </td><td style=\"text-align: right;\"> 1691678331</td><td style=\"text-align: right;\">    1.27172 </td><td style=\"text-align: right;\">    0.399102</td><td style=\"text-align: right;\">  9.0282e+13 </td><td style=\"text-align: right;\">  4.18389e+14</td><td style=\"text-align: right;\">                   2</td><td>6adba9f2  </td><td style=\"text-align: right;\">     0.565218</td><td style=\"text-align: right;\">     0.314379</td></tr>\n",
       "<tr><td>FSR_Trainable_6c3cd3ce</td><td>2023-08-11_00-16-13</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.97983</td><td style=\"text-align: right;\">    614.473</td><td style=\"text-align: right;\">     1.15006</td><td style=\"text-align: right;\"> 7.17201e+17</td><td style=\"text-align: right;\"> 0.657729</td><td>172.26.215.93</td><td style=\"text-align: right;\">175993</td><td style=\"text-align: right;\">     2.55531</td><td style=\"text-align: right;\">     432.298</td><td style=\"text-align: right;\">           209.845  </td><td style=\"text-align: right;\">          1.91522 </td><td style=\"text-align: right;\">     209.845  </td><td style=\"text-align: right;\"> 1691680573</td><td style=\"text-align: right;\">    1.05865 </td><td style=\"text-align: right;\">    0.246869</td><td style=\"text-align: right;\">  6.62236e+13</td><td style=\"text-align: right;\">  3.57334e+14</td><td style=\"text-align: right;\">                 100</td><td>6c3cd3ce  </td><td style=\"text-align: right;\">     0.499211</td><td style=\"text-align: right;\">     0.158518</td></tr>\n",
       "<tr><td>FSR_Trainable_6c66e650</td><td>2023-08-10_23-44-58</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.25445</td><td style=\"text-align: right;\">   1459.5  </td><td style=\"text-align: right;\">     1.25936</td><td style=\"text-align: right;\"> 3.0119e+18 </td><td style=\"text-align: right;\"> 0.840999</td><td>172.26.215.93</td><td style=\"text-align: right;\">166877</td><td style=\"text-align: right;\">     2.57883</td><td style=\"text-align: right;\">     963.174</td><td style=\"text-align: right;\">            46.4506 </td><td style=\"text-align: right;\">         13.2421  </td><td style=\"text-align: right;\">      46.4506 </td><td style=\"text-align: right;\"> 1691678698</td><td style=\"text-align: right;\">    1.14204 </td><td style=\"text-align: right;\">    0.531245</td><td style=\"text-align: right;\">  9.27194e+13</td><td style=\"text-align: right;\">  1.16738e+15</td><td style=\"text-align: right;\">                   4</td><td>6c66e650  </td><td style=\"text-align: right;\">     0.530032</td><td style=\"text-align: right;\">     0.310967</td></tr>\n",
       "<tr><td>FSR_Trainable_6dc65d0f</td><td>2023-08-10_23-53-18</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.2113 </td><td style=\"text-align: right;\">    778.52 </td><td style=\"text-align: right;\">     1.18053</td><td style=\"text-align: right;\"> 8.37784e+17</td><td style=\"text-align: right;\"> 0.704357</td><td>172.26.215.93</td><td style=\"text-align: right;\">167548</td><td style=\"text-align: right;\">     2.55531</td><td style=\"text-align: right;\">     583.046</td><td style=\"text-align: right;\">           487.447  </td><td style=\"text-align: right;\">          5.23167 </td><td style=\"text-align: right;\">     487.447  </td><td style=\"text-align: right;\"> 1691679198</td><td style=\"text-align: right;\">    1.0977  </td><td style=\"text-align: right;\">    0.300023</td><td style=\"text-align: right;\">  7.19927e+13</td><td style=\"text-align: right;\">  3.86573e+14</td><td style=\"text-align: right;\">                 100</td><td>6dc65d0f  </td><td style=\"text-align: right;\">     0.498098</td><td style=\"text-align: right;\">     0.206259</td></tr>\n",
       "<tr><td>FSR_Trainable_736b439f</td><td>2023-08-11_00-06-22</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.28781</td><td style=\"text-align: right;\">    643.656</td><td style=\"text-align: right;\">     1.14718</td><td style=\"text-align: right;\"> 9.40345e+17</td><td style=\"text-align: right;\"> 0.67149 </td><td>172.26.215.93</td><td style=\"text-align: right;\">172969</td><td style=\"text-align: right;\">     2.6235 </td><td style=\"text-align: right;\">     424.478</td><td style=\"text-align: right;\">           204.575  </td><td style=\"text-align: right;\">          2.10073 </td><td style=\"text-align: right;\">     204.575  </td><td style=\"text-align: right;\"> 1691679982</td><td style=\"text-align: right;\">    1.1155  </td><td style=\"text-align: right;\">    0.278062</td><td style=\"text-align: right;\">  6.36586e+13</td><td style=\"text-align: right;\">  5.20005e+14</td><td style=\"text-align: right;\">                 100</td><td>736b439f  </td><td style=\"text-align: right;\">     0.508136</td><td style=\"text-align: right;\">     0.163354</td></tr>\n",
       "<tr><td>FSR_Trainable_73b6e975</td><td>2023-08-11_00-04-40</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.05165</td><td style=\"text-align: right;\">    603.235</td><td style=\"text-align: right;\">     1.10962</td><td style=\"text-align: right;\"> 7.10646e+17</td><td style=\"text-align: right;\"> 0.6563  </td><td>172.26.215.93</td><td style=\"text-align: right;\">172682</td><td style=\"text-align: right;\">     2.58674</td><td style=\"text-align: right;\">     428.402</td><td style=\"text-align: right;\">           197.969  </td><td style=\"text-align: right;\">          2.35219 </td><td style=\"text-align: right;\">     197.969  </td><td style=\"text-align: right;\"> 1691679880</td><td style=\"text-align: right;\">    1.06949 </td><td style=\"text-align: right;\">    0.242702</td><td style=\"text-align: right;\">  6.47994e+13</td><td style=\"text-align: right;\">  3.5863e+14 </td><td style=\"text-align: right;\">                 100</td><td>73b6e975  </td><td style=\"text-align: right;\">     0.500539</td><td style=\"text-align: right;\">     0.15576 </td></tr>\n",
       "<tr><td>FSR_Trainable_754a29b9</td><td>2023-08-11_00-09-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.20362</td><td style=\"text-align: right;\">    617.271</td><td style=\"text-align: right;\">     1.16965</td><td style=\"text-align: right;\"> 8.00638e+17</td><td style=\"text-align: right;\"> 0.661166</td><td>172.26.215.93</td><td style=\"text-align: right;\">173730</td><td style=\"text-align: right;\">     2.61556</td><td style=\"text-align: right;\">     422.81 </td><td style=\"text-align: right;\">           266.416  </td><td style=\"text-align: right;\">          3.08264 </td><td style=\"text-align: right;\">     266.416  </td><td style=\"text-align: right;\"> 1691680178</td><td style=\"text-align: right;\">    1.09491 </td><td style=\"text-align: right;\">    0.257181</td><td style=\"text-align: right;\">  6.59314e+13</td><td style=\"text-align: right;\">  4.26839e+14</td><td style=\"text-align: right;\">                 100</td><td>754a29b9  </td><td style=\"text-align: right;\">     0.504089</td><td style=\"text-align: right;\">     0.157077</td></tr>\n",
       "<tr><td>FSR_Trainable_757aa8c1</td><td>2023-08-11_00-14-07</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    5.28397</td><td style=\"text-align: right;\">    629.53 </td><td style=\"text-align: right;\">     1.14994</td><td style=\"text-align: right;\"> 7.85287e+17</td><td style=\"text-align: right;\"> 0.672482</td><td>172.26.215.93</td><td style=\"text-align: right;\">175329</td><td style=\"text-align: right;\">     2.62772</td><td style=\"text-align: right;\">     442.902</td><td style=\"text-align: right;\">           133.848  </td><td style=\"text-align: right;\">          2.21081 </td><td style=\"text-align: right;\">     133.848  </td><td style=\"text-align: right;\"> 1691680447</td><td style=\"text-align: right;\">    1.11764 </td><td style=\"text-align: right;\">    0.258774</td><td style=\"text-align: right;\">  6.64469e+13</td><td style=\"text-align: right;\">  4.03876e+14</td><td style=\"text-align: right;\">                  64</td><td>757aa8c1  </td><td style=\"text-align: right;\">     0.50886 </td><td style=\"text-align: right;\">     0.163622</td></tr>\n",
       "<tr><td>FSR_Trainable_7674b648</td><td>2023-08-10_23-43-51</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   21.9081 </td><td style=\"text-align: right;\">   2515.46 </td><td style=\"text-align: right;\">     3.40217</td><td style=\"text-align: right;\"> 4.03842e+18</td><td style=\"text-align: right;\"> 2.09913 </td><td>172.26.215.93</td><td style=\"text-align: right;\">166425</td><td style=\"text-align: right;\">     7.36374</td><td style=\"text-align: right;\">    1510.95 </td><td style=\"text-align: right;\">             2.58814</td><td style=\"text-align: right;\">          2.58814 </td><td style=\"text-align: right;\">       2.58814</td><td style=\"text-align: right;\"> 1691678631</td><td style=\"text-align: right;\">    4.75388 </td><td style=\"text-align: right;\">    1.00837 </td><td style=\"text-align: right;\">  3.64118e+13</td><td style=\"text-align: right;\">  2.0623e+15 </td><td style=\"text-align: right;\">                   1</td><td>7674b648  </td><td style=\"text-align: right;\">     1.57753 </td><td style=\"text-align: right;\">     0.521598</td></tr>\n",
       "<tr><td>FSR_Trainable_7c0b9ad8</td><td>2023-08-10_23-28-47</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   21.7235 </td><td style=\"text-align: right;\">   3061.34 </td><td style=\"text-align: right;\">     3.81695</td><td style=\"text-align: right;\"> 6.46425e+18</td><td style=\"text-align: right;\"> 2.33962 </td><td>172.26.215.93</td><td style=\"text-align: right;\">158193</td><td style=\"text-align: right;\">     7.42428</td><td style=\"text-align: right;\">    1616.38 </td><td style=\"text-align: right;\">             9.21296</td><td style=\"text-align: right;\">          1.8457  </td><td style=\"text-align: right;\">       9.21296</td><td style=\"text-align: right;\"> 1691677727</td><td style=\"text-align: right;\">    5.01124 </td><td style=\"text-align: right;\">    1.2837  </td><td style=\"text-align: right;\">  5.26774e+13</td><td style=\"text-align: right;\">  2.97005e+15</td><td style=\"text-align: right;\">                   4</td><td>7c0b9ad8  </td><td style=\"text-align: right;\">     1.70065 </td><td style=\"text-align: right;\">     0.63897 </td></tr>\n",
       "<tr><td>FSR_Trainable_7d0169a8</td><td>2023-08-10_23-41-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    5.01242</td><td style=\"text-align: right;\">   1257.56 </td><td style=\"text-align: right;\">     1.46477</td><td style=\"text-align: right;\"> 4.6859e+08 </td><td style=\"text-align: right;\"> 6.72597 </td><td>172.26.215.93</td><td style=\"text-align: right;\">163924</td><td style=\"text-align: right;\">     2.53395</td><td style=\"text-align: right;\">     986.411</td><td style=\"text-align: right;\">             8.62426</td><td style=\"text-align: right;\">          8.62426 </td><td style=\"text-align: right;\">       8.62426</td><td style=\"text-align: right;\"> 1691678469</td><td style=\"text-align: right;\">    9.06855 </td><td style=\"text-align: right;\">    2.77399 </td><td style=\"text-align: right;\">  2.74343e+15</td><td style=\"text-align: right;\"> 78.7029     </td><td style=\"text-align: right;\">                   1</td><td>7d0169a8  </td><td style=\"text-align: right;\">     4.67529 </td><td style=\"text-align: right;\">     2.05068 </td></tr>\n",
       "<tr><td>FSR_Trainable_7d289c93</td><td>2023-08-11_00-23-24</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.96287</td><td style=\"text-align: right;\">    607.217</td><td style=\"text-align: right;\">     1.10313</td><td style=\"text-align: right;\"> 7.85399e+17</td><td style=\"text-align: right;\"> 0.654706</td><td>172.26.215.93</td><td style=\"text-align: right;\">177749</td><td style=\"text-align: right;\">     2.54565</td><td style=\"text-align: right;\">     416.807</td><td style=\"text-align: right;\">           311.048  </td><td style=\"text-align: right;\">          2.78568 </td><td style=\"text-align: right;\">     311.048  </td><td style=\"text-align: right;\"> 1691681004</td><td style=\"text-align: right;\">    1.05102 </td><td style=\"text-align: right;\">    0.248798</td><td style=\"text-align: right;\">  6.33387e+13</td><td style=\"text-align: right;\">  3.95381e+14</td><td style=\"text-align: right;\">                 100</td><td>7d289c93  </td><td style=\"text-align: right;\">     0.496612</td><td style=\"text-align: right;\">     0.158094</td></tr>\n",
       "<tr><td>FSR_Trainable_8269d25a</td><td>2023-08-10_23-55-07</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.14683</td><td style=\"text-align: right;\">    670.371</td><td style=\"text-align: right;\">     1.21098</td><td style=\"text-align: right;\"> 7.16011e+17</td><td style=\"text-align: right;\"> 0.677002</td><td>172.26.215.93</td><td style=\"text-align: right;\">170092</td><td style=\"text-align: right;\">     2.57945</td><td style=\"text-align: right;\">     485.966</td><td style=\"text-align: right;\">           409.341  </td><td style=\"text-align: right;\">          4.77236 </td><td style=\"text-align: right;\">     409.341  </td><td style=\"text-align: right;\"> 1691679307</td><td style=\"text-align: right;\">    1.08071 </td><td style=\"text-align: right;\">    0.265562</td><td style=\"text-align: right;\">  7.48425e+13</td><td style=\"text-align: right;\">  3.45867e+14</td><td style=\"text-align: right;\">                 100</td><td>8269d25a  </td><td style=\"text-align: right;\">     0.500723</td><td style=\"text-align: right;\">     0.176278</td></tr>\n",
       "<tr><td>FSR_Trainable_841d9a78</td><td>2023-08-10_23-29-43</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    7.66743</td><td style=\"text-align: right;\">   1558.65 </td><td style=\"text-align: right;\">     1.60878</td><td style=\"text-align: right;\"> 3.16852e+18</td><td style=\"text-align: right;\"> 0.945806</td><td>172.26.215.93</td><td style=\"text-align: right;\">158696</td><td style=\"text-align: right;\">     3.00157</td><td style=\"text-align: right;\">     974.909</td><td style=\"text-align: right;\">            10.1129 </td><td style=\"text-align: right;\">          2.24131 </td><td style=\"text-align: right;\">      10.1129 </td><td style=\"text-align: right;\"> 1691677783</td><td style=\"text-align: right;\">    1.6261  </td><td style=\"text-align: right;\">    0.607449</td><td style=\"text-align: right;\">  7.94686e+13</td><td style=\"text-align: right;\">  1.42194e+15</td><td style=\"text-align: right;\">                   4</td><td>841d9a78  </td><td style=\"text-align: right;\">     0.614056</td><td style=\"text-align: right;\">     0.33175 </td></tr>\n",
       "<tr><td>FSR_Trainable_85129490</td><td>2023-08-10_23-46-06</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   25.869  </td><td style=\"text-align: right;\">   1469.36 </td><td style=\"text-align: right;\">     4.20478</td><td style=\"text-align: right;\"> 1.98599e+18</td><td style=\"text-align: right;\"> 2.23912 </td><td>172.26.215.93</td><td style=\"text-align: right;\">168468</td><td style=\"text-align: right;\">     8.66016</td><td style=\"text-align: right;\">    1089.76 </td><td style=\"text-align: right;\">             2.14952</td><td style=\"text-align: right;\">          2.14952 </td><td style=\"text-align: right;\">       2.14952</td><td style=\"text-align: right;\"> 1691678766</td><td style=\"text-align: right;\">    5.77095 </td><td style=\"text-align: right;\">    0.574607</td><td style=\"text-align: right;\">  1.98566e+13</td><td style=\"text-align: right;\">  1.03907e+15</td><td style=\"text-align: right;\">                   1</td><td>85129490  </td><td style=\"text-align: right;\">     1.88459 </td><td style=\"text-align: right;\">     0.354529</td></tr>\n",
       "<tr><td>FSR_Trainable_93fa7cd9</td><td>2023-08-10_23-38-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    4.64692</td><td style=\"text-align: right;\">   1421.59 </td><td style=\"text-align: right;\">     1.22487</td><td style=\"text-align: right;\"> 2.76929e+18</td><td style=\"text-align: right;\"> 0.81504 </td><td>172.26.215.93</td><td style=\"text-align: right;\">162011</td><td style=\"text-align: right;\">     2.50135</td><td style=\"text-align: right;\">     940.012</td><td style=\"text-align: right;\">            38.9784 </td><td style=\"text-align: right;\">          2.32436 </td><td style=\"text-align: right;\">      38.9784 </td><td style=\"text-align: right;\"> 1691678280</td><td style=\"text-align: right;\">    1.01976 </td><td style=\"text-align: right;\">    0.513915</td><td style=\"text-align: right;\">  8.34592e+13</td><td style=\"text-align: right;\">  1.07544e+15</td><td style=\"text-align: right;\">                  16</td><td>93fa7cd9  </td><td style=\"text-align: right;\">     0.512671</td><td style=\"text-align: right;\">     0.302369</td></tr>\n",
       "<tr><td>FSR_Trainable_96f85d46</td><td>2023-08-10_23-36-03</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   23.3289 </td><td style=\"text-align: right;\">   1761.13 </td><td style=\"text-align: right;\">     3.64599</td><td style=\"text-align: right;\"> 1.87463e+18</td><td style=\"text-align: right;\"> 2.09335 </td><td>172.26.215.93</td><td style=\"text-align: right;\">161128</td><td style=\"text-align: right;\">     7.48558</td><td style=\"text-align: right;\">    1299.13 </td><td style=\"text-align: right;\">             2.83159</td><td style=\"text-align: right;\">          2.83159 </td><td style=\"text-align: right;\">       2.83159</td><td style=\"text-align: right;\"> 1691678163</td><td style=\"text-align: right;\">    5.33548 </td><td style=\"text-align: right;\">    0.647845</td><td style=\"text-align: right;\">  2.51563e+13</td><td style=\"text-align: right;\">  9.39295e+14</td><td style=\"text-align: right;\">                   1</td><td>96f85d46  </td><td style=\"text-align: right;\">     1.69791 </td><td style=\"text-align: right;\">     0.395438</td></tr>\n",
       "<tr><td>FSR_Trainable_9cb367ce</td><td>2023-08-10_23-53-41</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.37377</td><td style=\"text-align: right;\">    657.8  </td><td style=\"text-align: right;\">     1.20271</td><td style=\"text-align: right;\"> 6.61516e+17</td><td style=\"text-align: right;\"> 0.707929</td><td>172.26.215.93</td><td style=\"text-align: right;\">159650</td><td style=\"text-align: right;\">     2.70632</td><td style=\"text-align: right;\">     489.764</td><td style=\"text-align: right;\">          1320.8    </td><td style=\"text-align: right;\">         13.3535  </td><td style=\"text-align: right;\">    1320.8    </td><td style=\"text-align: right;\"> 1691679221</td><td style=\"text-align: right;\">    1.12934 </td><td style=\"text-align: right;\">    0.270587</td><td style=\"text-align: right;\">  6.49498e+13</td><td style=\"text-align: right;\">  3.47387e+14</td><td style=\"text-align: right;\">                 100</td><td>9cb367ce  </td><td style=\"text-align: right;\">     0.52169 </td><td style=\"text-align: right;\">     0.186238</td></tr>\n",
       "<tr><td>FSR_Trainable_a2c73c61</td><td>2023-08-10_23-57-17</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.03725</td><td style=\"text-align: right;\">    588.842</td><td style=\"text-align: right;\">     1.19262</td><td style=\"text-align: right;\"> 7.25426e+17</td><td style=\"text-align: right;\"> 0.658146</td><td>172.26.215.93</td><td style=\"text-align: right;\">170747</td><td style=\"text-align: right;\">     2.53516</td><td style=\"text-align: right;\">     417.036</td><td style=\"text-align: right;\">           241.787  </td><td style=\"text-align: right;\">          2.30856 </td><td style=\"text-align: right;\">     241.787  </td><td style=\"text-align: right;\"> 1691679437</td><td style=\"text-align: right;\">    1.07781 </td><td style=\"text-align: right;\">    0.242501</td><td style=\"text-align: right;\">  7.67544e+13</td><td style=\"text-align: right;\">  3.8003e+14 </td><td style=\"text-align: right;\">                 100</td><td>a2c73c61  </td><td style=\"text-align: right;\">     0.502706</td><td style=\"text-align: right;\">     0.15544 </td></tr>\n",
       "<tr><td>FSR_Trainable_a5c83218</td><td>2023-08-11_00-22-11</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.80457</td><td style=\"text-align: right;\">    594.541</td><td style=\"text-align: right;\">     1.08954</td><td style=\"text-align: right;\"> 7.14378e+17</td><td style=\"text-align: right;\"> 0.649587</td><td>172.26.215.93</td><td style=\"text-align: right;\">177565</td><td style=\"text-align: right;\">     2.53345</td><td style=\"text-align: right;\">     414.779</td><td style=\"text-align: right;\">           257.122  </td><td style=\"text-align: right;\">          2.51202 </td><td style=\"text-align: right;\">     257.122  </td><td style=\"text-align: right;\"> 1691680931</td><td style=\"text-align: right;\">    1.01435 </td><td style=\"text-align: right;\">    0.250711</td><td style=\"text-align: right;\">  6.73377e+13</td><td style=\"text-align: right;\">  3.933e+14  </td><td style=\"text-align: right;\">                 100</td><td>a5c83218  </td><td style=\"text-align: right;\">     0.491547</td><td style=\"text-align: right;\">     0.15804 </td></tr>\n",
       "<tr><td>FSR_Trainable_a6c859de</td><td>2023-08-10_23-31-14</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.81741</td><td style=\"text-align: right;\">   1334.09 </td><td style=\"text-align: right;\">     1.45266</td><td style=\"text-align: right;\"> 2.47861e+18</td><td style=\"text-align: right;\"> 0.840668</td><td>172.26.215.93</td><td style=\"text-align: right;\">159359</td><td style=\"text-align: right;\">     2.60839</td><td style=\"text-align: right;\">     954.995</td><td style=\"text-align: right;\">            44.6325 </td><td style=\"text-align: right;\">          5.51462 </td><td style=\"text-align: right;\">      44.6325 </td><td style=\"text-align: right;\"> 1691677874</td><td style=\"text-align: right;\">    1.24369 </td><td style=\"text-align: right;\">    0.474715</td><td style=\"text-align: right;\">  8.16911e+13</td><td style=\"text-align: right;\">  9.17048e+14</td><td style=\"text-align: right;\">                   8</td><td>a6c859de  </td><td style=\"text-align: right;\">     0.534046</td><td style=\"text-align: right;\">     0.306622</td></tr>\n",
       "<tr><td>FSR_Trainable_a76f516b</td><td>2023-08-10_23-46-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   17.696  </td><td style=\"text-align: right;\">   2493.28 </td><td style=\"text-align: right;\">     2.43247</td><td style=\"text-align: right;\"> 4.73453e+18</td><td style=\"text-align: right;\"> 1.78563 </td><td>172.26.215.93</td><td style=\"text-align: right;\">169182</td><td style=\"text-align: right;\">     6.83658</td><td style=\"text-align: right;\">    1631.65 </td><td style=\"text-align: right;\">             2.50164</td><td style=\"text-align: right;\">          2.50164 </td><td style=\"text-align: right;\">       2.50164</td><td style=\"text-align: right;\"> 1691678813</td><td style=\"text-align: right;\">    3.58366 </td><td style=\"text-align: right;\">    0.865041</td><td style=\"text-align: right;\">  4.49747e+13</td><td style=\"text-align: right;\">  1.60672e+15</td><td style=\"text-align: right;\">                   1</td><td>a76f516b  </td><td style=\"text-align: right;\">     1.26814 </td><td style=\"text-align: right;\">     0.517493</td></tr>\n",
       "<tr><td>FSR_Trainable_a86dc0e6</td><td>2023-08-10_23-47-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   24.3476 </td><td style=\"text-align: right;\">   3180.46 </td><td style=\"text-align: right;\">     5.01523</td><td style=\"text-align: right;\"> 4.69267e+18</td><td style=\"text-align: right;\"> 2.32986 </td><td>172.26.215.93</td><td style=\"text-align: right;\">169398</td><td style=\"text-align: right;\">     8.66764</td><td style=\"text-align: right;\">    2084.31 </td><td style=\"text-align: right;\">             1.25728</td><td style=\"text-align: right;\">          1.25728 </td><td style=\"text-align: right;\">       1.25728</td><td style=\"text-align: right;\"> 1691678829</td><td style=\"text-align: right;\">    5.19906 </td><td style=\"text-align: right;\">    1.16172 </td><td style=\"text-align: right;\">  5.46387e+13</td><td style=\"text-align: right;\">  2.254e+15  </td><td style=\"text-align: right;\">                   1</td><td>a86dc0e6  </td><td style=\"text-align: right;\">     1.70601 </td><td style=\"text-align: right;\">     0.623851</td></tr>\n",
       "<tr><td>FSR_Trainable_a92c1ed3</td><td>2023-08-11_00-02-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.07548</td><td style=\"text-align: right;\">    636.538</td><td style=\"text-align: right;\">     1.13056</td><td style=\"text-align: right;\"> 7.19013e+17</td><td style=\"text-align: right;\"> 0.673273</td><td>172.26.215.93</td><td style=\"text-align: right;\">172278</td><td style=\"text-align: right;\">     2.60675</td><td style=\"text-align: right;\">     462.666</td><td style=\"text-align: right;\">           231.388  </td><td style=\"text-align: right;\">          2.34482 </td><td style=\"text-align: right;\">     231.388  </td><td style=\"text-align: right;\"> 1691679748</td><td style=\"text-align: right;\">    1.07079 </td><td style=\"text-align: right;\">    0.25544 </td><td style=\"text-align: right;\">  6.49897e+13</td><td style=\"text-align: right;\">  3.58888e+14</td><td style=\"text-align: right;\">                 100</td><td>a92c1ed3  </td><td style=\"text-align: right;\">     0.504508</td><td style=\"text-align: right;\">     0.168766</td></tr>\n",
       "<tr><td>FSR_Trainable_aa13815a</td><td>2023-08-11_00-27-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.81462</td><td style=\"text-align: right;\">    619.679</td><td style=\"text-align: right;\">     1.10037</td><td style=\"text-align: right;\"> 7.71365e+17</td><td style=\"text-align: right;\"> 0.647178</td><td>172.26.215.93</td><td style=\"text-align: right;\">179320</td><td style=\"text-align: right;\">     2.542  </td><td style=\"text-align: right;\">     433.938</td><td style=\"text-align: right;\">           223.221  </td><td style=\"text-align: right;\">          1.5108  </td><td style=\"text-align: right;\">     223.221  </td><td style=\"text-align: right;\"> 1691681258</td><td style=\"text-align: right;\">    1.01896 </td><td style=\"text-align: right;\">    0.247034</td><td style=\"text-align: right;\">  6.65066e+13</td><td style=\"text-align: right;\">  3.78946e+14</td><td style=\"text-align: right;\">                 100</td><td>aa13815a  </td><td style=\"text-align: right;\">     0.492312</td><td style=\"text-align: right;\">     0.154865</td></tr>\n",
       "<tr><td>FSR_Trainable_b15e6191</td><td>2023-08-10_23-25-59</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.36319</td><td style=\"text-align: right;\">   1382.37 </td><td style=\"text-align: right;\">     1.06326</td><td style=\"text-align: right;\"> 2.21402e+17</td><td style=\"text-align: right;\">54.6182  </td><td>172.26.215.93</td><td style=\"text-align: right;\">156357</td><td style=\"text-align: right;\">     2.49798</td><td style=\"text-align: right;\">     999.393</td><td style=\"text-align: right;\">             2.8108 </td><td style=\"text-align: right;\">          2.8108  </td><td style=\"text-align: right;\">       2.8108 </td><td style=\"text-align: right;\"> 1691677559</td><td style=\"text-align: right;\">   44.6561  </td><td style=\"text-align: right;\">    7.05835 </td><td style=\"text-align: right;\">  5.16602e+15</td><td style=\"text-align: right;\">  7.88817e+15</td><td style=\"text-align: right;\">                   1</td><td>b15e6191  </td><td style=\"text-align: right;\">    48.2992  </td><td style=\"text-align: right;\">     6.31898 </td></tr>\n",
       "<tr><td>FSR_Trainable_bad38ad8</td><td>2023-08-10_23-37-01</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.21637</td><td style=\"text-align: right;\">   1057.92 </td><td style=\"text-align: right;\">     1.06687</td><td style=\"text-align: right;\"> 1.73463e+17</td><td style=\"text-align: right;\">38.9142  </td><td>172.26.215.93</td><td style=\"text-align: right;\">161778</td><td style=\"text-align: right;\">     2.40601</td><td style=\"text-align: right;\">     871.343</td><td style=\"text-align: right;\">             5.08934</td><td style=\"text-align: right;\">          5.08934 </td><td style=\"text-align: right;\">       5.08934</td><td style=\"text-align: right;\"> 1691678221</td><td style=\"text-align: right;\">   28.4639  </td><td style=\"text-align: right;\">    5.93441 </td><td style=\"text-align: right;\">  4.33664e+15</td><td style=\"text-align: right;\">  6.52012e+15</td><td style=\"text-align: right;\">                   1</td><td>bad38ad8  </td><td style=\"text-align: right;\">    32.9435  </td><td style=\"text-align: right;\">     5.97072 </td></tr>\n",
       "<tr><td>FSR_Trainable_bbab0ac2</td><td>2023-08-10_23-29-15</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    6.7643 </td><td style=\"text-align: right;\">   1460.49 </td><td style=\"text-align: right;\">     1.32651</td><td style=\"text-align: right;\"> 2.64695e+18</td><td style=\"text-align: right;\"> 0.915855</td><td>172.26.215.93</td><td style=\"text-align: right;\">158456</td><td style=\"text-align: right;\">     2.90219</td><td style=\"text-align: right;\">     968.64 </td><td style=\"text-align: right;\">            14.7077 </td><td style=\"text-align: right;\">          3.98398 </td><td style=\"text-align: right;\">      14.7077 </td><td style=\"text-align: right;\"> 1691677755</td><td style=\"text-align: right;\">    1.50218 </td><td style=\"text-align: right;\">    0.556037</td><td style=\"text-align: right;\">  6.40151e+13</td><td style=\"text-align: right;\">  1.19966e+15</td><td style=\"text-align: right;\">                   4</td><td>bbab0ac2  </td><td style=\"text-align: right;\">     0.601945</td><td style=\"text-align: right;\">     0.31391 </td></tr>\n",
       "<tr><td>FSR_Trainable_bcae2507</td><td>2023-08-11_00-24-15</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    9.03069</td><td style=\"text-align: right;\">   2068.75 </td><td style=\"text-align: right;\">     2.14323</td><td style=\"text-align: right;\"> 4.73017e+18</td><td style=\"text-align: right;\"> 1.20968 </td><td>172.26.215.93</td><td style=\"text-align: right;\">179776</td><td style=\"text-align: right;\">     3.51704</td><td style=\"text-align: right;\">    1291.17 </td><td style=\"text-align: right;\">             1.46933</td><td style=\"text-align: right;\">          1.46933 </td><td style=\"text-align: right;\">       1.46933</td><td style=\"text-align: right;\"> 1691681055</td><td style=\"text-align: right;\">    2.07247 </td><td style=\"text-align: right;\">    0.75476 </td><td style=\"text-align: right;\">  9.29571e+13</td><td style=\"text-align: right;\">  1.75986e+15</td><td style=\"text-align: right;\">                   1</td><td>bcae2507  </td><td style=\"text-align: right;\">     0.807825</td><td style=\"text-align: right;\">     0.401855</td></tr>\n",
       "<tr><td>FSR_Trainable_be58cc31</td><td>2023-08-11_00-25-31</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.70691</td><td style=\"text-align: right;\">    669.042</td><td style=\"text-align: right;\">     1.11112</td><td style=\"text-align: right;\"> 8.92484e+17</td><td style=\"text-align: right;\"> 0.651867</td><td>172.26.215.93</td><td style=\"text-align: right;\">178087</td><td style=\"text-align: right;\">     2.4933 </td><td style=\"text-align: right;\">     452.309</td><td style=\"text-align: right;\">           310.361  </td><td style=\"text-align: right;\">          3.00668 </td><td style=\"text-align: right;\">     310.361  </td><td style=\"text-align: right;\"> 1691681131</td><td style=\"text-align: right;\">    1.00342 </td><td style=\"text-align: right;\">    0.270041</td><td style=\"text-align: right;\">  6.62336e+13</td><td style=\"text-align: right;\">  4.30277e+14</td><td style=\"text-align: right;\">                 100</td><td>be58cc31  </td><td style=\"text-align: right;\">     0.485423</td><td style=\"text-align: right;\">     0.166444</td></tr>\n",
       "<tr><td>FSR_Trainable_bec324cd</td><td>2023-08-11_00-12-12</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.93905</td><td style=\"text-align: right;\">    950.415</td><td style=\"text-align: right;\">     1.25875</td><td style=\"text-align: right;\"> 1.18934e+17</td><td style=\"text-align: right;\">54.939   </td><td>172.26.215.93</td><td style=\"text-align: right;\">175760</td><td style=\"text-align: right;\">     2.50095</td><td style=\"text-align: right;\">     757.85 </td><td style=\"text-align: right;\">             2.39563</td><td style=\"text-align: right;\">          2.39563 </td><td style=\"text-align: right;\">       2.39563</td><td style=\"text-align: right;\"> 1691680332</td><td style=\"text-align: right;\">   45.7767  </td><td style=\"text-align: right;\">    5.9235  </td><td style=\"text-align: right;\">  1.06837e+16</td><td style=\"text-align: right;\">  4.17242e+15</td><td style=\"text-align: right;\">                   1</td><td>bec324cd  </td><td style=\"text-align: right;\">    48.5654  </td><td style=\"text-align: right;\">     6.37353 </td></tr>\n",
       "<tr><td>FSR_Trainable_bf07bd58</td><td>2023-08-11_00-17-22</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">    5.52895</td><td style=\"text-align: right;\">    766.3  </td><td style=\"text-align: right;\">     1.23561</td><td style=\"text-align: right;\"> 1.26877e+18</td><td style=\"text-align: right;\"> 0.712785</td><td>172.26.215.93</td><td style=\"text-align: right;\">177078</td><td style=\"text-align: right;\">     2.66036</td><td style=\"text-align: right;\">     463.304</td><td style=\"text-align: right;\">            47.5248 </td><td style=\"text-align: right;\">          3.01654 </td><td style=\"text-align: right;\">      47.5248 </td><td style=\"text-align: right;\"> 1691680642</td><td style=\"text-align: right;\">    1.17329 </td><td style=\"text-align: right;\">    0.343551</td><td style=\"text-align: right;\">  6.58036e+13</td><td style=\"text-align: right;\">  6.98457e+14</td><td style=\"text-align: right;\">                  16</td><td>bf07bd58  </td><td style=\"text-align: right;\">     0.519346</td><td style=\"text-align: right;\">     0.193439</td></tr>\n",
       "<tr><td>FSR_Trainable_bf244b87</td><td>2023-08-11_00-04-50</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    5.43864</td><td style=\"text-align: right;\">    734.931</td><td style=\"text-align: right;\">     1.26506</td><td style=\"text-align: right;\"> 1.27033e+18</td><td style=\"text-align: right;\"> 0.695838</td><td>172.26.215.93</td><td style=\"text-align: right;\">173444</td><td style=\"text-align: right;\">     2.63131</td><td style=\"text-align: right;\">     456.757</td><td style=\"text-align: right;\">            75.5416 </td><td style=\"text-align: right;\">          3.12559 </td><td style=\"text-align: right;\">      75.5416 </td><td style=\"text-align: right;\"> 1691679890</td><td style=\"text-align: right;\">    1.14222 </td><td style=\"text-align: right;\">    0.32926 </td><td style=\"text-align: right;\">  6.87992e+13</td><td style=\"text-align: right;\">  6.94395e+14</td><td style=\"text-align: right;\">                  32</td><td>bf244b87  </td><td style=\"text-align: right;\">     0.51084 </td><td style=\"text-align: right;\">     0.184998</td></tr>\n",
       "<tr><td>FSR_Trainable_c3538732</td><td>2023-08-10_23-39-15</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.06549</td><td style=\"text-align: right;\">   1407.8  </td><td style=\"text-align: right;\">     1.31704</td><td style=\"text-align: right;\"> 2.7782e+18 </td><td style=\"text-align: right;\"> 0.820928</td><td>172.26.215.93</td><td style=\"text-align: right;\">162516</td><td style=\"text-align: right;\">     2.48723</td><td style=\"text-align: right;\">     944.722</td><td style=\"text-align: right;\">            59.2204 </td><td style=\"text-align: right;\">          6.9592  </td><td style=\"text-align: right;\">      59.2204 </td><td style=\"text-align: right;\"> 1691678355</td><td style=\"text-align: right;\">    1.10347 </td><td style=\"text-align: right;\">    0.512834</td><td style=\"text-align: right;\">  9.1092e+13 </td><td style=\"text-align: right;\">  1.09081e+15</td><td style=\"text-align: right;\">                   8</td><td>c3538732  </td><td style=\"text-align: right;\">     0.515939</td><td style=\"text-align: right;\">     0.304988</td></tr>\n",
       "<tr><td>FSR_Trainable_c3c06fa4</td><td>2023-08-11_00-24-59</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    7.45337</td><td style=\"text-align: right;\">   1785.79 </td><td style=\"text-align: right;\">     1.40329</td><td style=\"text-align: right;\"> 4.2526e+18 </td><td style=\"text-align: right;\"> 0.975127</td><td>172.26.215.93</td><td style=\"text-align: right;\">180263</td><td style=\"text-align: right;\">     3.14314</td><td style=\"text-align: right;\">    1176.92 </td><td style=\"text-align: right;\">             2.69088</td><td style=\"text-align: right;\">          2.69088 </td><td style=\"text-align: right;\">       2.69088</td><td style=\"text-align: right;\"> 1691681099</td><td style=\"text-align: right;\">    1.58839 </td><td style=\"text-align: right;\">    0.64178 </td><td style=\"text-align: right;\">  6.39717e+13</td><td style=\"text-align: right;\">  1.59581e+15</td><td style=\"text-align: right;\">                   1</td><td>c3c06fa4  </td><td style=\"text-align: right;\">     0.623251</td><td style=\"text-align: right;\">     0.351875</td></tr>\n",
       "<tr><td>FSR_Trainable_c3d55401</td><td>2023-08-10_23-47-47</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.20402</td><td style=\"text-align: right;\">   1472.59 </td><td style=\"text-align: right;\">     1.1451 </td><td style=\"text-align: right;\"> 1.09159e+09</td><td style=\"text-align: right;\"> 6.49169 </td><td>172.26.215.93</td><td style=\"text-align: right;\">169861</td><td style=\"text-align: right;\">     2.40924</td><td style=\"text-align: right;\">     986.505</td><td style=\"text-align: right;\">             1.75447</td><td style=\"text-align: right;\">          1.75447 </td><td style=\"text-align: right;\">       1.75447</td><td style=\"text-align: right;\"> 1691678867</td><td style=\"text-align: right;\">    7.7337  </td><td style=\"text-align: right;\">    3.33447 </td><td style=\"text-align: right;\">  1.38644e+15</td><td style=\"text-align: right;\"> 57.2239     </td><td style=\"text-align: right;\">                   1</td><td>c3d55401  </td><td style=\"text-align: right;\">     4.463   </td><td style=\"text-align: right;\">     2.02869 </td></tr>\n",
       "<tr><td>FSR_Trainable_c9d4e9c0</td><td>2023-08-10_23-38-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.27321</td><td style=\"text-align: right;\">   1422.04 </td><td style=\"text-align: right;\">     1.26493</td><td style=\"text-align: right;\"> 2.74242e+18</td><td style=\"text-align: right;\"> 0.845306</td><td>172.26.215.93</td><td style=\"text-align: right;\">162274</td><td style=\"text-align: right;\">     2.60159</td><td style=\"text-align: right;\">     949.305</td><td style=\"text-align: right;\">            10.3587 </td><td style=\"text-align: right;\">          2.27483 </td><td style=\"text-align: right;\">      10.3587 </td><td style=\"text-align: right;\"> 1691678280</td><td style=\"text-align: right;\">    1.15806 </td><td style=\"text-align: right;\">    0.508201</td><td style=\"text-align: right;\">  8.10163e+13</td><td style=\"text-align: right;\">  1.0383e+15 </td><td style=\"text-align: right;\">                   4</td><td>c9d4e9c0  </td><td style=\"text-align: right;\">     0.540212</td><td style=\"text-align: right;\">     0.305094</td></tr>\n",
       "<tr><td>FSR_Trainable_cb03759c</td><td>2023-08-11_00-26-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.77005</td><td style=\"text-align: right;\">    618.209</td><td style=\"text-align: right;\">     1.11279</td><td style=\"text-align: right;\"> 7.47258e+17</td><td style=\"text-align: right;\"> 0.651386</td><td>172.26.215.93</td><td style=\"text-align: right;\">179096</td><td style=\"text-align: right;\">     2.50003</td><td style=\"text-align: right;\">     430.724</td><td style=\"text-align: right;\">           143.249  </td><td style=\"text-align: right;\">          0.987713</td><td style=\"text-align: right;\">     143.249  </td><td style=\"text-align: right;\"> 1691681169</td><td style=\"text-align: right;\">    1.02318 </td><td style=\"text-align: right;\">    0.240635</td><td style=\"text-align: right;\">  6.84755e+13</td><td style=\"text-align: right;\">  3.36901e+14</td><td style=\"text-align: right;\">                 100</td><td>cb03759c  </td><td style=\"text-align: right;\">     0.495356</td><td style=\"text-align: right;\">     0.156029</td></tr>\n",
       "<tr><td>FSR_Trainable_cd75fee7</td><td>2023-08-10_23-41-28</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    3.77107</td><td style=\"text-align: right;\">   1429.42 </td><td style=\"text-align: right;\">     1.14735</td><td style=\"text-align: right;\"> 8.26575e+08</td><td style=\"text-align: right;\"> 6.47234 </td><td>172.26.215.93</td><td style=\"text-align: right;\">164112</td><td style=\"text-align: right;\">     2.36288</td><td style=\"text-align: right;\">     949.373</td><td style=\"text-align: right;\">             9.64496</td><td style=\"text-align: right;\">          9.64496 </td><td style=\"text-align: right;\">       9.64496</td><td style=\"text-align: right;\"> 1691678488</td><td style=\"text-align: right;\">    7.127   </td><td style=\"text-align: right;\">    3.37317 </td><td style=\"text-align: right;\">  3.78056e+14</td><td style=\"text-align: right;\">  9.16208    </td><td style=\"text-align: right;\">                   1</td><td>cd75fee7  </td><td style=\"text-align: right;\">     4.47381 </td><td style=\"text-align: right;\">     1.99853 </td></tr>\n",
       "<tr><td>FSR_Trainable_cf3dcb02</td><td>2023-08-10_23-48-26</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.60715</td><td style=\"text-align: right;\">    845.945</td><td style=\"text-align: right;\">     1.30426</td><td style=\"text-align: right;\"> 1.46589e+18</td><td style=\"text-align: right;\"> 0.753981</td><td>172.26.215.93</td><td style=\"text-align: right;\">168709</td><td style=\"text-align: right;\">     2.71987</td><td style=\"text-align: right;\">     642.952</td><td style=\"text-align: right;\">           108.932  </td><td style=\"text-align: right;\">          0.873126</td><td style=\"text-align: right;\">     108.932  </td><td style=\"text-align: right;\"> 1691678906</td><td style=\"text-align: right;\">    1.19982 </td><td style=\"text-align: right;\">    0.328374</td><td style=\"text-align: right;\">  8.568e+13  </td><td style=\"text-align: right;\">  6.43191e+14</td><td style=\"text-align: right;\">                 100</td><td>cf3dcb02  </td><td style=\"text-align: right;\">     0.543852</td><td style=\"text-align: right;\">     0.21013 </td></tr>\n",
       "<tr><td>FSR_Trainable_d1e87242</td><td>2023-08-10_23-34-50</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    4.85682</td><td style=\"text-align: right;\">   1462.27 </td><td style=\"text-align: right;\">     1.25917</td><td style=\"text-align: right;\"> 2.84611e+18</td><td style=\"text-align: right;\"> 0.834943</td><td>172.26.215.93</td><td style=\"text-align: right;\">160416</td><td style=\"text-align: right;\">     2.57432</td><td style=\"text-align: right;\">     966.305</td><td style=\"text-align: right;\">            18.7492 </td><td style=\"text-align: right;\">          2.15335 </td><td style=\"text-align: right;\">      18.7492 </td><td style=\"text-align: right;\"> 1691678090</td><td style=\"text-align: right;\">    1.06456 </td><td style=\"text-align: right;\">    0.529195</td><td style=\"text-align: right;\">  8.31864e+13</td><td style=\"text-align: right;\">  1.11724e+15</td><td style=\"text-align: right;\">                   8</td><td>d1e87242  </td><td style=\"text-align: right;\">     0.52648 </td><td style=\"text-align: right;\">     0.308462</td></tr>\n",
       "<tr><td>FSR_Trainable_d54316cd</td><td>2023-08-11_00-17-29</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    5.09537</td><td style=\"text-align: right;\">    635.839</td><td style=\"text-align: right;\">     1.17641</td><td style=\"text-align: right;\"> 7.12315e+17</td><td style=\"text-align: right;\"> 0.675833</td><td>172.26.215.93</td><td style=\"text-align: right;\">176761</td><td style=\"text-align: right;\">     2.60344</td><td style=\"text-align: right;\">     451.821</td><td style=\"text-align: right;\">           173.852  </td><td style=\"text-align: right;\">          3.25703 </td><td style=\"text-align: right;\">     173.852  </td><td style=\"text-align: right;\"> 1691680649</td><td style=\"text-align: right;\">    1.08654 </td><td style=\"text-align: right;\">    0.260698</td><td style=\"text-align: right;\">  6.62886e+13</td><td style=\"text-align: right;\">  3.7615e+14 </td><td style=\"text-align: right;\">                  64</td><td>d54316cd  </td><td style=\"text-align: right;\">     0.507302</td><td style=\"text-align: right;\">     0.168531</td></tr>\n",
       "<tr><td>FSR_Trainable_d77a286d</td><td>2023-08-10_23-34-16</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        32</td><td style=\"text-align: right;\">    6.05661</td><td style=\"text-align: right;\">   1234.53 </td><td style=\"text-align: right;\">     1.55688</td><td style=\"text-align: right;\"> 1.83574e+18</td><td style=\"text-align: right;\"> 0.869892</td><td>172.26.215.93</td><td style=\"text-align: right;\">159886</td><td style=\"text-align: right;\">     2.67949</td><td style=\"text-align: right;\">     979.634</td><td style=\"text-align: right;\">           134.37   </td><td style=\"text-align: right;\">          8.38924 </td><td style=\"text-align: right;\">     134.37   </td><td style=\"text-align: right;\"> 1691678056</td><td style=\"text-align: right;\">    1.29884 </td><td style=\"text-align: right;\">    0.414143</td><td style=\"text-align: right;\">  7.96127e+13</td><td style=\"text-align: right;\">  5.43593e+14</td><td style=\"text-align: right;\">                  32</td><td>d77a286d  </td><td style=\"text-align: right;\">     0.553891</td><td style=\"text-align: right;\">     0.316001</td></tr>\n",
       "<tr><td>FSR_Trainable_dc87d342</td><td>2023-08-11_00-11-53</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.62637</td><td style=\"text-align: right;\">    823.811</td><td style=\"text-align: right;\">     1.11151</td><td style=\"text-align: right;\"> 1.37376e+17</td><td style=\"text-align: right;\">53.6481  </td><td>172.26.215.93</td><td style=\"text-align: right;\">175533</td><td style=\"text-align: right;\">     2.4908 </td><td style=\"text-align: right;\">     680.835</td><td style=\"text-align: right;\">             2.69606</td><td style=\"text-align: right;\">          2.69606 </td><td style=\"text-align: right;\">       2.69606</td><td style=\"text-align: right;\"> 1691680313</td><td style=\"text-align: right;\">   44.7667  </td><td style=\"text-align: right;\">    5.28168 </td><td style=\"text-align: right;\">  8.49856e+15</td><td style=\"text-align: right;\">  4.43004e+15</td><td style=\"text-align: right;\">                   1</td><td>dc87d342  </td><td style=\"text-align: right;\">    47.7801  </td><td style=\"text-align: right;\">     5.86798 </td></tr>\n",
       "<tr><td>FSR_Trainable_dd2298d1</td><td>2023-08-10_23-30-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   15.903  </td><td style=\"text-align: right;\">   1530.61 </td><td style=\"text-align: right;\">     2.87517</td><td style=\"text-align: right;\"> 2.48691e+18</td><td style=\"text-align: right;\"> 1.55155 </td><td>172.26.215.93</td><td style=\"text-align: right;\">158930</td><td style=\"text-align: right;\">     5.4187 </td><td style=\"text-align: right;\">     998.2  </td><td style=\"text-align: right;\">            10.0603 </td><td style=\"text-align: right;\">          2.64765 </td><td style=\"text-align: right;\">      10.0603 </td><td style=\"text-align: right;\"> 1691677809</td><td style=\"text-align: right;\">    3.59389 </td><td style=\"text-align: right;\">    0.623371</td><td style=\"text-align: right;\">  5.87848e+13</td><td style=\"text-align: right;\">  1.26238e+15</td><td style=\"text-align: right;\">                   4</td><td>dd2298d1  </td><td style=\"text-align: right;\">     1.2031  </td><td style=\"text-align: right;\">     0.348452</td></tr>\n",
       "<tr><td>FSR_Trainable_e1cb6d85</td><td>2023-08-10_23-58-12</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.0636 </td><td style=\"text-align: right;\">    609.894</td><td style=\"text-align: right;\">     1.14864</td><td style=\"text-align: right;\"> 6.90549e+17</td><td style=\"text-align: right;\"> 0.654856</td><td>172.26.215.93</td><td style=\"text-align: right;\">171215</td><td style=\"text-align: right;\">     2.55424</td><td style=\"text-align: right;\">     444.951</td><td style=\"text-align: right;\">           244.771  </td><td style=\"text-align: right;\">          2.15093 </td><td style=\"text-align: right;\">     244.771  </td><td style=\"text-align: right;\"> 1691679492</td><td style=\"text-align: right;\">    1.06703 </td><td style=\"text-align: right;\">    0.245927</td><td style=\"text-align: right;\">  7.60461e+13</td><td style=\"text-align: right;\">  3.64109e+14</td><td style=\"text-align: right;\">                 100</td><td>e1cb6d85  </td><td style=\"text-align: right;\">     0.496825</td><td style=\"text-align: right;\">     0.158031</td></tr>\n",
       "<tr><td>FSR_Trainable_e3d65c71</td><td>2023-08-10_23-45-50</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    5.13126</td><td style=\"text-align: right;\">   1442.76 </td><td style=\"text-align: right;\">     1.26304</td><td style=\"text-align: right;\"> 2.95943e+18</td><td style=\"text-align: right;\"> 0.821049</td><td>172.26.215.93</td><td style=\"text-align: right;\">167774</td><td style=\"text-align: right;\">     2.52729</td><td style=\"text-align: right;\">     934.748</td><td style=\"text-align: right;\">            42.268  </td><td style=\"text-align: right;\">          5.77872 </td><td style=\"text-align: right;\">      42.268  </td><td style=\"text-align: right;\"> 1691678750</td><td style=\"text-align: right;\">    1.1141  </td><td style=\"text-align: right;\">    0.529472</td><td style=\"text-align: right;\">  9.01279e+13</td><td style=\"text-align: right;\">  1.16434e+15</td><td style=\"text-align: right;\">                   8</td><td>e3d65c71  </td><td style=\"text-align: right;\">     0.515942</td><td style=\"text-align: right;\">     0.305107</td></tr>\n",
       "<tr><td>FSR_Trainable_e3da12c6</td><td>2023-08-10_23-36-23</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    3.84597</td><td style=\"text-align: right;\">   1473.5  </td><td style=\"text-align: right;\">     1.12235</td><td style=\"text-align: right;\"> 8.58023e+08</td><td style=\"text-align: right;\"> 6.48848 </td><td>172.26.215.93</td><td style=\"text-align: right;\">161327</td><td style=\"text-align: right;\">     2.36753</td><td style=\"text-align: right;\">     963.858</td><td style=\"text-align: right;\">             2.83805</td><td style=\"text-align: right;\">          2.83805 </td><td style=\"text-align: right;\">       2.83805</td><td style=\"text-align: right;\"> 1691678183</td><td style=\"text-align: right;\">    7.32091 </td><td style=\"text-align: right;\">    3.4364  </td><td style=\"text-align: right;\">  5.14034e+14</td><td style=\"text-align: right;\"> 27.417      </td><td style=\"text-align: right;\">                   1</td><td>e3da12c6  </td><td style=\"text-align: right;\">     4.47511 </td><td style=\"text-align: right;\">     2.01338 </td></tr>\n",
       "<tr><td>FSR_Trainable_e4521cca</td><td>2023-08-10_23-43-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">    4.37045</td><td style=\"text-align: right;\">   1206.65 </td><td style=\"text-align: right;\">     1.17846</td><td style=\"text-align: right;\"> 4.76619e+16</td><td style=\"text-align: right;\">40.2124  </td><td>172.26.215.93</td><td style=\"text-align: right;\">165503</td><td style=\"text-align: right;\">     2.4066 </td><td style=\"text-align: right;\">     987.876</td><td style=\"text-align: right;\">             2.35977</td><td style=\"text-align: right;\">          2.35977 </td><td style=\"text-align: right;\">       2.35977</td><td style=\"text-align: right;\"> 1691678580</td><td style=\"text-align: right;\">   28.4986  </td><td style=\"text-align: right;\">    6.09389 </td><td style=\"text-align: right;\">  4.51146e+15</td><td style=\"text-align: right;\">  1.32387e+15</td><td style=\"text-align: right;\">                   1</td><td>e4521cca  </td><td style=\"text-align: right;\">    33.1771  </td><td style=\"text-align: right;\">     7.03528 </td></tr>\n",
       "<tr><td>FSR_Trainable_e7543495</td><td>2023-08-10_23-40-24</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">    5.63669</td><td style=\"text-align: right;\">   1300.27 </td><td style=\"text-align: right;\">     1.61432</td><td style=\"text-align: right;\"> 2.34448e+18</td><td style=\"text-align: right;\"> 0.840285</td><td>172.26.215.93</td><td style=\"text-align: right;\">163446</td><td style=\"text-align: right;\">     2.62842</td><td style=\"text-align: right;\">     944.345</td><td style=\"text-align: right;\">            23.1881 </td><td style=\"text-align: right;\">          6.26399 </td><td style=\"text-align: right;\">      23.1881 </td><td style=\"text-align: right;\"> 1691678424</td><td style=\"text-align: right;\">    1.21102 </td><td style=\"text-align: right;\">    0.455591</td><td style=\"text-align: right;\">  9.5175e+13 </td><td style=\"text-align: right;\">  8.35788e+14</td><td style=\"text-align: right;\">                   4</td><td>e7543495  </td><td style=\"text-align: right;\">     0.537892</td><td style=\"text-align: right;\">     0.302393</td></tr>\n",
       "<tr><td>FSR_Trainable_e8d5cf7d</td><td>2023-08-11_00-22-26</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.11415</td><td style=\"text-align: right;\">    662.231</td><td style=\"text-align: right;\">     1.12745</td><td style=\"text-align: right;\"> 9.68934e+17</td><td style=\"text-align: right;\"> 0.666451</td><td>172.26.215.93</td><td style=\"text-align: right;\">177295</td><td style=\"text-align: right;\">     2.5679 </td><td style=\"text-align: right;\">     428.766</td><td style=\"text-align: right;\">           314.132  </td><td style=\"text-align: right;\">          3.0416  </td><td style=\"text-align: right;\">     314.132  </td><td style=\"text-align: right;\"> 1691680946</td><td style=\"text-align: right;\">    1.08058 </td><td style=\"text-align: right;\">    0.283626</td><td style=\"text-align: right;\">  6.61813e+13</td><td style=\"text-align: right;\">  5.22406e+14</td><td style=\"text-align: right;\">                 100</td><td>e8d5cf7d  </td><td style=\"text-align: right;\">     0.499823</td><td style=\"text-align: right;\">     0.166628</td></tr>\n",
       "<tr><td>FSR_Trainable_e93ab1cc</td><td>2023-08-10_23-46-38</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.81784</td><td style=\"text-align: right;\">   1501.77 </td><td style=\"text-align: right;\">     1.30271</td><td style=\"text-align: right;\"> 3.16423e+18</td><td style=\"text-align: right;\"> 0.855831</td><td>172.26.215.93</td><td style=\"text-align: right;\">168941</td><td style=\"text-align: right;\">     2.78019</td><td style=\"text-align: right;\">     965.558</td><td style=\"text-align: right;\">             4.01892</td><td style=\"text-align: right;\">          1.7615  </td><td style=\"text-align: right;\">       4.01892</td><td style=\"text-align: right;\"> 1691678798</td><td style=\"text-align: right;\">    1.22248 </td><td style=\"text-align: right;\">    0.550209</td><td style=\"text-align: right;\">  8.2876e+13 </td><td style=\"text-align: right;\">  1.23946e+15</td><td style=\"text-align: right;\">                   2</td><td>e93ab1cc  </td><td style=\"text-align: right;\">     0.541671</td><td style=\"text-align: right;\">     0.31416 </td></tr>\n",
       "<tr><td>FSR_Trainable_ed1df145</td><td>2023-08-10_23-41-57</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">    4.777  </td><td style=\"text-align: right;\">   1432.84 </td><td style=\"text-align: right;\">     1.22302</td><td style=\"text-align: right;\"> 2.83126e+18</td><td style=\"text-align: right;\"> 0.822887</td><td>172.26.215.93</td><td style=\"text-align: right;\">164340</td><td style=\"text-align: right;\">     2.50208</td><td style=\"text-align: right;\">     945.867</td><td style=\"text-align: right;\">            21.0966 </td><td style=\"text-align: right;\">          2.98815 </td><td style=\"text-align: right;\">      21.0966 </td><td style=\"text-align: right;\"> 1691678517</td><td style=\"text-align: right;\">    1.05352 </td><td style=\"text-align: right;\">    0.51493 </td><td style=\"text-align: right;\">  8.29557e+13</td><td style=\"text-align: right;\">  1.0782e+15 </td><td style=\"text-align: right;\">                   8</td><td>ed1df145  </td><td style=\"text-align: right;\">     0.518576</td><td style=\"text-align: right;\">     0.304311</td></tr>\n",
       "<tr><td>FSR_Trainable_f1fd40db</td><td>2023-08-11_00-24-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.3982 </td><td style=\"text-align: right;\">   1375.44 </td><td style=\"text-align: right;\">     1.28751</td><td style=\"text-align: right;\"> 2.75162e+18</td><td style=\"text-align: right;\"> 0.822881</td><td>172.26.215.93</td><td style=\"text-align: right;\">179529</td><td style=\"text-align: right;\">     2.58985</td><td style=\"text-align: right;\">     903.013</td><td style=\"text-align: right;\">             3.08215</td><td style=\"text-align: right;\">          1.38654 </td><td style=\"text-align: right;\">       3.08215</td><td style=\"text-align: right;\"> 1691681040</td><td style=\"text-align: right;\">    1.16877 </td><td style=\"text-align: right;\">    0.503107</td><td style=\"text-align: right;\">  7.93302e+13</td><td style=\"text-align: right;\">  1.07353e+15</td><td style=\"text-align: right;\">                   2</td><td>f1fd40db  </td><td style=\"text-align: right;\">     0.526203</td><td style=\"text-align: right;\">     0.296678</td></tr>\n",
       "<tr><td>FSR_Trainable_f43b6b94</td><td>2023-08-11_00-19-34</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    4.90332</td><td style=\"text-align: right;\">    603.267</td><td style=\"text-align: right;\">     1.1079 </td><td style=\"text-align: right;\"> 6.45115e+17</td><td style=\"text-align: right;\"> 0.656251</td><td>172.26.215.93</td><td style=\"text-align: right;\">176525</td><td style=\"text-align: right;\">     2.5424 </td><td style=\"text-align: right;\">     441.658</td><td style=\"text-align: right;\">           317.369  </td><td style=\"text-align: right;\">          3.01648 </td><td style=\"text-align: right;\">     317.369  </td><td style=\"text-align: right;\"> 1691680774</td><td style=\"text-align: right;\">    1.04433 </td><td style=\"text-align: right;\">    0.24329 </td><td style=\"text-align: right;\">  6.45422e+13</td><td style=\"text-align: right;\">  3.36313e+14</td><td style=\"text-align: right;\">                 100</td><td>f43b6b94  </td><td style=\"text-align: right;\">     0.495274</td><td style=\"text-align: right;\">     0.160977</td></tr>\n",
       "<tr><td>FSR_Trainable_f4bdfb81</td><td>2023-08-10_23-37-35</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.20153</td><td style=\"text-align: right;\">   1439.43 </td><td style=\"text-align: right;\">     1.15338</td><td style=\"text-align: right;\"> 2.88212e+18</td><td style=\"text-align: right;\"> 0.800387</td><td>172.26.215.93</td><td style=\"text-align: right;\">157231</td><td style=\"text-align: right;\">     2.41009</td><td style=\"text-align: right;\">     951.312</td><td style=\"text-align: right;\">           644.835  </td><td style=\"text-align: right;\">         10.3161  </td><td style=\"text-align: right;\">     644.835  </td><td style=\"text-align: right;\"> 1691678255</td><td style=\"text-align: right;\">    0.92078 </td><td style=\"text-align: right;\">    0.520412</td><td style=\"text-align: right;\">  8.70142e+13</td><td style=\"text-align: right;\">  1.11128e+15</td><td style=\"text-align: right;\">                  64</td><td>f4bdfb81  </td><td style=\"text-align: right;\">     0.494232</td><td style=\"text-align: right;\">     0.306155</td></tr>\n",
       "<tr><td>FSR_Trainable_f73cb3c8</td><td>2023-08-11_00-02-43</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       100</td><td style=\"text-align: right;\">    5.04452</td><td style=\"text-align: right;\">    645.065</td><td style=\"text-align: right;\">     1.18302</td><td style=\"text-align: right;\"> 7.20733e+17</td><td style=\"text-align: right;\"> 0.671492</td><td>172.26.215.93</td><td style=\"text-align: right;\">171806</td><td style=\"text-align: right;\">     2.57121</td><td style=\"text-align: right;\">     464.648</td><td style=\"text-align: right;\">           299.854  </td><td style=\"text-align: right;\">          3.51262 </td><td style=\"text-align: right;\">     299.854  </td><td style=\"text-align: right;\"> 1691679763</td><td style=\"text-align: right;\">    1.07432 </td><td style=\"text-align: right;\">    0.259048</td><td style=\"text-align: right;\">  6.68604e+13</td><td style=\"text-align: right;\">  3.65596e+14</td><td style=\"text-align: right;\">                 100</td><td>f73cb3c8  </td><td style=\"text-align: right;\">     0.502992</td><td style=\"text-align: right;\">     0.1685  </td></tr>\n",
       "<tr><td>FSR_Trainable_fcd00d9b</td><td>2023-08-10_23-46-01</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">    5.66355</td><td style=\"text-align: right;\">   1169.12 </td><td style=\"text-align: right;\">     1.57162</td><td style=\"text-align: right;\"> 1.47247e+18</td><td style=\"text-align: right;\"> 0.860786</td><td>172.26.215.93</td><td style=\"text-align: right;\">168283</td><td style=\"text-align: right;\">     2.70154</td><td style=\"text-align: right;\">     963.426</td><td style=\"text-align: right;\">            11.3221 </td><td style=\"text-align: right;\">          4.71271 </td><td style=\"text-align: right;\">      11.3221 </td><td style=\"text-align: right;\"> 1691678761</td><td style=\"text-align: right;\">    1.20768 </td><td style=\"text-align: right;\">    0.387207</td><td style=\"text-align: right;\">  9.14204e+13</td><td style=\"text-align: right;\">  3.94989e+14</td><td style=\"text-align: right;\">                   2</td><td>fcd00d9b  </td><td style=\"text-align: right;\">     0.548883</td><td style=\"text-align: right;\">     0.311903</td></tr>\n",
       "<tr><td>FSR_Trainable_fec4be7a</td><td>2023-08-10_23-35-16</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">    4.32369</td><td style=\"text-align: right;\">   1414.64 </td><td style=\"text-align: right;\">     1.20541</td><td style=\"text-align: right;\"> 2.78073e+18</td><td style=\"text-align: right;\"> 0.802208</td><td>172.26.215.93</td><td style=\"text-align: right;\">160138</td><td style=\"text-align: right;\">     2.46297</td><td style=\"text-align: right;\">     939.49 </td><td style=\"text-align: right;\">           141.883  </td><td style=\"text-align: right;\">          2.2107  </td><td style=\"text-align: right;\">     141.883  </td><td style=\"text-align: right;\"> 1691678116</td><td style=\"text-align: right;\">    0.941575</td><td style=\"text-align: right;\">    0.509197</td><td style=\"text-align: right;\">  8.57339e+13</td><td style=\"text-align: right;\">  1.06173e+15</td><td style=\"text-align: right;\">                  64</td><td>fec4be7a  </td><td style=\"text-align: right;\">     0.49939 </td><td style=\"text-align: right;\">     0.302818</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_102a7f72_1_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-25-43/wandb/run-20230810_232554-102a7f72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Syncing run FSR_Trainable_102a7f72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/102a7f72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_b15e6191_2_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-25-49/wandb/run-20230810_232603-b15e6191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Syncing run FSR_Trainable_b15e6191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/b15e6191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                mae_coord 4.36319\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                mae_force 1382.37175\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               mape_coord 1.06326\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               mape_force 2.2140218310339738e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                   metric 54.6182\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               rmse_coord 2.49798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               rmse_force 999.39284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:       time_since_restore 2.8108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:         time_this_iter_s 2.8108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:             time_total_s 2.8108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:                timestamp 1691677559\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               tmae_coord 44.65614\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:               tmae_force 7.05835\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              tmape_coord 5166019474208949.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              tmape_force 7888169219993202.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              trmse_coord 48.29921\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:              trmse_force 6.31898\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb:  View run FSR_Trainable_b15e6191 at: https://wandb.ai/seokjin/FSR-prediction/runs/b15e6191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156529)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232603-b15e6191/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_306a3737_3_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-25-56/wandb/run-20230810_232613-306a3737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Syncing run FSR_Trainable_306a3737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/306a3737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                mae_coord 5.33431\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                mae_force 1472.13737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               mape_coord 1.38568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               mape_force 1062868624.84831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                   metric 7.12616\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               rmse_coord 2.51624\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               rmse_force 945.33852\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:       time_since_restore 2.47301\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:         time_this_iter_s 1.04157\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:             time_total_s 2.47301\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:                timestamp 1691677570\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               tmae_coord 9.75127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:               tmae_force 4.00419\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              tmape_coord 4224397721910259.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              tmape_force 255.57755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              trmse_coord 4.88079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:              trmse_force 2.24537\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb:  View run FSR_Trainable_306a3737 at: https://wandb.ai/seokjin/FSR-prediction/runs/306a3737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156703)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232613-306a3737/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6872dd1b_4_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-26-05/wandb/run-20230810_232625-6872dd1b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Syncing run FSR_Trainable_6872dd1b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6872dd1b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_10656ea1_5_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-26-15/wandb/run-20230810_232634-10656ea1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Syncing run FSR_Trainable_10656ea1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/10656ea1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: / 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                mae_coord 4.9502\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                mae_force 1172.1803\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               mape_coord 1.12039\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               mape_force 3.834777176721199e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                   metric 55.13953\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               rmse_coord 2.62324\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               rmse_force 966.01832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:       time_since_restore 4.97302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:         time_this_iter_s 4.97302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:             time_total_s 4.97302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:                timestamp 1691677591\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               tmae_coord 45.3279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:               tmae_force 6.08244\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              tmape_coord 7086174454540348.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              tmape_force 1926566413636327.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              trmse_coord 48.07365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:              trmse_force 7.06589\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb:  View run FSR_Trainable_10656ea1 at: https://wandb.ai/seokjin/FSR-prediction/runs/10656ea1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157118)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232634-10656ea1/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_f4bdfb81_6_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-26-26/wandb/run-20230810_232649-f4bdfb81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Syncing run FSR_Trainable_f4bdfb81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f4bdfb81\n",
      "2023-08-10 23:26:52,520\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.635 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:26:52,524\tWARNING util.py:315 -- The `process_trial_result` operation took 2.640 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:26:52,527\tWARNING util.py:315 -- Processing trial results took 2.643 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:26:52,529\tWARNING util.py:315 -- The `process_trial_result` operation took 2.645 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:27:03,722\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.523 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:27:03,726\tWARNING util.py:315 -- The `process_trial_result` operation took 2.528 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:27:03,729\tWARNING util.py:315 -- Processing trial results took 2.532 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:27:03,734\tWARNING util.py:315 -- The `process_trial_result` operation took 2.537 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_60a52149_7_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-26-39/wandb/run-20230810_232706-60a52149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Syncing run FSR_Trainable_60a52149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/60a52149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: \\ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                mae_coord 3.78615\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                mae_force 1443.45864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               mape_coord 1.10471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               mape_force 908804851.81602\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                   metric 6.49708\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               rmse_coord 2.36548\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               rmse_force 947.57137\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:       time_since_restore 93.16555\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:         time_this_iter_s 2.80451\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:             time_total_s 93.16555\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:                timestamp 1691677653\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               tmae_coord 7.22777\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:               tmae_force 3.48836\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              tmape_coord 549108156194159.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              tmape_force 19.57797\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              trmse_coord 4.48776\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:              trmse_force 2.00933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb:  View run FSR_Trainable_102a7f72 at: https://wandb.ai/seokjin/FSR-prediction/runs/102a7f72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156356)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232554-102a7f72/logs\n",
      "2023-08-10 23:27:52,739\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.594 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:27:52,745\tWARNING util.py:315 -- The `process_trial_result` operation took 2.601 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:27:52,750\tWARNING util.py:315 -- Processing trial results took 2.606 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:27:52,752\tWARNING util.py:315 -- The `process_trial_result` operation took 2.608 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_331fad73_8_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-26-55/wandb/run-20230810_232754-331fad73\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Syncing run FSR_Trainable_331fad73\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/331fad73\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                mae_coord 3.9289\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                mae_force 1435.45573\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               mape_coord 1.11988\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               mape_force 777431270.6641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                   metric 6.48703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               rmse_coord 2.35913\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               rmse_force 942.36399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:       time_since_restore 7.95958\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:         time_this_iter_s 3.83683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:             time_total_s 7.95958\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:                timestamp 1691677676\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               tmae_coord 7.49904\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:               tmae_force 3.4862\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              tmape_coord 1114987040507929.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              tmape_force 37.79655\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              trmse_coord 4.47741\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:              trmse_force 2.00961\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb:  View run FSR_Trainable_331fad73 at: https://wandb.ai/seokjin/FSR-prediction/runs/331fad73\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157811)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232754-331fad73/logs\n",
      "2023-08-10 23:28:20,789\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.827 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:28:20,793\tWARNING util.py:315 -- The `process_trial_result` operation took 2.832 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:28:20,796\tWARNING util.py:315 -- Processing trial results took 2.836 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:28:20,799\tWARNING util.py:315 -- The `process_trial_result` operation took 2.838 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_408c68c9_9_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simpl_2023-08-10_23-27-46/wandb/run-20230810_232824-408c68c9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Syncing run FSR_Trainable_408c68c9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/408c68c9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                mae_coord 4.66863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                mae_force 1193.12629\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               mape_coord 1.28356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               mape_force 3.0400304752707348e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                   metric 40.38091\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               rmse_coord 2.43723\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               rmse_force 976.67463\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:       time_since_restore 3.85516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:         time_this_iter_s 3.85516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:             time_total_s 3.85516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:                timestamp 1691677697\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               tmae_coord 28.8892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:               tmae_force 6.15426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              tmape_coord 5300154023046148.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              tmape_force 1737082077526888.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              trmse_coord 33.24158\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:              trmse_force 7.13933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb:  View run FSR_Trainable_408c68c9 at: https://wandb.ai/seokjin/FSR-prediction/runs/408c68c9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158047)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232824-408c68c9/logs\n",
      "2023-08-10 23:28:40,468\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.984 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:28:40,471\tWARNING util.py:315 -- The `process_trial_result` operation took 2.989 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:28:40,476\tWARNING util.py:315 -- Processing trial results took 2.994 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:28:40,479\tWARNING util.py:315 -- The `process_trial_result` operation took 2.996 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_7c0b9ad8_10_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-28-14/wandb/run-20230810_232844-7c0b9ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Syncing run FSR_Trainable_7c0b9ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7c0b9ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                mae_coord 21.72348\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                mae_force 3061.34279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               mape_coord 3.81695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               mape_force 6.464254782993102e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                   metric 2.33962\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               rmse_coord 7.42428\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               rmse_force 1616.37573\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:       time_since_restore 9.21296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:         time_this_iter_s 1.8457\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:             time_total_s 9.21296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:                timestamp 1691677727\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               tmae_coord 5.01124\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:               tmae_force 1.2837\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              tmape_coord 52677386748321.09\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              tmape_force 2970054253954061.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              trmse_coord 1.70065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:              trmse_force 0.63897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb:  View run FSR_Trainable_7c0b9ad8 at: https://wandb.ai/seokjin/FSR-prediction/runs/7c0b9ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158279)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232844-7c0b9ad8/logs\n",
      "2023-08-10 23:29:04,349\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.019 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:29:04,352\tWARNING util.py:315 -- The `process_trial_result` operation took 2.022 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:29:04,354\tWARNING util.py:315 -- Processing trial results took 2.024 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:29:04,355\tWARNING util.py:315 -- The `process_trial_result` operation took 2.025 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bbab0ac2_11_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-28-35/wandb/run-20230810_232905-bbab0ac2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Syncing run FSR_Trainable_bbab0ac2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bbab0ac2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                mae_coord 6.7643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                mae_force 1460.49369\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               mape_coord 1.32651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               mape_force 2.646951859784423e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                   metric 0.91585\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               rmse_coord 2.90219\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               rmse_force 968.64006\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:       time_since_restore 14.70768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:         time_this_iter_s 3.98398\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:             time_total_s 14.70768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:                timestamp 1691677755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               tmae_coord 1.50218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:               tmae_force 0.55604\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              tmape_coord 64015141769778.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              tmape_force 1199661590205228.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              trmse_coord 0.60194\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:              trmse_force 0.31391\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb:  View run FSR_Trainable_bbab0ac2 at: https://wandb.ai/seokjin/FSR-prediction/runs/bbab0ac2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158514)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232905-bbab0ac2/logs\n",
      "2023-08-10 23:29:35,868\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.284 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:29:35,873\tWARNING util.py:315 -- The `process_trial_result` operation took 2.289 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:29:35,875\tWARNING util.py:315 -- Processing trial results took 2.291 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:29:35,877\tWARNING util.py:315 -- The `process_trial_result` operation took 2.293 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_841d9a78_12_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-28-58/wandb/run-20230810_232938-841d9a78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Syncing run FSR_Trainable_841d9a78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/841d9a78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: / 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                mae_coord 7.66743\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                mae_force 1558.65293\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               mape_coord 1.60878\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               mape_force 3.168517019168777e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                   metric 0.94581\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               rmse_coord 3.00157\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               rmse_force 974.90922\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:       time_since_restore 10.11287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:         time_this_iter_s 2.24131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:             time_total_s 10.11287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:                timestamp 1691677783\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               tmae_coord 1.6261\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:               tmae_force 0.60745\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              tmape_coord 79468617902849.77\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              tmape_force 1421940197448380.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              trmse_coord 0.61406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:              trmse_force 0.33175\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb:  View run FSR_Trainable_841d9a78 at: https://wandb.ai/seokjin/FSR-prediction/runs/841d9a78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158752)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232938-841d9a78/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                mae_coord 4.81683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                mae_force 1454.90892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               mape_coord 1.198\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               mape_force 2.958814488114105e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                   metric 0.80832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               rmse_coord 2.45688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               rmse_force 943.68957\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:       time_since_restore 200.6403\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:         time_this_iter_s 2.08851\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:             time_total_s 200.6403\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:                timestamp 1691677793\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               tmae_coord 1.04233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:               tmae_force 0.53714\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              tmape_coord 86745626089550.12\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              tmape_force 1189304285782465.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              trmse_coord 0.50154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:              trmse_force 0.30678\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb:  View run FSR_Trainable_6872dd1b at: https://wandb.ai/seokjin/FSR-prediction/runs/6872dd1b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=156892)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232625-6872dd1b/logs\n",
      "2023-08-10 23:30:02,225\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.628 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:02,230\tWARNING util.py:315 -- The `process_trial_result` operation took 2.635 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:02,231\tWARNING util.py:315 -- Processing trial results took 2.636 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:30:02,233\tWARNING util.py:315 -- The `process_trial_result` operation took 2.638 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_dd2298d1_13_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-29-30/wandb/run-20230810_233005-dd2298d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Syncing run FSR_Trainable_dd2298d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/dd2298d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                mae_coord 15.90297\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                mae_force 1530.61284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               mape_coord 2.87517\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               mape_force 2.4869055836183654e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                   metric 1.55155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               rmse_coord 5.4187\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               rmse_force 998.19981\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:       time_since_restore 10.06035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:         time_this_iter_s 2.64765\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:             time_total_s 10.06035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:                timestamp 1691677809\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               tmae_coord 3.59389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:               tmae_force 0.62337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              tmape_coord 58784789050188.15\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              tmape_force 1262378146355900.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              trmse_coord 1.2031\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:              trmse_force 0.34845\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb:  View run FSR_Trainable_dd2298d1 at: https://wandb.ai/seokjin/FSR-prediction/runs/dd2298d1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=158996)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233005-dd2298d1/logs\n",
      "2023-08-10 23:30:16,213\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.975 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:16,214\tWARNING util.py:315 -- The `process_trial_result` operation took 1.979 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:16,217\tWARNING util.py:315 -- Processing trial results took 1.982 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:30:16,221\tWARNING util.py:315 -- The `process_trial_result` operation took 1.985 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_698f5feb_14_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-29-57/wandb/run-20230810_233020-698f5feb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Syncing run FSR_Trainable_698f5feb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/698f5feb\n",
      "2023-08-10 23:30:34,982\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.021 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:34,987\tWARNING util.py:315 -- The `process_trial_result` operation took 2.027 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:30:34,989\tWARNING util.py:315 -- Processing trial results took 2.029 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:30:34,990\tWARNING util.py:315 -- The `process_trial_result` operation took 2.030 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a6c859de_15_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-30-12/wandb/run-20230810_233035-a6c859de\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Syncing run FSR_Trainable_a6c859de\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a6c859de\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                mae_coord 5.81741\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                mae_force 1334.09358\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               mape_coord 1.45266\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               mape_force 2.478613522071098e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                   metric 0.84067\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               rmse_coord 2.60839\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               rmse_force 954.99475\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:       time_since_restore 44.63252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:         time_this_iter_s 5.51462\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:             time_total_s 44.63252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:                timestamp 1691677874\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               tmae_coord 1.24369\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:               tmae_force 0.47472\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              tmape_coord 81691089157971.67\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              tmape_force 917048318181859.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              trmse_coord 0.53405\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:              trmse_force 0.30662\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb:  View run FSR_Trainable_a6c859de at: https://wandb.ai/seokjin/FSR-prediction/runs/a6c859de\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159445)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233035-a6c859de/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_9cb367ce_16_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-30-27/wandb/run-20230810_233135-9cb367ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Syncing run FSR_Trainable_9cb367ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/9cb367ce\n",
      "2023-08-10 23:31:43,704\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.120 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:31:43,708\tWARNING util.py:315 -- The `process_trial_result` operation took 2.124 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:31:43,710\tWARNING util.py:315 -- Processing trial results took 2.127 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:31:43,712\tWARNING util.py:315 -- The `process_trial_result` operation took 2.128 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                mae_coord 4.55035\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                mae_force 1056.73557\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               mape_coord 1.20262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               mape_force 1.8605837365171013e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                   metric 0.74627\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               rmse_coord 2.44309\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               rmse_force 719.54893\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:       time_since_restore 270.94168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:         time_this_iter_s 1.95343\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:             time_total_s 270.94168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:                timestamp 1691677903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               tmae_coord 0.97715\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:               tmae_force 0.39834\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              tmape_coord 80373287627659.66\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              tmape_force 750519982745107.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              trmse_coord 0.49571\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:              trmse_force 0.25057\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb:  View run FSR_Trainable_60a52149 at: https://wandb.ai/seokjin/FSR-prediction/runs/60a52149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157560)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232706-60a52149/logs\n",
      "2023-08-10 23:32:02,677\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.544 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:32:02,682\tWARNING util.py:315 -- The `process_trial_result` operation took 2.550 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:32:02,684\tWARNING util.py:315 -- Processing trial results took 2.552 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:32:02,686\tWARNING util.py:315 -- The `process_trial_result` operation took 2.554 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_d77a286d_17_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-31-27/wandb/run-20230810_233205-d77a286d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Syncing run FSR_Trainable_d77a286d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d77a286d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                mae_coord 5.87438\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                mae_force 606.66985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               mape_coord 1.32919\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               mape_force 7.012310280263078e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                   metric 0.70894\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               rmse_coord 2.83091\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               rmse_force 451.13399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:       time_since_restore 132.53888\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:         time_this_iter_s 1.072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:             time_total_s 132.53888\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:                timestamp 1691677954\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               tmae_coord 1.24222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:               tmae_force 0.24119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              tmape_coord 81469436415948.62\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              tmape_force 354460055636132.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              trmse_coord 0.55102\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:              trmse_force 0.15792\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb:  View run FSR_Trainable_698f5feb at: https://wandb.ai/seokjin/FSR-prediction/runs/698f5feb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159221)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233020-698f5feb/logs\n",
      "2023-08-10 23:32:52,900\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.772 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:32:52,906\tWARNING util.py:315 -- The `process_trial_result` operation took 2.779 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:32:52,909\tWARNING util.py:315 -- Processing trial results took 2.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:32:52,913\tWARNING util.py:315 -- The `process_trial_result` operation took 2.786 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_fec4be7a_18_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-31-57/wandb/run-20230810_233255-fec4be7a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Syncing run FSR_Trainable_fec4be7a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fec4be7a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                mae_coord 6.05661\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                mae_force 1234.52673\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               mape_coord 1.55688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               mape_force 1.8357444222781655e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                   metric 0.86989\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               rmse_coord 2.67949\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               rmse_force 979.63391\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:       time_since_restore 134.36999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:         time_this_iter_s 8.38924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:             time_total_s 134.36999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:                timestamp 1691678056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               tmae_coord 1.29884\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:               tmae_force 0.41414\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              tmape_coord 79612680738462.23\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              tmape_force 543593108960148.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              trmse_coord 0.55389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:              trmse_force 0.316\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb:  View run FSR_Trainable_d77a286d at: https://wandb.ai/seokjin/FSR-prediction/runs/d77a286d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159943)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233205-d77a286d/logs\n",
      "2023-08-10 23:34:33,860\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.719 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:34:33,866\tWARNING util.py:315 -- The `process_trial_result` operation took 2.727 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:34:33,870\tWARNING util.py:315 -- Processing trial results took 2.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:34:33,873\tWARNING util.py:315 -- The `process_trial_result` operation took 2.734 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_d1e87242_19_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-32-47/wandb/run-20230810_233436-d1e87242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Syncing run FSR_Trainable_d1e87242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d1e87242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                mae_coord 4.85682\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                mae_force 1462.26664\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               mape_coord 1.25917\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               mape_force 2.84611236723531e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                   metric 0.83494\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               rmse_coord 2.57432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               rmse_force 966.30498\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:       time_since_restore 18.7492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:         time_this_iter_s 2.15335\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:             time_total_s 18.7492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:                timestamp 1691678090\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               tmae_coord 1.06456\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:               tmae_force 0.52919\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              tmape_coord 83186359638889.11\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              tmape_force 1117244859804538.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              trmse_coord 0.52648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:              trmse_force 0.30846\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb:  View run FSR_Trainable_d1e87242 at: https://wandb.ai/seokjin/FSR-prediction/runs/d1e87242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160470)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233436-d1e87242/logs\n",
      "2023-08-10 23:35:09,742\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.226 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:35:09,749\tWARNING util.py:315 -- The `process_trial_result` operation took 2.233 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:35:09,752\tWARNING util.py:315 -- Processing trial results took 2.235 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:35:09,753\tWARNING util.py:315 -- The `process_trial_result` operation took 2.237 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_28642b0a_20_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-34-28/wandb/run-20230810_233510-28642b0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Syncing run FSR_Trainable_28642b0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/28642b0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                mae_coord 4.32369\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                mae_force 1414.64075\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               mape_coord 1.20541\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               mape_force 2.7807327469056333e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                   metric 0.80221\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               rmse_coord 2.46297\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               rmse_force 939.49049\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:       time_since_restore 141.88325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:         time_this_iter_s 2.2107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:             time_total_s 141.88325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:                timestamp 1691678116\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               tmae_coord 0.94157\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:               tmae_force 0.5092\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              tmape_coord 85733860098670.45\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              tmape_force 1061725550060038.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              trmse_coord 0.49939\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:              trmse_force 0.30282\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb:  View run FSR_Trainable_fec4be7a at: https://wandb.ai/seokjin/FSR-prediction/runs/fec4be7a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160194)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233255-fec4be7a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 23:35:40,653\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.962 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:35:40,657\tWARNING util.py:315 -- The `process_trial_result` operation took 2.968 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:35:40,662\tWARNING util.py:315 -- Processing trial results took 2.973 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:35:40,664\tWARNING util.py:315 -- The `process_trial_result` operation took 2.975 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_0daa8344_21_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-35-02/wandb/run-20230810_233540-0daa8344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Syncing run FSR_Trainable_0daa8344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0daa8344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                mae_coord 4.97571\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                mae_force 1429.93233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               mape_coord 1.24618\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               mape_force 2.778051859888056e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                   metric 0.83394\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               rmse_coord 2.57443\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               rmse_force 949.13286\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:       time_since_restore 39.60046\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:         time_this_iter_s 5.35054\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:             time_total_s 39.60046\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:                timestamp 1691678146\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               tmae_coord 1.08903\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:               tmae_force 0.51655\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              tmape_coord 82508456530542.53\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              tmape_force 1081219455704154.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              trmse_coord 0.5294\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:              trmse_force 0.30454\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb:  View run FSR_Trainable_28642b0a at: https://wandb.ai/seokjin/FSR-prediction/runs/28642b0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160707)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233510-28642b0a/logs\n",
      "2023-08-10 23:36:06,217\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.105 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:06,224\tWARNING util.py:315 -- The `process_trial_result` operation took 3.113 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:06,229\tWARNING util.py:315 -- Processing trial results took 3.118 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:36:06,231\tWARNING util.py:315 -- The `process_trial_result` operation took 3.120 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_96f85d46_22_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-35-31/wandb/run-20230810_233609-96f85d46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Syncing run FSR_Trainable_96f85d46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/96f85d46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                mae_coord 23.32891\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                mae_force 1761.12761\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               mape_coord 3.64599\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               mape_force 1.8746313201745915e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                   metric 2.09335\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               rmse_coord 7.48558\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               rmse_force 1299.12616\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:       time_since_restore 2.83159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:         time_this_iter_s 2.83159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:             time_total_s 2.83159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:                timestamp 1691678163\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               tmae_coord 5.33548\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:               tmae_force 0.64785\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              tmape_coord 25156266613269.996\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              tmape_force 939295196832193.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              trmse_coord 1.69791\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:              trmse_force 0.39544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb:  View run FSR_Trainable_96f85d46 at: https://wandb.ai/seokjin/FSR-prediction/runs/96f85d46\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161183)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233609-96f85d46/logs\n",
      "2023-08-10 23:36:26,342\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.603 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:26,350\tWARNING util.py:315 -- The `process_trial_result` operation took 2.613 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:26,353\tWARNING util.py:315 -- Processing trial results took 2.616 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:36:26,359\tWARNING util.py:315 -- The `process_trial_result` operation took 2.622 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e3da12c6_23_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-36-00/wandb/run-20230810_233629-e3da12c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Syncing run FSR_Trainable_e3da12c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e3da12c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                mae_coord 3.84597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                mae_force 1473.50233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               mape_coord 1.12235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               mape_force 858022563.46349\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                   metric 6.48848\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               rmse_coord 2.36753\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               rmse_force 963.85771\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:       time_since_restore 2.83805\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:         time_this_iter_s 2.83805\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:             time_total_s 2.83805\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:                timestamp 1691678183\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               tmae_coord 7.32091\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:               tmae_force 3.4364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              tmape_coord 514034454161191.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              tmape_force 27.41695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              trmse_coord 4.47511\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:              trmse_force 2.01338\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb:  View run FSR_Trainable_e3da12c6 at: https://wandb.ai/seokjin/FSR-prediction/runs/e3da12c6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161412)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233629-e3da12c6/logs\n",
      "2023-08-10 23:36:44,768\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.511 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:44,771\tWARNING util.py:315 -- The `process_trial_result` operation took 2.516 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:36:44,773\tWARNING util.py:315 -- Processing trial results took 2.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:36:44,777\tWARNING util.py:315 -- The `process_trial_result` operation took 2.521 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_517ec18a_24_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-36-20/wandb/run-20230810_233647-517ec18a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Syncing run FSR_Trainable_517ec18a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/517ec18a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                mae_coord 4.20545\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                mae_force 1002.07471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               mape_coord 1.11562\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               mape_force 1.7572523371263418e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                   metric 39.44955\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               rmse_coord 2.39518\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               rmse_force 785.1317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:       time_since_restore 2.56528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:         time_this_iter_s 2.56528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:             time_total_s 2.56528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:                timestamp 1691678202\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               tmae_coord 28.53833\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:               tmae_force 6.21475\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              tmape_coord 3916701460647780.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              tmape_force 6757121101281876.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              trmse_coord 33.37527\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:              trmse_force 6.07428\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb:  View run FSR_Trainable_517ec18a at: https://wandb.ai/seokjin/FSR-prediction/runs/517ec18a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161640)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233647-517ec18a/logs\n",
      "2023-08-10 23:37:04,128\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.402 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:04,133\tWARNING util.py:315 -- The `process_trial_result` operation took 2.409 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:04,135\tWARNING util.py:315 -- Processing trial results took 2.410 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:37:04,138\tWARNING util.py:315 -- The `process_trial_result` operation took 2.414 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bad38ad8_25_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-36-39/wandb/run-20230810_233707-bad38ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Syncing run FSR_Trainable_bad38ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bad38ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                mae_coord 4.21637\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                mae_force 1057.92238\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               mape_coord 1.06687\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               mape_force 1.7346282805258778e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                   metric 38.91422\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               rmse_coord 2.40601\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               rmse_force 871.34291\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:       time_since_restore 5.08934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:         time_this_iter_s 5.08934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:             time_total_s 5.08934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:                timestamp 1691678221\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               tmae_coord 28.46387\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:               tmae_force 5.93441\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              tmape_coord 4336644026242043.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              tmape_force 6520122952891103.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              trmse_coord 32.9435\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:              trmse_force 5.97072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb:  View run FSR_Trainable_bad38ad8 at: https://wandb.ai/seokjin/FSR-prediction/runs/bad38ad8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=161869)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233707-bad38ad8/logs\n",
      "2023-08-10 23:37:22,409\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.787 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:22,414\tWARNING util.py:315 -- The `process_trial_result` operation took 2.793 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:22,416\tWARNING util.py:315 -- Processing trial results took 2.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:37:22,418\tWARNING util.py:315 -- The `process_trial_result` operation took 2.796 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_93fa7cd9_26_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-36-56/wandb/run-20230810_233724-93fa7cd9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Syncing run FSR_Trainable_93fa7cd9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/93fa7cd9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                mae_coord 4.20153\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                mae_force 1439.43015\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               mape_coord 1.15338\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               mape_force 2.8821194719630536e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                   metric 0.80039\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               rmse_coord 2.41009\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               rmse_force 951.3122\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:       time_since_restore 644.83507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:         time_this_iter_s 10.31608\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:             time_total_s 644.83507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:                timestamp 1691678255\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               tmae_coord 0.92078\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:               tmae_force 0.52041\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              tmape_coord 87014171946749.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              tmape_force 1111284210972300.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              trmse_coord 0.49423\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:              trmse_force 0.30615\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb:  View run FSR_Trainable_f4bdfb81 at: https://wandb.ai/seokjin/FSR-prediction/runs/f4bdfb81\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=157337)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_232649-f4bdfb81/logs\n",
      "2023-08-10 23:37:53,258\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.558 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:53,264\tWARNING util.py:315 -- The `process_trial_result` operation took 2.565 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:37:53,268\tWARNING util.py:315 -- Processing trial results took 2.569 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:37:53,270\tWARNING util.py:315 -- The `process_trial_result` operation took 2.571 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_c9d4e9c0_27_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-37-16/wandb/run-20230810_233755-c9d4e9c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Syncing run FSR_Trainable_c9d4e9c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c9d4e9c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                mae_coord 5.27321\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                mae_force 1422.04241\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               mape_coord 1.26493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               mape_force 2.742420867280011e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                   metric 0.84531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               rmse_coord 2.60159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               rmse_force 949.30497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:       time_since_restore 10.3587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:         time_this_iter_s 2.27483\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:             time_total_s 10.3587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:                timestamp 1691678280\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               tmae_coord 1.15806\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:               tmae_force 0.5082\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              tmape_coord 81016296683321.64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              tmape_force 1038300273790129.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              trmse_coord 0.54021\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:              trmse_force 0.30509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb:  View run FSR_Trainable_c9d4e9c0 at: https://wandb.ai/seokjin/FSR-prediction/runs/c9d4e9c0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162333)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233755-c9d4e9c0/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162095)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_c3538732_28_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-37-47/wandb/run-20230810_233819-c3538732\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Syncing run FSR_Trainable_c3538732\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c3538732\n",
      "2023-08-10 23:38:21,710\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.425 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:38:21,715\tWARNING util.py:315 -- The `process_trial_result` operation took 2.432 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:38:21,717\tWARNING util.py:315 -- Processing trial results took 2.434 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:38:21,719\tWARNING util.py:315 -- The `process_trial_result` operation took 2.436 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6adba9f2_29_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-38-11/wandb/run-20230810_233831-6adba9f2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Syncing run FSR_Trainable_6adba9f2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6adba9f2\n",
      "2023-08-10 23:38:39,291\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.508 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:38:39,296\tWARNING util.py:315 -- The `process_trial_result` operation took 2.513 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:38:39,297\tWARNING util.py:315 -- Processing trial results took 2.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:38:39,300\tWARNING util.py:315 -- The `process_trial_result` operation took 2.517 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)08 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                mae_coord 5.94905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                mae_force 1174.37634\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               mape_coord 1.59666\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               mape_force 1.4085718503354345e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                   metric 0.8796\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               rmse_coord 2.76479\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               rmse_force 955.64399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:       time_since_restore 25.67148\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:         time_this_iter_s 12.42032\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:             time_total_s 25.67148\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:                timestamp 1691678331\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               tmae_coord 1.27172\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:               tmae_force 0.3991\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              tmape_coord 90282046824482.98\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              tmape_force 418389074529180.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              trmse_coord 0.56522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:              trmse_force 0.31438\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb:  View run FSR_Trainable_6adba9f2 at: https://wandb.ai/seokjin/FSR-prediction/runs/6adba9f2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162793)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233831-6adba9f2/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_3318cfcb_30_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-38-23/wandb/run-20230810_233912-3318cfcb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Syncing run FSR_Trainable_3318cfcb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3318cfcb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                mae_coord 5.06549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                mae_force 1407.79982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               mape_coord 1.31704\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               mape_force 2.778197987012102e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                   metric 0.82093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               rmse_coord 2.48723\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               rmse_force 944.72188\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:       time_since_restore 59.22044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:         time_this_iter_s 6.9592\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:             time_total_s 59.22044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:                timestamp 1691678355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               tmae_coord 1.10347\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:               tmae_force 0.51283\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              tmape_coord 91092024549203.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              tmape_force 1090808052450386.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              trmse_coord 0.51594\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:              trmse_force 0.30499\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb:  View run FSR_Trainable_c3538732 at: https://wandb.ai/seokjin/FSR-prediction/runs/c3538732\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=162580)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233819-c3538732/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_27422225_31_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-39-03/wandb/run-20230810_233934-27422225\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Syncing run FSR_Trainable_27422225\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/27422225\n",
      "2023-08-10 23:39:38,533\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.042 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:39:38,535\tWARNING util.py:315 -- The `process_trial_result` operation took 2.045 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:39:38,539\tWARNING util.py:315 -- Processing trial results took 2.049 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:39:38,540\tWARNING util.py:315 -- The `process_trial_result` operation took 2.050 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:39:45,348\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.668 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:39:45,350\tWARNING util.py:315 -- The `process_trial_result` operation took 2.671 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:39:45,353\tWARNING util.py:315 -- Processing trial results took 2.674 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:39:45,360\tWARNING util.py:315 -- The `process_trial_result` operation took 2.681 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                mae_coord 5.8053\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                mae_force 1164.2702\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               mape_coord 1.55026\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               mape_force 1.2730855282185746e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                   metric 0.87522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               rmse_coord 2.7432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               rmse_force 962.78208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:       time_since_restore 17.30044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:         time_this_iter_s 7.83127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:             time_total_s 17.30044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:                timestamp 1691678386\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               tmae_coord 1.23365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:               tmae_force 0.39266\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              tmape_coord 90247145401383.31\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              tmape_force 345391782333548.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              trmse_coord 0.55722\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:              trmse_force 0.318\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb:  View run FSR_Trainable_27422225 at: https://wandb.ai/seokjin/FSR-prediction/runs/27422225\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163254)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233934-27422225/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 23:40:07,324\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.571 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:40:07,331\tWARNING util.py:315 -- The `process_trial_result` operation took 2.579 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:40:07,333\tWARNING util.py:315 -- Processing trial results took 2.582 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:40:07,337\tWARNING util.py:315 -- The `process_trial_result` operation took 2.585 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e7543495_32_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-39-27/wandb/run-20230810_234006-e7543495\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Syncing run FSR_Trainable_e7543495\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e7543495\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                mae_coord 5.63669\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                mae_force 1300.2729\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               mape_coord 1.61432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               mape_force 2.3444760852718147e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                   metric 0.84029\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               rmse_coord 2.62842\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               rmse_force 944.34464\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:       time_since_restore 23.18815\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:         time_this_iter_s 6.26399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:             time_total_s 23.18815\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:                timestamp 1691678424\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               tmae_coord 1.21102\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:               tmae_force 0.45559\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              tmape_coord 95174968784179.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              tmape_force 835788271134987.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              trmse_coord 0.53789\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:              trmse_force 0.30239\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb:  View run FSR_Trainable_e7543495 at: https://wandb.ai/seokjin/FSR-prediction/runs/e7543495\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163501)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234006-e7543495/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_3e3ca0ec_33_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-39-58/wandb/run-20230810_234044-3e3ca0ec\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Syncing run FSR_Trainable_3e3ca0ec\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3e3ca0ec\n",
      "2023-08-10 23:40:49,329\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.279 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:40:49,335\tWARNING util.py:315 -- The `process_trial_result` operation took 2.286 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:40:49,338\tWARNING util.py:315 -- Processing trial results took 2.289 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:40:49,343\tWARNING util.py:315 -- The `process_trial_result` operation took 2.293 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)08 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                mae_coord 5.39546\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                mae_force 1171.88759\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               mape_coord 1.31081\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               mape_force 744812197.61523\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                   metric 7.04069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               rmse_coord 2.63208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               rmse_force 839.99133\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:       time_since_restore 10.59422\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:         time_this_iter_s 10.59422\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:             time_total_s 10.59422\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:                timestamp 1691678447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               tmae_coord 9.92972\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:               tmae_force 3.1346\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              tmape_coord 3578022639105054.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              tmape_force 275.50454\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              trmse_coord 4.93602\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:              trmse_force 2.10467\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb:  View run FSR_Trainable_3e3ca0ec at: https://wandb.ai/seokjin/FSR-prediction/runs/3e3ca0ec\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163742)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234044-3e3ca0ec/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                mae_coord 5.62804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                mae_force 1216.32404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               mape_coord 1.51554\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               mape_force 1.4659467540809846e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                   metric 0.8709\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               rmse_coord 2.69271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               rmse_force 968.08073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:       time_since_restore 119.15763\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:         time_this_iter_s 80.28497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:             time_total_s 119.15763\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:                timestamp 1691678465\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               tmae_coord 1.20799\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:               tmae_force 0.4109\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              tmape_coord 89978170812234.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              tmape_force 413275467923801.6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              trmse_coord 0.54972\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:              trmse_force 0.32117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb:  View run FSR_Trainable_3318cfcb at: https://wandb.ai/seokjin/FSR-prediction/runs/3318cfcb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163034)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233912-3318cfcb/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "2023-08-10 23:41:12,453\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.459 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:12,459\tWARNING util.py:315 -- The `process_trial_result` operation took 2.466 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:12,461\tWARNING util.py:315 -- Processing trial results took 2.468 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:41:12,463\tWARNING util.py:315 -- The `process_trial_result` operation took 2.470 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_7d0169a8_34_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-40-36/wandb/run-20230810_234110-7d0169a8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Syncing run FSR_Trainable_7d0169a8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7d0169a8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                mae_coord 5.01242\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                mae_force 1257.55576\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               mape_coord 1.46477\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               mape_force 468590374.959\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                   metric 6.72597\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               rmse_coord 2.53395\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               rmse_force 986.41145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:       time_since_restore 8.62426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:         time_this_iter_s 8.62426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:             time_total_s 8.62426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:                timestamp 1691678469\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               tmae_coord 9.06855\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:               tmae_force 2.77399\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              tmape_coord 2743428287890237.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              tmape_force 78.70294\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              trmse_coord 4.67529\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:              trmse_force 2.05068\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb:  View run FSR_Trainable_7d0169a8 at: https://wandb.ai/seokjin/FSR-prediction/runs/7d0169a8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=163979)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234110-7d0169a8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_cd75fee7_35_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-41-01/wandb/run-20230810_234127-cd75fee7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Syncing run FSR_Trainable_cd75fee7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/cd75fee7\n",
      "2023-08-10 23:41:30,479\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.416 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:30,483\tWARNING util.py:315 -- The `process_trial_result` operation took 2.421 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:30,489\tWARNING util.py:315 -- Processing trial results took 2.427 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:41:30,493\tWARNING util.py:315 -- The `process_trial_result` operation took 2.431 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                mae_coord 3.77107\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                mae_force 1429.42183\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               mape_coord 1.14735\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               mape_force 826575117.83059\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                   metric 6.47234\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               rmse_coord 2.36288\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               rmse_force 949.37339\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:       time_since_restore 9.64496\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:         time_this_iter_s 9.64496\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:             time_total_s 9.64496\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:                timestamp 1691678488\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               tmae_coord 7.127\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:               tmae_force 3.37317\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              tmape_coord 378055959737789.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              tmape_force 9.16208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              trmse_coord 4.47381\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:              trmse_force 1.99853\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb:  View run FSR_Trainable_cd75fee7 at: https://wandb.ai/seokjin/FSR-prediction/runs/cd75fee7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164220)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234127-cd75fee7/logs\n",
      "2023-08-10 23:41:37,414\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.823 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:37,418\tWARNING util.py:315 -- The `process_trial_result` operation took 2.829 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:37,423\tWARNING util.py:315 -- Processing trial results took 2.834 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:41:37,424\tWARNING util.py:315 -- The `process_trial_result` operation took 2.835 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_ed1df145_36_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-41-18/wandb/run-20230810_234142-ed1df145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Syncing run FSR_Trainable_ed1df145\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/ed1df145\n",
      "2023-08-10 23:41:49,787\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.455 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:49,794\tWARNING util.py:315 -- The `process_trial_result` operation took 2.463 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:41:49,796\tWARNING util.py:315 -- Processing trial results took 2.464 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:41:49,799\tWARNING util.py:315 -- The `process_trial_result` operation took 2.468 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6078457f_37_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-41-31/wandb/run-20230810_234152-6078457f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Syncing run FSR_Trainable_6078457f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6078457f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                mae_coord 25.54175\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                mae_force 1584.76603\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               mape_coord 4.0478\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               mape_force 1.2329214741618737e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                   metric 2.13754\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               rmse_coord 8.28123\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               rmse_force 1373.49338\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:       time_since_restore 2.97755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:         time_this_iter_s 2.97755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:             time_total_s 2.97755\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:                timestamp 1691678507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               tmae_coord 5.59152\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:               tmae_force 0.50024\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              tmape_coord 12619200918646.293\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              tmape_force 450804445789171.06\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              trmse_coord 1.75503\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:              trmse_force 0.38251\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb:  View run FSR_Trainable_6078457f at: https://wandb.ai/seokjin/FSR-prediction/runs/6078457f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164665)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234152-6078457f/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234142-ed1df145/logs\n",
      "2023-08-10 23:42:09,079\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.802 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:09,084\tWARNING util.py:315 -- The `process_trial_result` operation took 2.808 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:09,086\tWARNING util.py:315 -- Processing trial results took 2.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:42:09,089\tWARNING util.py:315 -- The `process_trial_result` operation took 2.813 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164440)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_5be7df8b_38_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-41-44/wandb/run-20230810_234212-5be7df8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Syncing run FSR_Trainable_5be7df8b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/5be7df8b\n",
      "2023-08-10 23:42:23,216\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.576 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:23,222\tWARNING util.py:315 -- The `process_trial_result` operation took 2.584 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:23,225\tWARNING util.py:315 -- Processing trial results took 2.586 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:42:23,227\tWARNING util.py:315 -- The `process_trial_result` operation took 2.588 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_1c248ea4_39_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-42-03/wandb/run-20230810_234230-1c248ea4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Syncing run FSR_Trainable_1c248ea4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1c248ea4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: / 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                mae_coord 27.87118\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                mae_force 1508.88045\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               mape_coord 4.40688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               mape_force 2.2016965134837064e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                   metric 2.35812\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               rmse_coord 8.97485\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               rmse_force 1007.51851\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:       time_since_restore 2.69863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:         time_this_iter_s 2.69863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:             time_total_s 2.69863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:                timestamp 1691678540\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               tmae_coord 6.26571\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:               tmae_force 0.63276\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              tmape_coord 24314008266880.562\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              tmape_force 1128304175705368.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              trmse_coord 1.99205\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:              trmse_force 0.36607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb:  View run FSR_Trainable_1c248ea4 at: https://wandb.ai/seokjin/FSR-prediction/runs/1c248ea4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165122)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234230-1c248ea4/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "2023-08-10 23:42:48,984\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.647 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:48,990\tWARNING util.py:315 -- The `process_trial_result` operation took 2.654 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:42:48,995\tWARNING util.py:315 -- Processing trial results took 2.659 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:42:48,998\tWARNING util.py:315 -- The `process_trial_result` operation took 2.663 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=164908)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_591ef7b6_40_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-42-18/wandb/run-20230810_234252-591ef7b6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Syncing run FSR_Trainable_591ef7b6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/591ef7b6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                mae_coord 21.98219\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                mae_force 1629.42897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               mape_coord 3.68064\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               mape_force 3.138965974389512e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                   metric 1.86966\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               rmse_coord 7.29082\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               rmse_force 1004.59888\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:       time_since_restore 2.95831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:         time_this_iter_s 2.95831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:             time_total_s 2.95831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:                timestamp 1691678566\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               tmae_coord 4.85151\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:               tmae_force 0.63533\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              tmape_coord 17213082282519.057\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              tmape_force 1445788298549049.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              trmse_coord 1.53325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:              trmse_force 0.3364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb:  View run FSR_Trainable_591ef7b6 at: https://wandb.ai/seokjin/FSR-prediction/runs/591ef7b6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234252-591ef7b6/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165389)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2023-08-10 23:43:03,264\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.923 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:03,270\tWARNING util.py:315 -- The `process_trial_result` operation took 2.931 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:03,272\tWARNING util.py:315 -- Processing trial results took 2.933 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:43:03,274\tWARNING util.py:315 -- The `process_trial_result` operation took 2.935 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e4521cca_41_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-42-43/wandb/run-20230810_234309-e4521cca\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Syncing run FSR_Trainable_e4521cca\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e4521cca\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                mae_coord 4.37045\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                mae_force 1206.64708\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               mape_coord 1.17846\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               mape_force 4.766186187743226e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                   metric 40.21243\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               rmse_coord 2.4066\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               rmse_force 987.87581\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:       time_since_restore 2.35977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:         time_this_iter_s 2.35977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:             time_total_s 2.35977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:                timestamp 1691678580\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               tmae_coord 28.49863\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:               tmae_force 6.09389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              tmape_coord 4511464882647196.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              tmape_force 1323870804577249.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              trmse_coord 33.17715\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:              trmse_force 7.03528\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb:  View run FSR_Trainable_e4521cca at: https://wandb.ai/seokjin/FSR-prediction/runs/e4521cca\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165610)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234309-e4521cca/logs\n",
      "2023-08-10 23:43:16,483\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.933 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:16,488\tWARNING util.py:315 -- The `process_trial_result` operation took 2.938 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:16,490\tWARNING util.py:315 -- Processing trial results took 2.941 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:43:16,492\tWARNING util.py:315 -- The `process_trial_result` operation took 2.942 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_3743b7d6_42_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-42-58/wandb/run-20230810_234319-3743b7d6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Syncing run FSR_Trainable_3743b7d6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/3743b7d6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                mae_coord 4.16215\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                mae_force 1246.6584\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               mape_coord 1.14113\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               mape_force 2.0753831920044372e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                   metric 40.39675\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               rmse_coord 2.38845\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               rmse_force 1143.17331\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:       time_since_restore 2.94978\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:         time_this_iter_s 2.94978\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:             time_total_s 2.94978\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:                timestamp 1691678593\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               tmae_coord 28.08761\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:               tmae_force 6.17826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              tmape_coord 3175212944133643.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              tmape_force 818479394196726.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              trmse_coord 33.19873\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:              trmse_force 7.19803\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb:  View run FSR_Trainable_3743b7d6 at: https://wandb.ai/seokjin/FSR-prediction/runs/3743b7d6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=165826)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234319-3743b7d6/logs\n",
      "2023-08-10 23:43:30,856\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.117 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:30,862\tWARNING util.py:315 -- The `process_trial_result` operation took 3.123 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:30,863\tWARNING util.py:315 -- Processing trial results took 3.125 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:43:30,866\tWARNING util.py:315 -- The `process_trial_result` operation took 3.128 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_585cd643_43_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-43-10/wandb/run-20230810_234332-585cd643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Syncing run FSR_Trainable_585cd643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/585cd643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                mae_coord 4.23701\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                mae_force 1145.32569\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               mape_coord 1.14484\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               mape_force 5.9301571154382696e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                   metric 40.12715\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               rmse_coord 2.42826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               rmse_force 958.62649\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:       time_since_restore 3.95117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:         time_this_iter_s 3.95117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:             time_total_s 3.95117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:                timestamp 1691678607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               tmae_coord 28.554\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:               tmae_force 5.98329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              tmape_coord 4458419635700749.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              tmape_force 1641549680065246.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              trmse_coord 33.08715\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:              trmse_force 7.04\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb:  View run FSR_Trainable_585cd643 at: https://wandb.ai/seokjin/FSR-prediction/runs/585cd643\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166061)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234332-585cd643/logs\n",
      "2023-08-10 23:43:43,570\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.404 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:43,575\tWARNING util.py:315 -- The `process_trial_result` operation took 2.410 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:43,580\tWARNING util.py:315 -- Processing trial results took 2.415 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:43:43,599\tWARNING util.py:315 -- The `process_trial_result` operation took 2.435 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_31e77bab_44_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-43-23/wandb/run-20230810_234345-31e77bab\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Syncing run FSR_Trainable_31e77bab\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/31e77bab\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                mae_coord 26.27793\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                mae_force 2792.02982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               mape_coord 4.53116\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               mape_force 6.141383499226716e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                   metric 2.47475\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               rmse_coord 8.89721\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               rmse_force 1446.18251\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:       time_since_restore 3.7364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:         time_this_iter_s 3.7364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:             time_total_s 3.7364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:                timestamp 1691678621\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               tmae_coord 5.77772\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:               tmae_force 1.18656\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              tmape_coord 57843689795038.13\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              tmape_force 2816480411638045.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              trmse_coord 1.89926\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:              trmse_force 0.57549\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb:  View run FSR_Trainable_31e77bab at: https://wandb.ai/seokjin/FSR-prediction/runs/31e77bab\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166288)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234345-31e77bab/logs\n",
      "2023-08-10 23:43:54,526\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.834 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:54,533\tWARNING util.py:315 -- The `process_trial_result` operation took 2.842 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:43:54,535\tWARNING util.py:315 -- Processing trial results took 2.844 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:43:54,537\tWARNING util.py:315 -- The `process_trial_result` operation took 2.846 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_7674b648_45_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-43-37/wandb/run-20230810_234356-7674b648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Syncing run FSR_Trainable_7674b648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7674b648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                mae_coord 5.85389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                mae_force 771.65527\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               mape_coord 1.25699\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               mape_force 8.61843657218934e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                   metric 0.72871\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               rmse_coord 2.7996\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               rmse_force 581.25326\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:       time_since_restore 474.34132\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:         time_this_iter_s 5.00901\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:             time_total_s 474.34132\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:                timestamp 1691678632\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               tmae_coord 1.21466\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:               tmae_force 0.28999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              tmape_coord 71754137161270.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              tmape_force 378670216662469.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              trmse_coord 0.53284\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:              trmse_force 0.19587\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb:  View run FSR_Trainable_0daa8344 at: https://wandb.ai/seokjin/FSR-prediction/runs/0daa8344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=160942)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233540-0daa8344/logs\n",
      "2023-08-10 23:44:04,651\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.270 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:04,655\tWARNING util.py:315 -- The `process_trial_result` operation took 2.275 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:04,656\tWARNING util.py:315 -- Processing trial results took 2.277 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:44:04,657\tWARNING util.py:315 -- The `process_trial_result` operation took 2.278 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166527)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234356-7674b648/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_27be0a03_46_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-43-49/wandb/run-20230810_234406-27be0a03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Syncing run FSR_Trainable_27be0a03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/27be0a03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                mae_coord 26.96992\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                mae_force 3176.16875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               mape_coord 4.11658\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               mape_force 4.919802028349221e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                   metric 2.54253\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               rmse_coord 8.60395\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               rmse_force 2034.62103\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:       time_since_restore 2.32211\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:         time_this_iter_s 2.32211\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:             time_total_s 2.32211\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:                timestamp 1691678642\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               tmae_coord 6.12897\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:               tmae_force 1.05988\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              tmape_coord 47733180852693.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              tmape_force 1853921761142084.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              trmse_coord 1.96022\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:              trmse_force 0.58231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb:  View run FSR_Trainable_27be0a03 at: https://wandb.ai/seokjin/FSR-prediction/runs/27be0a03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166764)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234406-27be0a03/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6c66e650_47_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-44-00/wandb/run-20230810_234418-6c66e650\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Syncing run FSR_Trainable_6c66e650\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6c66e650\n",
      "2023-08-10 23:44:23,409\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:23,410\tWARNING util.py:315 -- The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:23,411\tWARNING util.py:315 -- Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:44:23,412\tWARNING util.py:315 -- The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:29,243\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.808 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:29,246\tWARNING util.py:315 -- The `process_trial_result` operation took 2.812 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:29,249\tWARNING util.py:315 -- Processing trial results took 2.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:44:29,254\tWARNING util.py:315 -- The `process_trial_result` operation took 2.820 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_096272f9_48_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-44-10/wandb/run-20230810_234431-096272f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Syncing run FSR_Trainable_096272f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/096272f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: | 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                mae_coord 8.63391\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                mae_force 1498.85447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               mape_coord 1.49474\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               mape_force 3.0041138555016786e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                   metric 0.97785\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               rmse_coord 3.34404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               rmse_force 949.74072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:       time_since_restore 5.28859\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:         time_this_iter_s 2.40362\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:             time_total_s 5.28859\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:                timestamp 1691678671\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               tmae_coord 1.82469\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:               tmae_force 0.56234\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              tmape_coord 72004009675919.39\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              tmape_force 1260785018239779.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              trmse_coord 0.6651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:              trmse_force 0.31275\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb:  View run FSR_Trainable_096272f9 at: https://wandb.ai/seokjin/FSR-prediction/runs/096272f9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167207)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234431-096272f9/logs\n",
      "2023-08-10 23:44:41,156\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.543 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:41,164\tWARNING util.py:315 -- The `process_trial_result` operation took 2.551 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:41,166\tWARNING util.py:315 -- Processing trial results took 2.553 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:44:41,168\tWARNING util.py:315 -- The `process_trial_result` operation took 2.555 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_2ede7356_49_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-44-23/wandb/run-20230810_234443-2ede7356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Syncing run FSR_Trainable_2ede7356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/2ede7356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: | 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                mae_coord 8.26093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                mae_force 1434.78826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               mape_coord 1.53348\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               mape_force 2.72936202708417e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                   metric 0.96502\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               rmse_coord 3.23655\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               rmse_force 943.36233\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:       time_since_restore 5.73593\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:         time_this_iter_s 2.71496\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:             time_total_s 5.73593\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:                timestamp 1691678683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               tmae_coord 1.74711\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:               tmae_force 0.53112\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              tmape_coord 78530166972589.55\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              tmape_force 1116855269612220.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              trmse_coord 0.65271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:              trmse_force 0.31231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb:  View run FSR_Trainable_2ede7356 at: https://wandb.ai/seokjin/FSR-prediction/runs/2ede7356\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167429)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234443-2ede7356/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-08-10 23:44:58,061\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.985 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:58,066\tWARNING util.py:315 -- The `process_trial_result` operation took 2.992 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:44:58,068\tWARNING util.py:315 -- Processing trial results took 2.994 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:44:58,070\tWARNING util.py:315 -- The `process_trial_result` operation took 2.996 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6dc65d0f_50_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-44-35/wandb/run-20230810_234457-6dc65d0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Syncing run FSR_Trainable_6dc65d0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6dc65d0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: iterations_since_restore 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                mae_coord 5.25445\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                mae_force 1459.4999\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               mape_coord 1.25936\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               mape_force 3.0118989914469417e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                   metric 0.841\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               rmse_coord 2.57883\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               rmse_force 963.17443\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:       time_since_restore 46.45061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:         time_this_iter_s 13.24213\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:             time_total_s 46.45061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:                timestamp 1691678698\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               tmae_coord 1.14204\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:               tmae_force 0.53124\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              tmape_coord 92719442369367.92\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              tmape_force 1167375724308540.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:       training_iteration 4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              trmse_coord 0.53003\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:              trmse_force 0.31097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb:  View run FSR_Trainable_6c66e650 at: https://wandb.ai/seokjin/FSR-prediction/runs/6c66e650\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=166988)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234418-6c66e650/logs\n",
      "2023-08-10 23:45:14,332\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.349 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:14,337\tWARNING util.py:315 -- The `process_trial_result` operation took 3.355 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:14,339\tWARNING util.py:315 -- Processing trial results took 3.356 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:45:14,340\tWARNING util.py:315 -- The `process_trial_result` operation took 3.358 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e3d65c71_51_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-44-47/wandb/run-20230810_234514-e3d65c71\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Syncing run FSR_Trainable_e3d65c71\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e3d65c71\n",
      "2023-08-10 23:45:27,934\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.623 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:27,938\tWARNING util.py:315 -- The `process_trial_result` operation took 2.628 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:27,939\tWARNING util.py:315 -- Processing trial results took 2.629 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:45:27,940\tWARNING util.py:315 -- The `process_trial_result` operation took 2.631 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_64cfa6a4_52_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-45-04/wandb/run-20230810_234528-64cfa6a4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Syncing run FSR_Trainable_64cfa6a4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/64cfa6a4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: \\ 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                mae_coord 5.92604\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                mae_force 1151.09617\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               mape_coord 1.61944\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               mape_force 1.1009648866967466e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                   metric 0.8797\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               rmse_coord 2.7736\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               rmse_force 957.47278\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:       time_since_restore 10.81406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:         time_this_iter_s 4.84724\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:             time_total_s 10.81406\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:                timestamp 1691678732\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               tmae_coord 1.25945\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:               tmae_force 0.3844\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              tmape_coord 90591800155140.75\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              tmape_force 286508339269822.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              trmse_coord 0.56302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:              trmse_force 0.31669\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb:  View run FSR_Trainable_64cfa6a4 at: https://wandb.ai/seokjin/FSR-prediction/runs/64cfa6a4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168100)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234528-64cfa6a4/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: iterations_since_restore 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                mae_coord 5.13126\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                mae_force 1442.75789\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               mape_coord 1.26304\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               mape_force 2.9594304184263066e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                   metric 0.82105\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               rmse_coord 2.52729\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               rmse_force 934.74847\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:       time_since_restore 42.26797\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:         time_this_iter_s 5.77872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:             time_total_s 42.26797\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:                timestamp 1691678750\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               tmae_coord 1.1141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:               tmae_force 0.52947\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              tmape_coord 90127875962543.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              tmape_force 1164338693147894.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:       training_iteration 8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              trmse_coord 0.51594\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:              trmse_force 0.30511\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb:  View run FSR_Trainable_e3d65c71 at: https://wandb.ai/seokjin/FSR-prediction/runs/e3d65c71\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167888)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234514-e3d65c71/logs\n",
      "2023-08-10 23:45:57,251\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.525 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:57,256\tWARNING util.py:315 -- The `process_trial_result` operation took 2.531 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:45:57,258\tWARNING util.py:315 -- Processing trial results took 2.533 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:45:57,263\tWARNING util.py:315 -- The `process_trial_result` operation took 2.538 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_fcd00d9b_53_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-45-19/wandb/run-20230810_234600-fcd00d9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Syncing run FSR_Trainable_fcd00d9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/fcd00d9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                mae_coord 5.66355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                mae_force 1169.12295\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               mape_coord 1.57162\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               mape_force 1.4724655159353126e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                   metric 0.86079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               rmse_coord 2.70154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               rmse_force 963.42623\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:       time_since_restore 11.32208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:         time_this_iter_s 4.71271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:             time_total_s 11.32208\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:                timestamp 1691678761\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               tmae_coord 1.20768\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:               tmae_force 0.38721\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              tmape_coord 91420380150201.12\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              tmape_force 394988513692780.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              trmse_coord 0.54888\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:              trmse_force 0.3119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb:  View run FSR_Trainable_fcd00d9b at: https://wandb.ai/seokjin/FSR-prediction/runs/fcd00d9b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168339)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234600-fcd00d9b/logs\n",
      "2023-08-10 23:46:08,553\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.262 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:08,560\tWARNING util.py:315 -- The `process_trial_result` operation took 2.269 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:08,561\tWARNING util.py:315 -- Processing trial results took 2.271 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:46:08,564\tWARNING util.py:315 -- The `process_trial_result` operation took 2.273 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_85129490_54_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-45-48/wandb/run-20230810_234611-85129490\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Syncing run FSR_Trainable_85129490\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/85129490\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                mae_coord 25.86901\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                mae_force 1469.36365\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               mape_coord 4.20478\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               mape_force 1.9859851173603502e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                   metric 2.23912\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               rmse_coord 8.66016\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               rmse_force 1089.76368\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:       time_since_restore 2.14952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:         time_this_iter_s 2.14952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:             time_total_s 2.14952\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:                timestamp 1691678766\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               tmae_coord 5.77095\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:               tmae_force 0.57461\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              tmape_coord 19856615073894.152\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              tmape_force 1039072168053729.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              trmse_coord 1.88459\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:              trmse_force 0.35453\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb:  View run FSR_Trainable_85129490 at: https://wandb.ai/seokjin/FSR-prediction/runs/85129490\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168574)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234611-85129490/logs\n",
      "2023-08-10 23:46:21,559\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.668 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:21,564\tWARNING util.py:315 -- The `process_trial_result` operation took 2.674 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:21,565\tWARNING util.py:315 -- Processing trial results took 2.676 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:46:21,567\tWARNING util.py:315 -- The `process_trial_result` operation took 2.678 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_cf3dcb02_55_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-46-04/wandb/run-20230810_234625-cf3dcb02\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Syncing run FSR_Trainable_cf3dcb02\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/cf3dcb02\n",
      "2023-08-10 23:46:36,870\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.199 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:36,873\tWARNING util.py:315 -- The `process_trial_result` operation took 2.202 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:36,875\tWARNING util.py:315 -- Processing trial results took 2.204 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:46:36,878\tWARNING util.py:315 -- The `process_trial_result` operation took 2.207 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e93ab1cc_56_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-46-17/wandb/run-20230810_234639-e93ab1cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Syncing run FSR_Trainable_e93ab1cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e93ab1cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                mae_coord 5.81784\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                mae_force 1501.76668\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               mape_coord 1.30271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               mape_force 3.164234009796236e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                   metric 0.85583\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               rmse_coord 2.78019\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               rmse_force 965.55778\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:       time_since_restore 4.01892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:         time_this_iter_s 1.7615\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:             time_total_s 4.01892\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:                timestamp 1691678798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               tmae_coord 1.22248\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:               tmae_force 0.55021\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              tmape_coord 82876020644056.48\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              tmape_force 1239459977911525.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              trmse_coord 0.54167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:              trmse_force 0.31416\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb:  View run FSR_Trainable_e93ab1cc at: https://wandb.ai/seokjin/FSR-prediction/runs/e93ab1cc\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169023)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234639-e93ab1cc/logs\n",
      "2023-08-10 23:46:56,320\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.674 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:56,324\tWARNING util.py:315 -- The `process_trial_result` operation took 2.678 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:46:56,330\tWARNING util.py:315 -- Processing trial results took 2.684 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:46:56,334\tWARNING util.py:315 -- The `process_trial_result` operation took 2.688 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a76f516b_57_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-46-32/wandb/run-20230810_234659-a76f516b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Syncing run FSR_Trainable_a76f516b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a76f516b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                mae_coord 17.69598\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                mae_force 2493.27579\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               mape_coord 2.43247\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               mape_force 4.734532307313862e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                   metric 1.78563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               rmse_coord 6.83658\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               rmse_force 1631.65149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:       time_since_restore 2.50164\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:         time_this_iter_s 2.50164\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:             time_total_s 2.50164\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:                timestamp 1691678813\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               tmae_coord 3.58366\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:               tmae_force 0.86504\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              tmape_coord 44974746555644.35\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              tmape_force 1606722909207608.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              trmse_coord 1.26814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:              trmse_force 0.51749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb:  View run FSR_Trainable_a76f516b at: https://wandb.ai/seokjin/FSR-prediction/runs/a76f516b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169255)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234659-a76f516b/logs\n",
      "2023-08-10 23:47:12,374\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.386 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:12,380\tWARNING util.py:315 -- The `process_trial_result` operation took 2.393 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:12,382\tWARNING util.py:315 -- Processing trial results took 2.395 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:47:12,384\tWARNING util.py:315 -- The `process_trial_result` operation took 2.396 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a86dc0e6_58_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-46-51/wandb/run-20230810_234718-a86dc0e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Syncing run FSR_Trainable_a86dc0e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a86dc0e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: / 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                mae_coord 24.34764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                mae_force 3180.46141\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               mape_coord 5.01523\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               mape_force 4.692667815495114e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                   metric 2.32986\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               rmse_coord 8.66764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               rmse_force 2084.30987\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:       time_since_restore 1.25728\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:         time_this_iter_s 1.25728\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:             time_total_s 1.25728\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:                timestamp 1691678829\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               tmae_coord 5.19906\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:               tmae_force 1.16172\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              tmape_coord 54638682154660.734\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              tmape_force 2253998069250437.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              trmse_coord 1.70601\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:              trmse_force 0.62385\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb:  View run FSR_Trainable_a86dc0e6 at: https://wandb.ai/seokjin/FSR-prediction/runs/a86dc0e6\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169484)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234718-a86dc0e6/logs\n",
      "2023-08-10 23:47:30,952\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.630 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:30,962\tWARNING util.py:315 -- The `process_trial_result` operation took 2.642 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:30,965\tWARNING util.py:315 -- Processing trial results took 2.645 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:47:30,969\tWARNING util.py:315 -- The `process_trial_result` operation took 2.649 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_54d09832_59_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-47-08/wandb/run-20230810_234734-54d09832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Syncing run FSR_Trainable_54d09832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/54d09832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                mae_coord 4.09872\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                mae_force 1408.0746\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               mape_coord 1.14061\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               mape_force 754100846.07163\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                   metric 6.50713\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               rmse_coord 2.39572\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               rmse_force 972.60364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:       time_since_restore 2.23724\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:         time_this_iter_s 2.23724\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:             time_total_s 2.23724\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:                timestamp 1691678848\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               tmae_coord 7.79294\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:               tmae_force 3.21462\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              tmape_coord 1298163514225625.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              tmape_force 76.45834\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              trmse_coord 4.5108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:              trmse_force 1.99633\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb:  View run FSR_Trainable_54d09832 at: https://wandb.ai/seokjin/FSR-prediction/runs/54d09832\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169713)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234734-54d09832/logs\n",
      "2023-08-10 23:47:50,869\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.388 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:50,877\tWARNING util.py:315 -- The `process_trial_result` operation took 3.397 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:47:50,879\tWARNING util.py:315 -- Processing trial results took 3.399 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:47:50,880\tWARNING util.py:315 -- The `process_trial_result` operation took 3.400 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_c3d55401_60_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-47-26/wandb/run-20230810_234754-c3d55401\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Syncing run FSR_Trainable_c3d55401\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c3d55401\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                mae_coord 4.20402\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                mae_force 1472.58826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               mape_coord 1.1451\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               mape_force 1091591498.94954\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                   metric 6.49169\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               rmse_coord 2.40924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               rmse_force 986.50459\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:       time_since_restore 1.75447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:         time_this_iter_s 1.75447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:             time_total_s 1.75447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:                timestamp 1691678867\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               tmae_coord 7.7337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:               tmae_force 3.33447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              tmape_coord 1386443419736072.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              tmape_force 57.22389\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              trmse_coord 4.463\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:              trmse_force 2.02869\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb:  View run FSR_Trainable_c3d55401 at: https://wandb.ai/seokjin/FSR-prediction/runs/c3d55401\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=169949)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234754-c3d55401/logs\n",
      "2023-08-10 23:48:13,400\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.222 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:48:13,406\tWARNING util.py:315 -- The `process_trial_result` operation took 2.228 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:48:13,407\tWARNING util.py:315 -- Processing trial results took 2.229 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:48:13,408\tWARNING util.py:315 -- The `process_trial_result` operation took 2.230 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_8269d25a_61_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-47-45/wandb/run-20230810_234814-8269d25a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Syncing run FSR_Trainable_8269d25a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/8269d25a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                mae_coord 5.60715\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                mae_force 845.945\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               mape_coord 1.30426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               mape_force 1.4658873894588554e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                   metric 0.75398\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               rmse_coord 2.71987\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               rmse_force 642.95157\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:       time_since_restore 108.93238\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:         time_this_iter_s 0.87313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:             time_total_s 108.93238\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:                timestamp 1691678906\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               tmae_coord 1.19982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:               tmae_force 0.32837\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              tmape_coord 85679993069412.88\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              tmape_force 643191406693760.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              trmse_coord 0.54385\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:              trmse_force 0.21013\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb:  View run FSR_Trainable_cf3dcb02 at: https://wandb.ai/seokjin/FSR-prediction/runs/cf3dcb02\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=168800)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234625-cf3dcb02/logs\n",
      "2023-08-10 23:48:44,866\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.265 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:48:44,881\tWARNING util.py:315 -- The `process_trial_result` operation took 3.283 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:48:44,885\tWARNING util.py:315 -- Processing trial results took 3.286 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:48:44,899\tWARNING util.py:315 -- The `process_trial_result` operation took 3.300 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_50d0539b_62_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-48-06/wandb/run-20230810_234847-50d0539b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Syncing run FSR_Trainable_50d0539b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/50d0539b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                mae_coord 4.89638\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                mae_force 593.61173\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               mape_coord 1.15408\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               mape_force 6.82202990433563e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                   metric 0.64646\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               rmse_coord 2.50369\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               rmse_force 420.59939\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:       time_since_restore 242.14757\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:         time_this_iter_s 2.41695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:             time_total_s 242.14757\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:                timestamp 1691679170\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               tmae_coord 1.0379\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:               tmae_force 0.2409\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              tmape_coord 76038665242995.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              tmape_force 351248099410058.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              trmse_coord 0.49147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:              trmse_force 0.155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb:  View run FSR_Trainable_50d0539b at: https://wandb.ai/seokjin/FSR-prediction/runs/50d0539b\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170418)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234847-50d0539b/logs\n",
      "2023-08-10 23:53:08,577\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.523 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:53:08,584\tWARNING util.py:315 -- The `process_trial_result` operation took 2.531 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:53:08,586\tWARNING util.py:315 -- Processing trial results took 2.533 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:53:08,588\tWARNING util.py:315 -- The `process_trial_result` operation took 2.535 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a2c73c61_63_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-48-38/wandb/run-20230810_235314-a2c73c61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Syncing run FSR_Trainable_a2c73c61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a2c73c61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                mae_coord 5.2113\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                mae_force 778.52023\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               mape_coord 1.18053\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               mape_force 8.377843691915203e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                   metric 0.70436\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               rmse_coord 2.55531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               rmse_force 583.04632\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:       time_since_restore 487.44708\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:         time_this_iter_s 5.23167\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:             time_total_s 487.44708\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:                timestamp 1691679198\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               tmae_coord 1.0977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:               tmae_force 0.30002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              tmape_coord 71992658116763.95\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              tmape_force 386572577613815.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              trmse_coord 0.4981\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:              trmse_force 0.20626\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb:  View run FSR_Trainable_6dc65d0f at: https://wandb.ai/seokjin/FSR-prediction/runs/6dc65d0f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=167652)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234457-6dc65d0f/logs\n",
      "2023-08-10 23:53:37,019\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.578 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:53:37,022\tWARNING util.py:315 -- The `process_trial_result` operation took 2.582 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:53:37,025\tWARNING util.py:315 -- Processing trial results took 2.585 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:53:37,027\tWARNING util.py:315 -- The `process_trial_result` operation took 2.587 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_07df2b2d_64_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-53-03/wandb/run-20230810_235339-07df2b2d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Syncing run FSR_Trainable_07df2b2d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/07df2b2d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                mae_coord 5.37377\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                mae_force 657.79953\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               mape_coord 1.20271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               mape_force 6.615155014288161e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                   metric 0.70793\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               rmse_coord 2.70632\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               rmse_force 489.7638\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:       time_since_restore 1320.79779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:         time_this_iter_s 13.35348\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:             time_total_s 1320.79779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:                timestamp 1691679221\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               tmae_coord 1.12934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:               tmae_force 0.27059\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              tmape_coord 64949752231245.14\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              tmape_force 347386737615712.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              trmse_coord 0.52169\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:              trmse_force 0.18624\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb:  View run FSR_Trainable_9cb367ce at: https://wandb.ai/seokjin/FSR-prediction/runs/9cb367ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=159706)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_233135-9cb367ce/logs\n",
      "2023-08-10 23:54:00,348\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.490 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:54:00,351\tWARNING util.py:315 -- The `process_trial_result` operation took 2.494 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:54:00,353\tWARNING util.py:315 -- Processing trial results took 2.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:54:00,354\tWARNING util.py:315 -- The `process_trial_result` operation took 2.497 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e1cb6d85_65_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-53-31/wandb/run-20230810_235402-e1cb6d85\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Syncing run FSR_Trainable_e1cb6d85\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e1cb6d85\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                mae_coord 5.14683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                mae_force 670.3709\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               mape_coord 1.21098\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               mape_force 7.160111819281608e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                   metric 0.677\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               rmse_coord 2.57945\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               rmse_force 485.96595\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:       time_since_restore 409.34125\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:         time_this_iter_s 4.77236\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:             time_total_s 409.34125\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:                timestamp 1691679307\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               tmae_coord 1.08071\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:               tmae_force 0.26556\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              tmape_coord 74842489834206.88\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              tmape_force 345867376040290.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              trmse_coord 0.50072\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:              trmse_force 0.17628\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb:  View run FSR_Trainable_8269d25a at: https://wandb.ai/seokjin/FSR-prediction/runs/8269d25a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170181)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_234814-8269d25a/logs\n",
      "2023-08-10 23:55:28,852\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.919 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:55:28,857\tWARNING util.py:315 -- The `process_trial_result` operation took 1.925 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:55:28,859\tWARNING util.py:315 -- Processing trial results took 1.927 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:55:28,860\tWARNING util.py:315 -- The `process_trial_result` operation took 1.929 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_56b1e2c2_66_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-53-54/wandb/run-20230810_235529-56b1e2c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Syncing run FSR_Trainable_56b1e2c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/56b1e2c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                mae_coord 5.03725\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                mae_force 588.84214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               mape_coord 1.19262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               mape_force 7.254256027124998e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                   metric 0.65815\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               rmse_coord 2.53516\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               rmse_force 417.03578\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:       time_since_restore 241.78747\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:         time_this_iter_s 2.30856\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:             time_total_s 241.78747\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:                timestamp 1691679437\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               tmae_coord 1.07781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:               tmae_force 0.2425\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              tmape_coord 76754366874931.11\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              tmape_force 380029711905130.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              trmse_coord 0.50271\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:              trmse_force 0.15544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb:  View run FSR_Trainable_a2c73c61 at: https://wandb.ai/seokjin/FSR-prediction/runs/a2c73c61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=170804)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235314-a2c73c61/logs\n",
      "2023-08-10 23:57:35,571\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.400 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:57:35,576\tWARNING util.py:315 -- The `process_trial_result` operation took 2.407 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:57:35,578\tWARNING util.py:315 -- Processing trial results took 2.409 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:57:35,580\tWARNING util.py:315 -- The `process_trial_result` operation took 2.410 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_f73cb3c8_67_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-55-22/wandb/run-20230810_235737-f73cb3c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Syncing run FSR_Trainable_f73cb3c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f73cb3c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                mae_coord 4.91688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                mae_force 603.15007\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               mape_coord 1.15364\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               mape_force 6.930509518795343e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                   metric 0.65415\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               rmse_coord 2.50696\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               rmse_force 436.27423\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:       time_since_restore 237.42065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:         time_this_iter_s 2.13235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:             time_total_s 237.42065\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:                timestamp 1691679462\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               tmae_coord 1.04289\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:               tmae_force 0.24402\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              tmape_coord 76195287475749.05\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              tmape_force 347883449272553.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              trmse_coord 0.49391\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:              trmse_force 0.16024\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb:  View run FSR_Trainable_07df2b2d at: https://wandb.ai/seokjin/FSR-prediction/runs/07df2b2d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171041)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235339-07df2b2d/logs\n",
      "2023-08-10 23:58:00,451\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.075 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:58:00,457\tWARNING util.py:315 -- The `process_trial_result` operation took 2.083 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:58:00,459\tWARNING util.py:315 -- Processing trial results took 2.085 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:58:00,461\tWARNING util.py:315 -- The `process_trial_result` operation took 2.087 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_22748d08_68_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-57-29/wandb/run-20230810_235801-22748d08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Syncing run FSR_Trainable_22748d08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/22748d08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                mae_coord 5.0636\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                mae_force 609.89373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               mape_coord 1.14864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               mape_force 6.905490199180959e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                   metric 0.65486\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               rmse_coord 2.55424\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               rmse_force 444.95149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:       time_since_restore 244.77083\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:         time_this_iter_s 2.15093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:             time_total_s 244.77083\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:                timestamp 1691679492\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               tmae_coord 1.06703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:               tmae_force 0.24593\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              tmape_coord 76046113202522.02\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              tmape_force 364108716887355.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              trmse_coord 0.49683\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:              trmse_force 0.15803\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb:  View run FSR_Trainable_e1cb6d85 at: https://wandb.ai/seokjin/FSR-prediction/runs/e1cb6d85\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171273)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235402-e1cb6d85/logs\n",
      "2023-08-10 23:58:29,716\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.785 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:58:29,719\tWARNING util.py:315 -- The `process_trial_result` operation took 2.788 s, which may be a performance bottleneck.\n",
      "2023-08-10 23:58:29,722\tWARNING util.py:315 -- Processing trial results took 2.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-10 23:58:29,724\tWARNING util.py:315 -- The `process_trial_result` operation took 2.793 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a92c1ed3_69_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-57-55/wandb/run-20230810_235832-a92c1ed3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Syncing run FSR_Trainable_a92c1ed3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a92c1ed3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)08 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                mae_coord 6.40807\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                mae_force 917.10154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               mape_coord 1.65733\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               mape_force 1.0943229927354203e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                   metric 0.80232\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               rmse_coord 2.79796\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               rmse_force 661.13329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:       time_since_restore 322.00786\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:         time_this_iter_s 14.14333\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:             time_total_s 322.00786\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:                timestamp 1691679651\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               tmae_coord 1.35313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:               tmae_force 0.36316\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              tmape_coord 70696064626774.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              tmape_force 539166803719613.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              trmse_coord 0.56563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:              trmse_force 0.23669\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb:  View run FSR_Trainable_56b1e2c2 at: https://wandb.ai/seokjin/FSR-prediction/runs/56b1e2c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171555)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235529-56b1e2c2/logs\n",
      "2023-08-11 00:01:11,833\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.245 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:01:11,837\tWARNING util.py:315 -- The `process_trial_result` operation took 3.250 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:01:11,839\tWARNING util.py:315 -- Processing trial results took 3.251 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:01:11,841\tWARNING util.py:315 -- The `process_trial_result` operation took 3.254 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_73b6e975_70_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-10_23-58-24/wandb/run-20230811_000115-73b6e975\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Syncing run FSR_Trainable_73b6e975\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/73b6e975\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                mae_coord 5.07548\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                mae_force 636.5385\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               mape_coord 1.13056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               mape_force 7.19012967282376e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                   metric 0.67327\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               rmse_coord 2.60675\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               rmse_force 462.66633\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:       time_since_restore 231.38826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:         time_this_iter_s 2.34482\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:             time_total_s 231.38826\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:                timestamp 1691679748\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               tmae_coord 1.07079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:               tmae_force 0.25544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              tmape_coord 64989718671083.86\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              tmape_force 358887825594653.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              trmse_coord 0.50451\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:              trmse_force 0.16877\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb:  View run FSR_Trainable_a92c1ed3 at: https://wandb.ai/seokjin/FSR-prediction/runs/a92c1ed3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172334)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235832-a92c1ed3/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "2023-08-11 00:02:46,805\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.947 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:02:46,808\tWARNING util.py:315 -- The `process_trial_result` operation took 1.952 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:02:46,812\tWARNING util.py:315 -- Processing trial results took 1.955 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:02:46,813\tWARNING util.py:315 -- The `process_trial_result` operation took 1.957 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                mae_coord 5.04452\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                mae_force 645.06542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               mape_coord 1.18302\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               mape_force 7.207328412902335e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                   metric 0.67149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               rmse_coord 2.57121\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               rmse_force 464.64779\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:       time_since_restore 299.85415\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:         time_this_iter_s 3.51262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:             time_total_s 299.85415\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:                timestamp 1691679763\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               tmae_coord 1.07432\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:               tmae_force 0.25905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              tmape_coord 66860417088637.68\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              tmape_force 365595624817676.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              trmse_coord 0.50299\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:              trmse_force 0.1685\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb:  View run FSR_Trainable_f73cb3c8 at: https://wandb.ai/seokjin/FSR-prediction/runs/f73cb3c8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=171863)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235737-f73cb3c8/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_736b439f_71_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-01-05/wandb/run-20230811_000249-736b439f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Syncing run FSR_Trainable_736b439f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/736b439f\n",
      "2023-08-11 00:03:05,000\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.582 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:03:05,004\tWARNING util.py:315 -- The `process_trial_result` operation took 2.587 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:03:05,005\tWARNING util.py:315 -- Processing trial results took 2.588 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:03:05,006\tWARNING util.py:315 -- The `process_trial_result` operation took 2.589 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "wandb: - Waiting for wandb.init()...258)\u001b[0m wandb: / Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_4bf5a3a3_72_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-02-42/wandb/run-20230811_000308-4bf5a3a3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Syncing run FSR_Trainable_4bf5a3a3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4bf5a3a3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                mae_coord 5.09703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                mae_force 582.82231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               mape_coord 1.17097\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               mape_force 6.133924794749033e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                   metric 0.66725\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               rmse_coord 2.59882\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               rmse_force 424.77451\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:       time_since_restore 307.55864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:         time_this_iter_s 2.83908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:             time_total_s 307.55864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:                timestamp 1691679795\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               tmae_coord 1.07997\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:               tmae_force 0.24228\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              tmape_coord 66426084481154.016\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              tmape_force 337360393047977.56\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              trmse_coord 0.50835\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:              trmse_force 0.15889\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb:  View run FSR_Trainable_22748d08 at: https://wandb.ai/seokjin/FSR-prediction/runs/22748d08\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172098)\u001b[0m wandb: Find logs at: ./wandb/run-20230810_235801-22748d08/logs\n",
      "2023-08-11 00:03:35,066\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.561 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:03:35,070\tWARNING util.py:315 -- The `process_trial_result` operation took 1.565 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:03:35,073\tWARNING util.py:315 -- Processing trial results took 1.569 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:03:35,074\tWARNING util.py:315 -- The `process_trial_result` operation took 1.570 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bf244b87_73_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-02-58/wandb/run-20230811_000337-bf244b87\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Syncing run FSR_Trainable_bf244b87\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bf244b87\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: - 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                mae_coord 5.05165\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                mae_force 603.23544\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               mape_coord 1.10962\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               mape_force 7.106460845796801e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                   metric 0.6563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               rmse_coord 2.58674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               rmse_force 428.40207\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:       time_since_restore 197.96948\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:         time_this_iter_s 2.35219\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:             time_total_s 197.96948\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:                timestamp 1691679880\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               tmae_coord 1.06949\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:               tmae_force 0.2427\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              tmape_coord 64799361019264.914\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              tmape_force 358630290201206.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              trmse_coord 0.50054\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:              trmse_force 0.15576\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb:  View run FSR_Trainable_73b6e975 at: https://wandb.ai/seokjin/FSR-prediction/runs/73b6e975\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=172740)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000115-73b6e975/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: \\ 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: iterations_since_restore 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                mae_coord 5.43864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                mae_force 734.93093\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               mape_coord 1.26506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               mape_force 1.2703313306977572e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                   metric 0.69584\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               rmse_coord 2.63131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               rmse_force 456.75737\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:       time_since_restore 75.54162\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:         time_this_iter_s 3.12559\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:             time_total_s 75.54162\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:                timestamp 1691679890\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               tmae_coord 1.14222\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:               tmae_force 0.32926\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              tmape_coord 68799190565590.28\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              tmape_force 694394984003696.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:       training_iteration 32\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              trmse_coord 0.51084\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:              trmse_force 0.185\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb:  View run FSR_Trainable_bf244b87 at: https://wandb.ai/seokjin/FSR-prediction/runs/bf244b87\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173502)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000337-bf244b87/logs\n",
      "2023-08-11 00:05:00,117\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.183 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:05:00,122\tWARNING util.py:315 -- The `process_trial_result` operation took 2.190 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:05:00,124\tWARNING util.py:315 -- Processing trial results took 2.193 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:05:00,126\tWARNING util.py:315 -- The `process_trial_result` operation took 2.194 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_754a29b9_74_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-03-30/wandb/run-20230811_000505-754a29b9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Syncing run FSR_Trainable_754a29b9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/754a29b9\n",
      "2023-08-11 00:05:14,282\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.693 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:05:14,286\tWARNING util.py:315 -- The `process_trial_result` operation took 2.698 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:05:14,287\tWARNING util.py:315 -- Processing trial results took 2.699 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:05:14,289\tWARNING util.py:315 -- The `process_trial_result` operation took 2.701 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_0d612610_75_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-04-55/wandb/run-20230811_000517-0d612610\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Syncing run FSR_Trainable_0d612610\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/0d612610\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                mae_coord 5.28781\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                mae_force 643.65551\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               mape_coord 1.14718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               mape_force 9.403445856059035e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                   metric 0.67149\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               rmse_coord 2.6235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               rmse_force 424.47752\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:       time_since_restore 204.57491\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:         time_this_iter_s 2.10073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:             time_total_s 204.57491\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:                timestamp 1691679982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               tmae_coord 1.1155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:               tmae_force 0.27806\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              tmape_coord 63658640954917.13\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              tmape_force 520004819167223.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              trmse_coord 0.50814\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:              trmse_force 0.16335\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb:  View run FSR_Trainable_736b439f at: https://wandb.ai/seokjin/FSR-prediction/runs/736b439f\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173026)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000249-736b439f/logs\n",
      "2023-08-11 00:06:44,906\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.079 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:06:44,908\tWARNING util.py:315 -- The `process_trial_result` operation took 2.082 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:06:44,912\tWARNING util.py:315 -- Processing trial results took 2.086 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:06:44,913\tWARNING util.py:315 -- The `process_trial_result` operation took 2.087 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_29c08e0a_76_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-05-08/wandb/run-20230811_000647-29c08e0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Syncing run FSR_Trainable_29c08e0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/29c08e0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: / 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                mae_coord 4.99187\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                mae_force 636.21265\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               mape_coord 1.18266\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               mape_force 8.711087204758752e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                   metric 0.65976\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               rmse_coord 2.57585\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               rmse_force 435.44745\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:       time_since_restore 254.82252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:         time_this_iter_s 2.81081\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:             time_total_s 254.82252\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:                timestamp 1691680053\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               tmae_coord 1.05981\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:               tmae_force 0.2636\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              tmape_coord 67472691962011.914\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              tmape_force 456723725312864.1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              trmse_coord 0.49882\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:              trmse_force 0.16094\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb:  View run FSR_Trainable_4bf5a3a3 at: https://wandb.ai/seokjin/FSR-prediction/runs/4bf5a3a3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173258)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000308-4bf5a3a3/logs\n",
      "2023-08-11 00:07:54,148\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.491 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:07:54,151\tWARNING util.py:315 -- The `process_trial_result` operation took 2.494 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:07:54,156\tWARNING util.py:315 -- Processing trial results took 2.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:07:54,157\tWARNING util.py:315 -- The `process_trial_result` operation took 2.501 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_596c93b0_77_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-06-39/wandb/run-20230811_000757-596c93b0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Syncing run FSR_Trainable_596c93b0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/596c93b0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: \\ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                mae_coord 5.20362\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                mae_force 617.27125\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               mape_coord 1.16965\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               mape_force 8.006380419182916e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                   metric 0.66117\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               rmse_coord 2.61556\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               rmse_force 422.80964\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:       time_since_restore 266.41563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:         time_this_iter_s 3.08264\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:             time_total_s 266.41563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:                timestamp 1691680178\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               tmae_coord 1.09491\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:               tmae_force 0.25718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              tmape_coord 65931414879426.805\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              tmape_force 426839498421554.75\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              trmse_coord 0.50409\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:              trmse_force 0.15708\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb:  View run FSR_Trainable_754a29b9 at: https://wandb.ai/seokjin/FSR-prediction/runs/754a29b9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=173798)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000505-754a29b9/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: - 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: \\ 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                mae_coord 5.12986\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                mae_force 612.80177\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               mape_coord 1.12797\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               mape_force 6.951110939425052e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                   metric 0.67393\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               rmse_coord 2.60204\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               rmse_force 440.06905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:       time_since_restore 266.73477\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:         time_this_iter_s 2.75075\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:             time_total_s 266.73477\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:                timestamp 1691680192\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               tmae_coord 1.08718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:               tmae_force 0.25565\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              tmape_coord 64400892267593.836\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              tmape_force 368536675751045.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              trmse_coord 0.50478\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:              trmse_force 0.16915\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb:  View run FSR_Trainable_0d612610 at: https://wandb.ai/seokjin/FSR-prediction/runs/0d612610\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174012)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000517-0d612610/logs\n",
      "2023-08-11 00:09:56,902\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.994 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:09:56,905\tWARNING util.py:315 -- The `process_trial_result` operation took 2.997 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:09:56,907\tWARNING util.py:315 -- Processing trial results took 2.999 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:09:56,911\tWARNING util.py:315 -- The `process_trial_result` operation took 3.003 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_1636580a_78_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-07-48/wandb/run-20230811_001000-1636580a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Syncing run FSR_Trainable_1636580a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/1636580a\n",
      "2023-08-11 00:10:17,197\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.609 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:10:17,204\tWARNING util.py:315 -- The `process_trial_result` operation took 2.619 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:10:17,206\tWARNING util.py:315 -- Processing trial results took 2.621 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:10:17,208\tWARNING util.py:315 -- The `process_trial_result` operation took 2.623 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_36c37afe_79_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-09-50/wandb/run-20230811_001021-36c37afe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Syncing run FSR_Trainable_36c37afe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/36c37afe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                mae_coord 5.05953\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                mae_force 586.90415\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               mape_coord 1.13316\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               mape_force 6.118870719505866e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                   metric 0.66048\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               rmse_coord 2.59115\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               rmse_force 438.31995\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:       time_since_restore 265.11614\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:         time_this_iter_s 3.24051\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:             time_total_s 265.11614\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:                timestamp 1691680279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               tmae_coord 1.07259\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:               tmae_force 0.2347\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              tmape_coord 64503243337382.72\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              tmape_force 315283811138201.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              trmse_coord 0.50193\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:              trmse_force 0.15855\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb:  View run FSR_Trainable_29c08e0a at: https://wandb.ai/seokjin/FSR-prediction/runs/29c08e0a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174298)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000647-29c08e0a/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                mae_coord 4.88913\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                mae_force 626.01174\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               mape_coord 1.08639\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               mape_force 7.485230771883284e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                   metric 0.64915\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               rmse_coord 2.52522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               rmse_force 429.61433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:       time_since_restore 209.90695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:         time_this_iter_s 1.95934\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:             time_total_s 209.90695\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:                timestamp 1691680294\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               tmae_coord 1.03227\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:               tmae_force 0.25458\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              tmape_coord 65837072585127.79\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              tmape_force 376871956582451.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              trmse_coord 0.48975\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:              trmse_force 0.1594\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb:  View run FSR_Trainable_596c93b0 at: https://wandb.ai/seokjin/FSR-prediction/runs/596c93b0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174567)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_000757-596c93b0/logs\n",
      "2023-08-11 00:11:39,006\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.099 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:11:39,010\tWARNING util.py:315 -- The `process_trial_result` operation took 2.104 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:11:39,013\tWARNING util.py:315 -- Processing trial results took 2.107 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:11:39,015\tWARNING util.py:315 -- The `process_trial_result` operation took 2.109 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_757aa8c1_80_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-10-10/wandb/run-20230811_001141-757aa8c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Syncing run FSR_Trainable_757aa8c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/757aa8c1\n",
      "2023-08-11 00:11:55,546\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:11:55,549\tWARNING util.py:315 -- The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:11:55,552\tWARNING util.py:315 -- Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:11:55,553\tWARNING util.py:315 -- The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_dc87d342_81_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-11-34/wandb/run-20230811_001158-dc87d342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Syncing run FSR_Trainable_dc87d342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/dc87d342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                mae_coord 4.62637\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                mae_force 823.81098\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               mape_coord 1.11151\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               mape_force 1.3737625748012003e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                   metric 53.64806\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               rmse_coord 2.4908\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               rmse_force 680.83497\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:       time_since_restore 2.69606\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:         time_this_iter_s 2.69606\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:             time_total_s 2.69606\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:                timestamp 1691680313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               tmae_coord 44.76675\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:               tmae_force 5.28168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              tmape_coord 8498559477084938.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              tmape_force 4430037175390190.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              trmse_coord 47.78008\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:              trmse_force 5.86798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb:  View run FSR_Trainable_dc87d342 at: https://wandb.ai/seokjin/FSR-prediction/runs/dc87d342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175617)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001158-dc87d342/logs\n",
      "2023-08-11 00:12:14,013\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.968 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:14,016\tWARNING util.py:315 -- The `process_trial_result` operation took 1.971 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:14,017\tWARNING util.py:315 -- Processing trial results took 1.972 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:12:14,018\tWARNING util.py:315 -- The `process_trial_result` operation took 1.974 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bec324cd_82_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-11-51/wandb/run-20230811_001219-bec324cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Syncing run FSR_Trainable_bec324cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bec324cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                mae_coord 4.93905\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                mae_force 950.41482\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               mape_coord 1.25875\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               mape_force 1.189336451554994e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                   metric 54.93895\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               rmse_coord 2.50095\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               rmse_force 757.84995\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:       time_since_restore 2.39563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:         time_this_iter_s 2.39563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:             time_total_s 2.39563\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:                timestamp 1691680332\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               tmae_coord 45.77674\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:               tmae_force 5.9235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              tmape_coord 1.068368634850101e+16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              tmape_force 4172423034833060.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              trmse_coord 48.56543\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:              trmse_force 6.37353\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb:  View run FSR_Trainable_bec324cd at: https://wandb.ai/seokjin/FSR-prediction/runs/bec324cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175849)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001219-bec324cd/logs\n",
      "2023-08-11 00:12:31,912\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:31,914\tWARNING util.py:315 -- The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:31,916\tWARNING util.py:315 -- Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:12:31,917\tWARNING util.py:315 -- The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_6c3cd3ce_83_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-12-09/wandb/run-20230811_001235-6c3cd3ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Syncing run FSR_Trainable_6c3cd3ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/6c3cd3ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)04 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                mae_coord 5.24446\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                mae_force 635.45231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               mape_coord 1.16404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               mape_force 7.445642950519013e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                   metric 0.67635\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               rmse_coord 2.6034\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               rmse_force 451.80073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:       time_since_restore 130.42363\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:         time_this_iter_s 2.06758\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:             time_total_s 130.42363\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:                timestamp 1691680354\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               tmae_coord 1.1147\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:               tmae_force 0.26533\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              tmape_coord 64471072924564.39\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              tmape_force 402286524877309.8\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              trmse_coord 0.50749\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:              trmse_force 0.16886\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb:  View run FSR_Trainable_36c37afe at: https://wandb.ai/seokjin/FSR-prediction/runs/36c37afe\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175104)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001021-36c37afe/logs\n",
      "2023-08-11 00:12:51,552\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.951 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:51,556\tWARNING util.py:315 -- The `process_trial_result` operation took 1.956 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:12:51,557\tWARNING util.py:315 -- Processing trial results took 1.958 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:12:51,559\tWARNING util.py:315 -- The `process_trial_result` operation took 1.959 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_45da30e1_84_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-12-27/wandb/run-20230811_001254-45da30e1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Syncing run FSR_Trainable_45da30e1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/45da30e1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: - 0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                mae_coord 5.12711\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                mae_force 605.25509\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               mape_coord 1.10189\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               mape_force 6.485553759507378e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                   metric 0.66712\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               rmse_coord 2.61539\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               rmse_force 445.24104\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:       time_since_restore 207.32186\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:         time_this_iter_s 2.99687\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:             time_total_s 207.32186\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:                timestamp 1691680420\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               tmae_coord 1.08282\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:               tmae_force 0.23984\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              tmape_coord 63785121201286.33\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              tmape_force 312930238455151.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              trmse_coord 0.50498\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:              trmse_force 0.16214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb:  View run FSR_Trainable_1636580a at: https://wandb.ai/seokjin/FSR-prediction/runs/1636580a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=174872)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001000-1636580a/logs\n",
      "2023-08-11 00:14:04,232\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.003 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:14:04,236\tWARNING util.py:315 -- The `process_trial_result` operation took 2.010 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:14:04,236\tWARNING util.py:315 -- Processing trial results took 2.011 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:14:04,237\tWARNING util.py:315 -- The `process_trial_result` operation took 2.012 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_f43b6b94_85_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-12-47/wandb/run-20230811_001406-f43b6b94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Syncing run FSR_Trainable_f43b6b94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f43b6b94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: | 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                mae_coord 5.28397\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                mae_force 629.52965\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               mape_coord 1.14994\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               mape_force 7.85287087021087e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                   metric 0.67248\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               rmse_coord 2.62772\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               rmse_force 442.90155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:       time_since_restore 133.84841\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:         time_this_iter_s 2.21081\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:             time_total_s 133.84841\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:                timestamp 1691680447\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               tmae_coord 1.11764\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:               tmae_force 0.25877\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              tmape_coord 66446882797732.57\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              tmape_force 403875876326853.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              trmse_coord 0.50886\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:              trmse_force 0.16362\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb:  View run FSR_Trainable_757aa8c1 at: https://wandb.ai/seokjin/FSR-prediction/runs/757aa8c1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=175387)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001141-757aa8c1/logs\n",
      "2023-08-11 00:14:28,214\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.989 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:14:28,218\tWARNING util.py:315 -- The `process_trial_result` operation took 2.995 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:14:28,220\tWARNING util.py:315 -- Processing trial results took 2.997 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:14:28,222\tWARNING util.py:315 -- The `process_trial_result` operation took 2.999 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_d54316cd_86_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-13-58/wandb/run-20230811_001431-d54316cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Syncing run FSR_Trainable_d54316cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/d54316cd\n",
      "2023-08-11 00:15:42,691\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 0.641 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:15:42,697\tWARNING util.py:315 -- The `process_trial_result` operation took 0.647 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:15:42,698\tWARNING util.py:315 -- Processing trial results took 0.649 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:15:42,701\tWARNING util.py:315 -- The `process_trial_result` operation took 0.652 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                mae_coord 4.97983\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                mae_force 614.4735\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               mape_coord 1.15006\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               mape_force 7.172014786223247e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                   metric 0.65773\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               rmse_coord 2.55531\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               rmse_force 432.29769\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:       time_since_restore 209.84547\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:         time_this_iter_s 1.91522\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:             time_total_s 209.84547\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:                timestamp 1691680573\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               tmae_coord 1.05865\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:               tmae_force 0.24687\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              tmape_coord 66223587168602.03\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              tmape_force 357334114897142.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              trmse_coord 0.49921\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:              trmse_force 0.15852\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb:  View run FSR_Trainable_6c3cd3ce at: https://wandb.ai/seokjin/FSR-prediction/runs/6c3cd3ce\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176080)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001235-6c3cd3ce/logs\n",
      "2023-08-11 00:16:35,724\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.668 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:16:35,729\tWARNING util.py:315 -- The `process_trial_result` operation took 2.674 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:16:35,733\tWARNING util.py:315 -- Processing trial results took 2.678 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:16:35,735\tWARNING util.py:315 -- The `process_trial_result` operation took 2.681 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: | 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bf07bd58_87_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-14-21/wandb/run-20230811_001641-bf07bd58\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Syncing run FSR_Trainable_bf07bd58\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bf07bd58\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                mae_coord 5.24342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                mae_force 631.47237\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               mape_coord 1.17056\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               mape_force 7.915378278700516e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                   metric 0.66946\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               rmse_coord 2.6168\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               rmse_force 434.63051\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:       time_since_restore 215.54119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:         time_this_iter_s 2.27965\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:             time_total_s 215.54119\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:                timestamp 1691680598\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               tmae_coord 1.10404\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:               tmae_force 0.266\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              tmape_coord 66063657501743.91\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              tmape_force 423421542010655.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              trmse_coord 0.50373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:              trmse_force 0.16573\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb:  View run FSR_Trainable_45da30e1 at: https://wandb.ai/seokjin/FSR-prediction/runs/45da30e1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176313)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001254-45da30e1/logs\n",
      "2023-08-11 00:17:01,396\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.673 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:01,400\tWARNING util.py:315 -- The `process_trial_result` operation took 2.679 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:01,403\tWARNING util.py:315 -- Processing trial results took 2.681 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:17:01,406\tWARNING util.py:315 -- The `process_trial_result` operation took 2.684 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_e8d5cf7d_88_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-16-28/wandb/run-20230811_001703-e8d5cf7d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Syncing run FSR_Trainable_e8d5cf7d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/e8d5cf7d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: \\ 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                mae_coord 5.52895\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                mae_force 766.2997\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               mape_coord 1.23561\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               mape_force 1.2687709259950267e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                   metric 0.71278\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               rmse_coord 2.66036\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               rmse_force 463.3044\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:       time_since_restore 47.52477\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:         time_this_iter_s 3.01654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:             time_total_s 47.52477\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:                timestamp 1691680642\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               tmae_coord 1.17329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:               tmae_force 0.34355\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              tmape_coord 65803611436425.59\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              tmape_force 698457155280584.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              trmse_coord 0.51935\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:              trmse_force 0.19344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb:  View run FSR_Trainable_bf07bd58 at: https://wandb.ai/seokjin/FSR-prediction/runs/bf07bd58\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177137)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001641-bf07bd58/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: iterations_since_restore 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                mae_coord 5.09537\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                mae_force 635.83855\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               mape_coord 1.17641\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               mape_force 7.12314811132636e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                   metric 0.67583\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               rmse_coord 2.60344\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               rmse_force 451.8214\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:       time_since_restore 173.85247\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:         time_this_iter_s 3.25703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:             time_total_s 173.85247\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:                timestamp 1691680649\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               tmae_coord 1.08654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:               tmae_force 0.2607\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              tmape_coord 66288641889120.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              tmape_force 376149628026326.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:       training_iteration 64\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              trmse_coord 0.5073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:              trmse_force 0.16853\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb:  View run FSR_Trainable_d54316cd at: https://wandb.ai/seokjin/FSR-prediction/runs/d54316cd\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176820)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001431-d54316cd/logs\n",
      "2023-08-11 00:17:43,975\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.621 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:43,980\tWARNING util.py:315 -- The `process_trial_result` operation took 2.627 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:43,982\tWARNING util.py:315 -- Processing trial results took 2.629 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:17:43,984\tWARNING util.py:315 -- The `process_trial_result` operation took 2.630 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_a5c83218_89_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-16-54/wandb/run-20230811_001746-a5c83218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Syncing run FSR_Trainable_a5c83218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/a5c83218\n",
      "2023-08-11 00:17:59,086\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.407 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:59,088\tWARNING util.py:315 -- The `process_trial_result` operation took 2.411 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:17:59,092\tWARNING util.py:315 -- Processing trial results took 2.414 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:17:59,093\tWARNING util.py:315 -- The `process_trial_result` operation took 2.415 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_7d289c93_90_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-17-38/wandb/run-20230811_001801-7d289c93\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Syncing run FSR_Trainable_7d289c93\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/7d289c93\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                mae_coord 4.90332\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                mae_force 603.26681\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               mape_coord 1.1079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               mape_force 6.45115108668871e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                   metric 0.65625\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               rmse_coord 2.5424\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               rmse_force 441.65775\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:       time_since_restore 317.36924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:         time_this_iter_s 3.01648\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:             time_total_s 317.36924\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:                timestamp 1691680774\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               tmae_coord 1.04433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:               tmae_force 0.24329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              tmape_coord 64542219590401.43\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              tmape_force 336313420288604.9\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              trmse_coord 0.49527\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:              trmse_force 0.16098\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb:  View run FSR_Trainable_f43b6b94 at: https://wandb.ai/seokjin/FSR-prediction/runs/f43b6b94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=176585)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001406-f43b6b94/logs\n",
      "2023-08-11 00:19:56,374\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.373 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:19:56,377\tWARNING util.py:315 -- The `process_trial_result` operation took 2.377 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:19:56,379\tWARNING util.py:315 -- Processing trial results took 2.379 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:19:56,382\tWARNING util.py:315 -- The `process_trial_result` operation took 2.381 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_be58cc31_91_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-17-52/wandb/run-20230811_001958-be58cc31\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Syncing run FSR_Trainable_be58cc31\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/be58cc31\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                mae_coord 4.80457\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                mae_force 594.54087\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               mape_coord 1.08954\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               mape_force 7.143778220439465e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                   metric 0.64959\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               rmse_coord 2.53345\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               rmse_force 414.77912\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:       time_since_restore 257.12159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:         time_this_iter_s 2.51202\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:             time_total_s 257.12159\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:                timestamp 1691680931\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               tmae_coord 1.01435\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:               tmae_force 0.25071\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              tmape_coord 67337684347493.87\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              tmape_force 393300090691687.7\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              trmse_coord 0.49155\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:              trmse_force 0.15804\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb:  View run FSR_Trainable_a5c83218 at: https://wandb.ai/seokjin/FSR-prediction/runs/a5c83218\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177634)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001746-a5c83218/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                mae_coord 5.11415\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                mae_force 662.23096\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               mape_coord 1.12745\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               mape_force 9.68934491477846e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                   metric 0.66645\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               rmse_coord 2.5679\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               rmse_force 428.76564\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:       time_since_restore 314.13191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:         time_this_iter_s 3.0416\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:             time_total_s 314.13191\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:                timestamp 1691680946\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               tmae_coord 1.08058\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:               tmae_force 0.28363\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              tmape_coord 66181299666356.74\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              tmape_force 522406245198852.3\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              trmse_coord 0.49982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:              trmse_force 0.16663\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb:  View run FSR_Trainable_e8d5cf7d at: https://wandb.ai/seokjin/FSR-prediction/runs/e8d5cf7d\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177372)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001703-e8d5cf7d/logs\n",
      "2023-08-11 00:22:34,209\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.707 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:22:34,212\tWARNING util.py:315 -- The `process_trial_result` operation took 2.711 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:22:34,215\tWARNING util.py:315 -- Processing trial results took 2.714 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:22:34,217\tWARNING util.py:315 -- The `process_trial_result` operation took 2.717 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_072f68bb_92_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-19-50/wandb/run-20230811_002236-072f68bb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Syncing run FSR_Trainable_072f68bb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/072f68bb\n",
      "2023-08-11 00:22:48,876\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.501 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:22:48,880\tWARNING util.py:315 -- The `process_trial_result` operation took 2.506 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:22:48,883\tWARNING util.py:315 -- Processing trial results took 2.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:22:48,885\tWARNING util.py:315 -- The `process_trial_result` operation took 2.511 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_310307c2_93_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-22-27/wandb/run-20230811_002250-310307c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Syncing run FSR_Trainable_310307c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/310307c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                mae_coord 4.20653\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                mae_force 1141.59671\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               mape_coord 1.10089\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               mape_force 614469758.37959\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                   metric 6.15373\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               rmse_coord 2.42268\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               rmse_force 739.05594\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:       time_since_restore 4.64235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:         time_this_iter_s 4.64235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:             time_total_s 4.64235\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:                timestamp 1691680966\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               tmae_coord 7.7325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:               tmae_force 2.84977\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              tmape_coord 72.80209\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              tmape_force 92.50426\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              trmse_coord 4.46506\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:              trmse_force 1.68868\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb:  View run FSR_Trainable_310307c2 at: https://wandb.ai/seokjin/FSR-prediction/runs/310307c2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178706)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002250-310307c2/logs\n",
      "2023-08-11 00:23:12,812\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.560 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:12,817\tWARNING util.py:315 -- The `process_trial_result` operation took 2.566 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:12,819\tWARNING util.py:315 -- Processing trial results took 2.568 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:23:12,822\tWARNING util.py:315 -- The `process_trial_result` operation took 2.571 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_454e8493_94_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-22-41/wandb/run-20230811_002314-454e8493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Syncing run FSR_Trainable_454e8493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/454e8493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: \\ 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: | 0.006 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                mae_coord 4.36361\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                mae_force 1134.85324\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               mape_coord 1.13134\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               mape_force 622720015.98864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                   metric 6.1296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               rmse_coord 2.42731\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               rmse_force 780.21245\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:       time_since_restore 5.50131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:         time_this_iter_s 5.50131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:             time_total_s 5.50131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:                timestamp 1691680990\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               tmae_coord 7.93311\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:               tmae_force 2.69459\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              tmape_coord 193.71002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              tmape_force 56.83843\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              trmse_coord 4.45982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:              trmse_force 1.66979\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb:  View run FSR_Trainable_454e8493 at: https://wandb.ai/seokjin/FSR-prediction/runs/454e8493\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178942)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002314-454e8493/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: - 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: \\ 0.005 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                mae_coord 4.96287\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                mae_force 607.21672\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               mape_coord 1.10313\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               mape_force 7.853993222108959e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                   metric 0.65471\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               rmse_coord 2.54565\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               rmse_force 416.80676\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:       time_since_restore 311.04808\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:         time_this_iter_s 2.78568\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:             time_total_s 311.04808\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:                timestamp 1691681004\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               tmae_coord 1.05102\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:               tmae_force 0.2488\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              tmape_coord 63338701810891.445\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              tmape_force 395380568884306.06\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              trmse_coord 0.49661\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:              trmse_force 0.15809\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb:  View run FSR_Trainable_7d289c93 at: https://wandb.ai/seokjin/FSR-prediction/runs/7d289c93\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=177848)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001801-7d289c93/logs\n",
      "2023-08-11 00:23:30,440\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.995 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:30,443\tWARNING util.py:315 -- The `process_trial_result` operation took 1.999 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:30,445\tWARNING util.py:315 -- Processing trial results took 2.000 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:23:30,446\tWARNING util.py:315 -- The `process_trial_result` operation took 2.001 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_cb03759c_95_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-23-05/wandb/run-20230811_002333-cb03759c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Syncing run FSR_Trainable_cb03759c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/cb03759c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: iterations_since_restore 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                mae_coord 5.36296\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                mae_force 777.87186\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               mape_coord 1.21745\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               mape_force 1.2842607019643653e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                   metric 0.70565\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               rmse_coord 2.60789\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               rmse_force 499.0469\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:       time_since_restore 53.34433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:         time_this_iter_s 3.33996\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:             time_total_s 53.34433\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:                timestamp 1691681008\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               tmae_coord 1.13725\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:               tmae_force 0.33057\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              tmape_coord 63861892477930.78\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              tmape_force 642106939733575.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:       training_iteration 16\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              trmse_coord 0.51412\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:              trmse_force 0.19154\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb:  View run FSR_Trainable_072f68bb at: https://wandb.ai/seokjin/FSR-prediction/runs/072f68bb\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178482)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002236-072f68bb/logs\n",
      "2023-08-11 00:23:47,084\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.300 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:47,087\tWARNING util.py:315 -- The `process_trial_result` operation took 2.305 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:47,090\tWARNING util.py:315 -- Processing trial results took 2.308 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:23:47,095\tWARNING util.py:315 -- The `process_trial_result` operation took 2.313 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_aa13815a_96_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-23-26/wandb/run-20230811_002352-aa13815a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Syncing run FSR_Trainable_aa13815a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/aa13815a\n",
      "2023-08-11 00:23:58,996\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.998 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:58,999\tWARNING util.py:315 -- The `process_trial_result` operation took 2.002 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:23:59,002\tWARNING util.py:315 -- Processing trial results took 2.006 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:23:59,004\tWARNING util.py:315 -- The `process_trial_result` operation took 2.007 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_f1fd40db_97_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-23-41/wandb/run-20230811_002402-f1fd40db\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Syncing run FSR_Trainable_f1fd40db\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/f1fd40db\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: iterations_since_restore 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                mae_coord 5.3982\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                mae_force 1375.44237\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               mape_coord 1.28751\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               mape_force 2.7516178724003456e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                   metric 0.82288\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               rmse_coord 2.58985\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               rmse_force 903.01264\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:       time_since_restore 3.08215\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:         time_this_iter_s 1.38654\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:             time_total_s 3.08215\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:                timestamp 1691681040\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               tmae_coord 1.16877\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:               tmae_force 0.50311\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              tmape_coord 79330202356118.61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              tmape_force 1073531195304480.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:       training_iteration 2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              trmse_coord 0.5262\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:              trmse_force 0.29668\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb:  View run FSR_Trainable_f1fd40db at: https://wandb.ai/seokjin/FSR-prediction/runs/f1fd40db\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179632)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002402-f1fd40db/logs\n",
      "2023-08-11 00:24:18,658\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.803 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:24:18,663\tWARNING util.py:315 -- The `process_trial_result` operation took 2.808 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:24:18,665\tWARNING util.py:315 -- Processing trial results took 2.810 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:24:18,667\tWARNING util.py:315 -- The `process_trial_result` operation took 2.812 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_bcae2507_98_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-23-55/wandb/run-20230811_002422-bcae2507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Syncing run FSR_Trainable_bcae2507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/bcae2507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                mae_coord 9.03069\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                mae_force 2068.7548\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               mape_coord 2.14323\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               mape_force 4.730170158819e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                   metric 1.20968\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               rmse_coord 3.51704\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               rmse_force 1291.17059\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:       time_since_restore 1.46933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:         time_this_iter_s 1.46933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:             time_total_s 1.46933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:                timestamp 1691681055\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               tmae_coord 2.07247\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:               tmae_force 0.75476\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              tmape_coord 92957110211476.94\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              tmape_force 1759863249454922.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              trmse_coord 0.80782\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:              trmse_force 0.40185\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb:  View run FSR_Trainable_bcae2507 at: https://wandb.ai/seokjin/FSR-prediction/runs/bcae2507\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179866)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002422-bcae2507/logs\n",
      "2023-08-11 00:24:40,880\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 1.864 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:24:40,886\tWARNING util.py:315 -- The `process_trial_result` operation took 1.870 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:24:40,887\tWARNING util.py:315 -- Processing trial results took 1.871 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:24:40,889\tWARNING util.py:315 -- The `process_trial_result` operation took 1.873 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_4e53941a_99_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Simp_2023-08-11_00-24-14/wandb/run-20230811_002442-4e53941a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Syncing run FSR_Trainable_4e53941a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/4e53941a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                mae_coord 6.44075\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                mae_force 1709.56089\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               mape_coord 1.36151\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               mape_force 3.793321959000969e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                   metric 0.90887\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               rmse_coord 2.81318\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               rmse_force 1029.52798\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:       time_since_restore 4.09515\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:         time_this_iter_s 4.09515\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:             time_total_s 4.09515\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:                timestamp 1691681079\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               tmae_coord 1.35185\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:               tmae_force 0.66864\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              tmape_coord 74471583059726.61\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              tmape_force 1647682934886659.2\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              trmse_coord 0.55276\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:              trmse_force 0.35611\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb:  View run FSR_Trainable_4e53941a at: https://wandb.ai/seokjin/FSR-prediction/runs/4e53941a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180097)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002442-4e53941a/logs\n",
      "2023-08-11 00:25:02,314\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.378 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:25:02,320\tWARNING util.py:315 -- The `process_trial_result` operation took 2.384 s, which may be a performance bottleneck.\n",
      "2023-08-11 00:25:02,322\tWARNING util.py:315 -- Processing trial results took 2.386 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-08-11 00:25:02,323\tWARNING util.py:315 -- The `process_trial_result` operation took 2.388 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/FSR_Trainable_2023-08-10_23-25-39/FSR_Trainable_c3c06fa4_100_criterion=torch_nn_MSELoss,data_loader=fsr_data_get_index_splited_by_subject,imputer=sklearn_impute_Sim_2023-08-11_00-24-35/wandb/run-20230811_002505-c3c06fa4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Syncing run FSR_Trainable_c3c06fa4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:  View project at https://wandb.ai/seokjin/FSR-prediction\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:  View run at https://wandb.ai/seokjin/FSR-prediction/runs/c3c06fa4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: \\ 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: | 0.003 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: iterations_since_restore 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                mae_coord 7.45337\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                mae_force 1785.79047\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               mape_coord 1.40329\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               mape_force 4.252596966067686e+18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                   metric 0.97513\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               rmse_coord 3.14314\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               rmse_force 1176.91833\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:       time_since_restore 2.69088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:         time_this_iter_s 2.69088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:             time_total_s 2.69088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:                timestamp 1691681099\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               tmae_coord 1.58839\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:               tmae_force 0.64178\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              tmape_coord 63971727091081.86\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              tmape_force 1595813356103187.5\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:       training_iteration 1\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              trmse_coord 0.62325\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:              trmse_force 0.35188\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb:  View run FSR_Trainable_c3c06fa4 at: https://wandb.ai/seokjin/FSR-prediction/runs/c3c06fa4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=180331)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002505-c3c06fa4/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                mae_coord 4.70691\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                mae_force 669.04219\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               mape_coord 1.11112\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               mape_force 8.92484269275767e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                   metric 0.65187\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               rmse_coord 2.4933\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               rmse_force 452.30922\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:       time_since_restore 310.36073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:         time_this_iter_s 3.00668\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:             time_total_s 310.36073\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:                timestamp 1691681131\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               tmae_coord 1.00342\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:               tmae_force 0.27004\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              tmape_coord 66233593833135.305\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              tmape_force 430277137988802.44\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              trmse_coord 0.48542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:              trmse_force 0.16644\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb:  View run FSR_Trainable_be58cc31 at: https://wandb.ai/seokjin/FSR-prediction/runs/be58cc31\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=178146)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_001958-be58cc31/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: - 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: \\ 0.004 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                mae_coord 4.77005\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                mae_force 618.20949\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               mape_coord 1.11279\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               mape_force 7.47257639739483e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                   metric 0.65139\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               rmse_coord 2.50003\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               rmse_force 430.72445\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:       time_since_restore 143.24899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:         time_this_iter_s 0.98771\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:             time_total_s 143.24899\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:                timestamp 1691681169\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               tmae_coord 1.02318\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:               tmae_force 0.24063\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              tmape_coord 68475546198984.18\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              tmape_force 336901404983434.25\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              trmse_coord 0.49536\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:              trmse_force 0.15603\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb:  View run FSR_Trainable_cb03759c at: https://wandb.ai/seokjin/FSR-prediction/runs/cb03759c\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179180)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002333-cb03759c/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: - 0.002 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: iterations_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                mae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                mae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               mape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               mape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                   metric \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               rmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               rmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:       time_since_restore \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:         time_this_iter_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:             time_total_s \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                timestamp \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               tmae_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               tmae_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              tmape_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              tmape_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:       training_iteration \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              trmse_coord \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              trmse_force \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                mae_coord 4.81462\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                mae_force 619.67857\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               mape_coord 1.10037\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               mape_force 7.713647305428042e+17\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                   metric 0.64718\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               rmse_coord 2.542\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               rmse_force 433.93831\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:       time_since_restore 223.22088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:         time_this_iter_s 1.5108\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:             time_total_s 223.22088\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:                timestamp 1691681258\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               tmae_coord 1.01896\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:               tmae_force 0.24703\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              tmape_coord 66506599432417.01\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              tmape_force 378946259009743.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              trmse_coord 0.49231\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:              trmse_force 0.15487\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb:  View run FSR_Trainable_aa13815a at: https://wandb.ai/seokjin/FSR-prediction/runs/aa13815a\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=179415)\u001b[0m wandb: Find logs at: ./wandb/run-20230811_002352-aa13815a/logs\n",
      "2023-08-11 00:27:43,357\tINFO tune.py:1111 -- Total run time: 3719.54 seconds (3714.48 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
