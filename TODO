train과 test데이터를 나누는 방법
1. 사람에 따라 나누기 (transfer learning)
2. timestep에 따라 나누기

구하고자 하는 것 나눠서 구할지 정하기
1. 입력: FSR data 출력: 힘, 입력: FSR data / mass 출력: 좌표
2. 입력: FSR data, FSR data / mass 출력: 힘, 좌표
* scaling을 잘 한다면 FSR / mass 데이터를 안 써도 될 것 같다.
* 일단은 1번대로 힘만 예측

좌표의 null값 처리
1. 평균
2. 0d

모델
1. CNN, LSTM, CNN-LSTM, LSTM-CNN, Random Forest

scaling 방법
1. train데이터셋 전체에 대하여 minmax(0, 1), standard, robust
2. 좌표에만 추가로 minmax(-1, 1)을 고려해볼 수도.

----------------------------------------------------

아이디어
1. F-Scan을 이용해 구한 각 지점마다의 힘 데이터를 통해 CNN-LSTM
2. F-Scan데이터를 오토인코더로 매니폴드 러닝, (사람의 발은 모두 비슷하게 생겼고, 생활할 때도 발을 비슷하게 사용하기 때문에 매니폴드는 확실히 작을 것으로 예상). FSR data로 저차원의 매니폴드를 예측함으로써 정확도를 향상할 수 있지 않을까 + F-Scan데이터 전체를 활용하지 못하는 현재의 문제 해결 + 출력으로 6개 지점의 힘이 아닌 F-Scan의 결과가 나옴

----------------------------------------------------

말할 거
1. SCAN의 경우 논문에서의 설명대로라면 서있는 상태에서 무게중심을 돌리다가 앞뒤로도 움직여야 하는데 몇몇 데이터는 돌리기만 하고 앞뒤로 움직이지는 않음
2. 논문에서의 설명과 달리 E센서와 F센서가 바뀌었고, x축과 y축이 바뀜

----------------------------------------------------

실험 목록

task123 = 시간을 기준으로 나눔
task456 = 피실험자를 기준으로 나눔
task14 = 힘과 좌표를 동시에 예측
task25 = 힘 예측
task36 = 좌표 예측

----------------------------------------------------

중요한 사항

ANN, LSTM, CNN-LSTM을 모두 paramspace에 넣고 hyperparameter tuning을 하면 ASHAScheduler를 사용했을 때 대부분 ANN으로 수렴함
하지만 LSTM, CNN-LSTM만을 paramspace에 넣고 hyperparameter tuning을 하면 ASHAScheduler를 동일하게 사용했을 때 LSTM으로 수렴함
또한 LSTM을 통해 수렴된 RMSE가 더 낮음
LSTM이 ANN에 비해 수렴시키기는 어렵지만 수렴이 된다면 더 좋은 성능을 내는 모델인 것 같고 그래서 ANN으로 local minima에 빠지는 것 같음

근거
1. task1은 LSTM으로, task23456은 ANN으로 수렴함
2. 시계열 데이터에서 RNN도 아닌 LSTM보다 ANN이 우세할리는 없다고 생각하여 의심함
3. task1을 다시 돌려봄, ANN으로 수렴(아래 링크) rmse는 115.822
https://wandb.ai/seokjin/FSR-prediction/groups/FSR_Trainable_2023-07-07_08-54-05/workspace?workspace=user-seokjin
4. task1에서 ANN을 빼고 돌려봄, LSTM으로 수렴(아래 링크) rmse는 91.067
https://wandb.ai/seokjin/FSR-prediction/groups/FSR_Trainable_2023-07-07_09-33-36/table?workspace=user-seokjin
5. 3번에서 수행한 실험은 더이상 ANN외에 거의 시도해보지를 않음

개선 실험
+ ANN, LSTM, CNN-LSTM을 따로따로 실험해본다
+ PBT 계열의 스케쥴러를 사용한다
  한정된 자원으로 최대한의 튜닝을 이끌어내는 ASHAScheduler는 탐험을 하지 않음, 한 번 ANN으로 수렴되기 시작하면 항상 ANN만 탐색함

-참고- 스케쥴러 종류
  Population Based Training(2017)
  Population Based Bandits(2020)
  HyperBand(2016)
  Asynchronus HyperBand(2018)
  HyperBand for BOHB(2018)

---------------------------------------------------

정리

+ PBT의 경우 탐색하려는 hyperparameter가 branching이 필요한 경우 사용할 수 없다.
+ PB2의 경우 탐색하려는 hyperparameter가 categorical data인 경우 사용할 수 없다.
+ 결국 branching, categorical data 모두에 사용할 수 있는 optuna search가 가장 범용적

+ branching을 모두 없애고 PBT를 적용해보려 하였으나 작동하지 않아 보류하였다. 그냥 모델 별로 다시 튜닝하는 것만 시도해봄

----------------------------------------------------

실험 정리
1. Adagrad는 업데이트량이 에폭이 커질수록 계속 작아지는 특징 때문인지 같은 학습률의 다른 optimizer를 사용했을 때보다 수렴이 느렸음
2. SGD는 gradient explode가 발생하지 않음, Adam에서는 종종 발생
3. Adam의 성능이 제일 좋았음
4. transfer learning 방법도 기존의 방법과 비교했을 때 rmse가 비슷한 정도로 수렴했음
5. LSTM 레이어 수는 1일때가 가장 좋았음

----------------------------------------------------

질문할 거
1. LSTM의 초기 hidden_state와 cell_state를 초기화하는 방식. 보통 어떻게 하는지. normal_(0, 1)으로 초기화했을 땐 gradient explode가 났는데 pytorch기본값인 0으로 초기화하니 나지 않았음 (항상 안 나는 건 아님)
L1Norm 상황에 따라 다름
gradient clipping 해볼만 한 거

2. 딥러닝에서 입력 값이 레이어를 타고 흐르면서 연산되는 값이, 양수인지 음수인지가 지니는 의미가 있는지.
* 왜 이미지분야에서 pooling은 min pooling은 거의 안쓰지만 max pooling만 하는지
* 왜 이미지 픽셀을 minmax스케일링을 할 때 (-1, 1)으로 하지 않고 (0, 1)로만 하는지
* 모든 활성함수가 우함수가 아니라는 점 때문에 입력값을
* 예를 들면 값이 크면 클수록 중요한 값을 가리키는게 맞는지, 아니면 절대값이 크면 클수록 중요한 값인 건지.

3. imputer로 채워넣은 값을 loss를 구할 때 반영해야할지

----------------------------------------------------

버그
1. optimizer의 exp_avg와 exp_avg_sq의 값이 튀면서 모든 파라미터가 nan이 되는 현상
* 하이퍼파라미터 상태는 아래와 같았음.
```python
    seed_everything(42)
    num_epoch = 100

    hidden_size = 8
    num_layer = 4
    model = LSTM(input_size, hidden_size, num_layer, output_size)
    
    learning_rate = 0.166806755734981
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch)
    criterion = torch.nn.MSELoss()
```
* LSTM의 처음 hidden_state와 cell_state는 normal_(0, 1)이었음
* LSTM의 처음 hidden_state와 cell_state를 0으로만 채워진 텐서를 넣으니 (pytorch의 디폴트) 값이 튀긴 하지만 nan으로 바뀌진 않았음.